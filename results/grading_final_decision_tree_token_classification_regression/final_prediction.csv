question_id,text,class,score,scoring_vectors,justification_cues,justification_cue_spans,y_pred
8.2_MM,"The Reverse Path Forwarding guarantees that the Packet used the best route when this packet arrived at the IS entry port. Reverse Path Broadcast is based on RPF  to suitable reduce of Overhead. RPF (for a packet arriving at an IS)  -Has this packet arrived at the IS entry port   over which the packets for this station/source are usually also sent?    Yes:  -Assumption:   Packet used the BEST route until now  -Action:     resend over all edges (not including the incoming one)     No:  -Assumption:   Packet did NOT use this route (it is NOT the best route)  -Action:     discard packet (most likely duplicate)  RPB: -Has this packet arrived at the IS entry port   over which the packets for this station/source are usually also sent?    Yes:  -Packet used the BEST route until now?    -YES: select the edge at which the packets arrived and from which they are then rerouted to source S (in reversed direction)  -NO: DO NOT send over all edges (without the incoming one),  i.e., not as in Reverse Path Forwarding (RPF)     No:  -discard packet (most likely duplicate)",PARTIAL_CORRECT,0.75,"[0.6364904642105103, 0.6813170313835144, 0.6382836103439331]","[(0, 31), (35, 36), (38, 39), (42, 43), (48, 49)]","[['The Reverse Path Forwarding guarantees that the Packet used the best route when this packet arrived at the IS entry port', 'Path', 'is', 'R', 'reduce']]",0.875
8.2_MM,"Reverse Path Forwarding: Used for ensuring loop-free forwarding of multicast packets in multicast routing and to help prevent IP address spoofing in unicast routing.  Checks if the packet arrived at the IS entry port over which the packets for this station/source are usually sent. If packet is assumed taking the best route: resend over all edges (not including the incoming one). If packet is assumed not taking the best route: discard packet.  Reverse Path Broadcast: Used to check if the set of shortest paths to a node forms a tree that spans the network.  If the packet arrives at the IS entry over which the packets for this station/source are usually sent: Checks if Packet used the BEST route until now: if yes, select the edge at which the packets arrived and from which they are then rerouted to source. If no, do not send over all edges (without the incoming one). If the packet is not for this station/source: discard packet.",PARTIAL_CORRECT,0.875,"[0.60215824842453, 0.6793730854988098, 0.6377739310264587]","[(1, 44), (45, 49), (50, 53), (54, 59), (61, 62), (67, 68), (70, 71), (74, 75)]","[['Reverse Path Forwarding: Used for ensuring loop-free forwarding of multicast packets in multicast routing and to help prevent IP address spoofing in unicast routing', 'Checks if the', 'packet arrived', 'the IS entry port over', 'the', 'station', 'are', 'sent']]",0.875
8.2_MM,"-prevent routing loops/ cycles in the network   RPF: -each node has a route to every other node -each node only forwards a broadcast packet received from the same port used to send packets back towards the sender -so the packet is forwarded only if it comes from the same route that would be used to reply to the source   RPB: -improvement of RPF If the packet arrived at the IS entry over which the packets for this station/source S are usually also sent and packet used the best route until, then select the edge at which the packets arrived and from which they are then rerouted to source S in reversed direction, if it’s not the best route then not send over all edges without the incoming one. -if not then discard packet.",PARTIAL_CORRECT,0.75,"[0.6193535327911377, 0.5990291833877563, 0.587430477142334]","[(42, 46), (49, 52), (53, 54), (56, 57), (59, 60)]","[['packet received', 'port used to', '', 'back', 'the']]",0.75
8.2_MM,"Reverse Path Forwarding and Reverse Path Broadcasting are both algorithms used for loop-free multi- and broadcast communication and therefore aim to be more efficient than simple attempts like flooding or individual sending of packets to every destination in the network. The idea of both algorithms is the use of so called “spanning trees” for each individual node in the network, which contain routes to every subnode in every subnetwork. Since one intermediary system does only know his own spanning tree, but not the ones of the surrounding nodes, each router has to use its knowledge of optimal routing for certain destinations as a criterion for further transmission. For Reverse Path Forwarding this means, that each node has to check the link on which an incoming packet is received. If this link is the optimal one, over which packets for this station are also usually sent, then node can assume that the packet has taken an optimal way up to it. As a consequence, it then re-sends the packet over all of its edges, but not the one on which the packet was received. If the packet on the other hand does not come over such an “optimal” link it gets discarded.  Since re-sending over all edges seems not to be the most efficient way of multicast-routing, Reverse Path Broadcast introduces a further check for packets that arrive over the optimal link as well as a limited re-transmission of packets: If a packet has taken the optimal path until this station, the station reroutes the packet over the optimal incoming link to the Source in reversed direction. This means, that the receiving node looks up in its routing table over which link such a packet would normally be received. Exactly this link is then used for rerouting the packet to the source instead of using all links as it is done before in Reverse Path Forwarding. Otherwise (so to say if the packet is not received on an optimal link or received on an optimal link, but has not taken an optimal path so far), the packet is not resent. This mechanism is implemented to limit the number of duplicates in the network - while Reverse Path Forwarding retransmits over all edges (excluding the one on which the packet was received), Reverse Path Broadcasting chooses the most suitable link for retransmission.",CORRECT,1.0,"[0.6167476773262024, 0.6326139569282532, 0.6456853151321411]","[(0, 64), (167, 168)]","[['Reverse Path Forwarding and Reverse Path Broadcasting are both algorithms used for loop-free multi- and broadcast communication and therefore aim to be more efficient than simple attempts like flooding or individual sending of packets to every destination in the network', 'e']]",0.875
8.2_MM,"The PURPOSE of these two algorithms is the EFFICIENT (e.g. compared to flooding) execution of BROADCAST ROUTING, i.e. the sending of packets to all other hosts in the subnet. MODE OF OPERATION: Both are based on the idea of the Spanning Tree to use the shortest possible paths from the sender to the receivers. _RPF_ FORWARDS A BROADCAST PACKET arriving on one link over all other links ONLY IF IT ARRIVES OVER A LINK OVER WHICH, according to its own routing table, PACKETS ARE ALSO ROUTED TO THE SENDER OF THE BROADCAST (i.e. it is assumed that the packet arrived on the best path), OTHERWISE THE PACKET IS DISCARDED. _RPB_ differs from _RPF_ in the way it forwards packets: A PACKET IS ONLY FORWARDED TO A DIRECT NEIGHBOURING NODE IF THE FORWARDING NODE WOULD ALSO BE LOCATED ON A UNICAST PATH BETWEEN THE SENDER AND THAT NEIGHBOURING NODE. For example, if a node B receives a broadcast packet from A and B has links with C and D, but has previously learned that no packets are routed from A to C via B, but to D via B, then it will not forward the packet to C (unlike _RPF_), but only to D. This further reduces the number of messages compared to _RPF_.",CORRECT,1.0,"[0.47066864371299744, 0.504161536693573, 0.5038530826568604]","[(106, 107), (109, 110), (112, 118), (123, 125), (127, 128), (129, 130)]","[['A', 'CAST', 'arriving on one link over', 'IF IT', 'VES', 'A']]",0.75
8.2_MM,"They are techniques to forward multicast packets in networks. They use information the IS has about the network structure (derived from normal unicast packets) to guess where to send the multicast packets. If a packet in RPF arrives over the ""usual"" path over which the sender sends, the IS will distribute(flood) the network with the packet. If the packet arrives not over the usual path, the packet will be dropped. In RPB, if the packet arrives over the ""usual"" path, the IS will send it over the path that unicast packets ""usually"" take and not flood the network. If the packet arrives not over the usual path, the packet will be dropped.",PARTIAL_CORRECT,0.75,"[0, 0, 0]",[],[[]],0.25
8.2_MM,"Reverse Path Forwarding and Reverse Path Broadcast are used in broadcasting, to enable loop-free by verifying the reachability of the destination. That way each IS will know its multicast tree RPF :  ALGORITHM : Check if the packet that arrived at the IS entry port over which the packets for this source are usually also sent. If yes, an assumption can be made that the packet used the best route. Then the packets will be resent over other edges (not including the incoming one) if no, assume the packet did not use the best route. Then this packet will be discarded. RPB : ALGORITHM :  Check if the packet that arrived at the IS entry port over which the packets fort this source are usually also sent. If yes, check if the packet used the best route. * If yes, select the edge at which the packets arrived and from which they are then rerouted to the source * If no, do not send over all the edges (without the incoming one) If no, the packet is discarded.",CORRECT,1.0,"[0.633337140083313, 0.6428908705711365, 0.7172321081161499]","[(0, 20), (59, 60), (87, 88)]","[['Reverse Path Forwarding and Reverse Path Broadcast are used in broadcasting', 'Check', 'sent']]",0.875
8.2_MM,"Reverse Path Forwarding: - Purpose: reduce traffic in broadcasting compared to flooding. In Reverse Path Forwarding, a sender only sends an incoming packet to all of its adjacent nodes if it has arrived over the edge that is considered to be part of the shortest path between that node and the source. Otherwise, the packet is ignored. Reverse Path Broadcasting: - Purpose: further reduce traffic compared to Reverse Path Forwarding. In Reverse Path Broadcasting, if a packet has arrived over the edge which is usually used for sending packets to the source, it is only forwarded to those neighbors, which usually route unicast messages to the sender via that node. So a router only spreads packets to a neighbor if it is on the shortest path between that neighbor and the source.",CORRECT,1.0,"[0.654269814491272, 0.6812569499015808, 0.6577140092849731]","[(0, 25), (30, 31), (95, 112), (113, 121)]","[['Reverse Path Forwarding: - Purpose: reduce traffic in broadcasting compared to flooding', 'Path', 'Reverse Path Broadcasting: - Purpose: further reduce traffic compare', 'to Reverse Path Forwarding']]",0.875
8.2_MM,"Reverse Path Forwarding (RPF) and Reverse Path Broadcast (RPB) are algorithms that are used to distribute packets with more than one receiver in a network. Simple approaches are individual sending to every destination or flooding. These simple approaches aren’t optimal for distributing packets to n receivers. In RPF each router has information which path it would use for unicast packets. If a router receives a package, it checks whether it received the package via the optimal route, and only forwards it to every other reachable router (except from the router it received the package from). In RPB however, packages are only forwarded according to the routing tables (via the best routes), thus reducing the load of the network.",PARTIAL_CORRECT,0.625,"[0.5589901804924011, 0.6219645738601685, 0.6572938561439514]","[(0, 45)]",[['Reverse Path Forwarding (RPF) and Reverse Path Broadcast (RPB) are algorithms that are used to distribute packets with more than one receiver in a network']],0.875
8.2_MM,"Reverse Path Forwarding is an algorithm to allow loop free forwarding of packets (especially for multicast). The source IP of an incoming packet is looked up in the routing table. If the packet would be send on this interface if the source IP would be the destination, the packet is forwarded on all edges but the incoming one. Packets that don't arrive via the shortest route may be ignored. Reverse Path Broadcast is also used for loop free forwarding and works similar to RPF. Though it does not send the packets out on all edged but selects those edges that are on the shortest path (in reverse) to the source of the multicast packet.",PARTIAL_CORRECT,0.75,"[0.6823895573616028, 0.7039439678192139, 0.6615173816680908]","[(0, 26), (102, 103), (104, 106), (107, 110), (113, 114), (117, 118)]","[['Reverse Path Forwarding is an algorithm to allow loop free forwarding of packets (especially for multicast', 'e', 'Broadcast', 'also used for', 'ing', 'to']]",0.75
8.2_MM,"Reverse path forwarding prevents multicast traffic from entering routing loops by looking up a table which holds all routers the multicast packet already visited. The packet is then forwarded to all routers that are not in the table. Reverse path broadcast is an extension of RPF: in this case packets are only forwarded to this interfaces, where the next router is on the shortest path to data origin.",PARTIAL_CORRECT,0.375,"[0.6077548861503601, 0.6616309285163879, 0.6387994885444641]","[(0, 41)]",[['Reverse path forwarding prevents multicast traffic from entering routing loops by looking up a table which holds all routers the multicast packet already visited']],0.875
8.2_MM,"The purpose is to reduce that overall network usage, and not produce unneeded traffic. You only send out the gotten packet if it came from a router you would route through to the sender, otherwise the packet gets droped as it can not be the optimal path.",INCORRECT,0.0,"[0, 0, 0]",[],[[]],0.25
8.2_MM,"In both,Packet used the BEST route with specific selection of the outgoing links. Reverse Path Forwarding:Packet used the best route and resend over all adjacent edges (not including the incoming one). Reverse Path Broadcast:Packet uses the best route and sends packet to adjacent nodes but select the edge at which the packets arrived and from which they are then rerouted to source in reversed direction and include the arrival node.",PARTIAL_CORRECT,0.375,"[0.6823895573616028, 0.7122014164924622, 0.6404375433921814]","[(19, 49), (51, 52), (54, 56), (58, 67), (68, 70), (71, 72), (73, 74), (75, 76), (77, 78), (79, 80), (81, 82), (83, 84), (94, 95), (105, 106), (107, 108)]","[['Reverse Path Forwarding:Packet used the best route and resend over all adjacent edges (not including the incoming one', 'Revers', 'Broadcast', 'et uses the best route and sends', 'packet to', 'acent', 'nodes', 'select', 'edge', '', 'the', 'packet', 'then', 'include', '']]",0.75
6.2_IPP,Extension headers carry optional header information which are important for IP routing. They are placed between fixed headers and the payload in a packet. Advantages compared to IPv4: -Extension headers help to overcome size limitations for options -Allow new options to be implemented without changing the header,CORRECT,1.0,"[0.5883876085281372, 0.7024303078651428, 0.7494151592254639, 0.5780832171440125, 0.6572867035865784, 0.5981650352478027]","[(4, 5), (20, 39), (48, 49), (67, 82)]","[['carry', 'They are placed between fixed headers and the payload in a packet', ':', '-Allow new options to be implemented without changing the header']]",1.0
6.2_IPP,Extension headers contain of additional information like Routing and Fragmentation for the network device to decide how to process the IPv6 packet. Extension headers are placed between fixed header and payload. IPv6 options are placed in separate extension headers that are located between the IPv6 header and the transport-layer header in a packet. They help to overcome size limitation and allow to append new options without changing the fixed header. The main advantage is efficiency: Since there is no extra space for options between fixed header and payload there is a smaller header and therefore more space for payload. This way it is much faster.,PARTIAL_CORRECT,0.75,"[0.6880078315734863, 0.7541436553001404, 0.6475589275360107, 0.5861254930496216, 0.6719326972961426, 0.5921727418899536]","[(30, 45), (47, 83), (97, 101), (102, 103), (104, 106), (107, 108), (109, 110), (115, 116), (117, 118), (121, 147), (148, 154)]","[['Extension headers are placed between fixed header and payload', 'v6 options are placed in separate extension headers that are located between the IPv6 header and the transport-layer header in a packet', 'append new options', 'without', 'changing the', 'fixed', 'header', 'is', 'efficiency', 'there is no extra space for options between fixed header and payload there is a smaller header and ', 'herefore more space for payload']]",1.0
6.2_IPP,"Extension headers are optional headers that store additional information. They are located between the fixed header and the payload. A lot of the information that is stored in extension headers in IPv6 is stored the fixed header in IPv4. Because of that the 'space' for the information is always reserved in IPv4, even if you don't need it. In IPv6, because extension headers are optional, you don't have to reserve any space for this information, if you don't need it.",PARTIAL_CORRECT,0.5,"[0.6174231767654419, 0.7572407126426697, 0.6710723042488098, 0.5817998051643372, 0.6770945191383362, 0.5985828638076782]","[(1, 2), (4, 5), (6, 7), (14, 30), (32, 37), (38, 45), (47, 52), (53, 54), (55, 57), (58, 60)]","[['', '', '', 'They are located between the fixed header and the payload', 'lot of the information that', 'stored in extension headers in', '6 is stored the', 'fixed', 'header in', 'v4']]",0.5
6.2_IPP,"The extension headers are optional headers placed between the fixed headers and the payload. Using these, the header information is no longer limited in size (like in ipv4) and thus can be extended based on future requirements.",CORRECT,1.0,"[0.5999706387519836, 0.6954705119132996, 0.6219860911369324, 0.5592333674430847, 0.6292415857315063, 0.5523834228515625]","[(0, 22)]",[['The extension headers are optional headers placed between the fixed headers and the payload']],0.75
6.2_IPP,"Extension Headers allow to extend the new, simplified and fixed-size IPv6-header with additional options. These headers are located between the standard header and the payload (upper-level headers and user data). This approach allows to add several additional options without reserving space in the standard header for such optional data,allowing the standard header to be smaller.",PARTIAL_CORRECT,0.5,"[0.6148179769515991, 0.7258365154266357, 0.6344702839851379, 0.5783641338348389, 0.6397170424461365, 0.587325394153595]","[(28, 53), (70, 71), (72, 74), (75, 76)]","[['These headers are located between the standard header and the payload (upper-level headers and user data', 'in', 'standard ', 'for']]",1.0
6.2_IPP,Extension headers are located between header and payload. They can contain options or other information which extend the header. The main advantage of the extension headers in IPv6 compared to IPv4 is that they are optional. In IPv4 there is a part for the options reserved but in IPv6 when there are no options the space of the extension headers can be used for a longer payload. So the extension headers are more efficient.,PARTIAL_CORRECT,0.5,"[0.6048898696899414, 0.767025887966156, 0.6299715042114258, 0.5781521797180176, 0.6626659631729126, 0.5747045874595642]","[(0, 13), (31, 33), (35, 36), (38, 39), (41, 44), (45, 46), (48, 49), (51, 53)]","[['Extension headers are located between header and payload', 'advantage', 'extension', 'in', '6 compared', 'IP', 'is', 'y are']]",1.0
6.2_IPP,"The header in IPv6 has a fixed length and is designed to be used for easy processing, it only contains information needed for routing. Any additional information is stored in extension headers. They carry optional information and can be found in between the fixed header and the playload. Since the whole IPv6 packet is only allowed a certain size, these additional extension headers take up space of the payload. The main advantage of extension headers is that they can be added optionally and help to overcome size limitation.",PARTIAL_CORRECT,0.75,"[0.6315791606903076, 0.6712686419487, 0.6352400183677673, 0.5403927564620972, 0.652642011642456, 0.5550692677497864]","[(48, 70)]",[['They carry optional information and can be found in between the fixed header and the playload']],0.75
6.2_IPP,"- located between fixed header and payload - are optional, modularly including additional information, e.g. Routing information, Authentication, or Destination options - Ipv6 has a fixed sized header",PARTIAL_CORRECT,0.75,"[0.5835660099983215, 0.7278285026550293, 0.6196646690368652, 0.5581119656562805, 0.6511490345001221, 0.567624032497406]","[(0, 18)]",[['- located between fixed header and payload - are optional']],0.75
6.2_IPP,Extension headers are optional headers that can augment the main header. They are located between the main header and the payload. Their main advantages are that they cause less overhead since they can be omitted if not needed and that new headers can be added in the future.,PARTIAL_CORRECT,0.75,"[0.6667761206626892, 0.7585565447807312, 0.6684984564781189, 0.5819392204284668, 0.6779443025588989, 0.5935941338539124]","[(1, 2), (5, 6), (10, 12), (17, 31)]","[['', 'optional', 'augment the', 'They are located between the main header and the payload']]",0.5
6.2_IPP,"Extension headers in IPv6 are optional fields that cab specify additional options in an IP package. They are located between the actual IPv6 header abd the package payload. Compared to IPv4, they have the advantage of being more flexible as they are optional and can be used to add additional options to a package without being limited by the limited header size.",CORRECT,1.0,"[0.56975919008255, 0.7570176720619202, 0.6378198266029358, 0.5614562630653381, 0.6292046308517456, 0.5692704916000366]","[(25, 44), (64, 65), (71, 72)]","[['They are located between the actual IPv6 header abd the package payload', 'as', 'can']]",1.0
6.2_IPP,"Extension Headers are extensions for the normal header. You can support multiple addresses or specify more options for your header and packet, like e.g. authentication.  The Extension Headers are located between the normal header and the payload, they will be attached to the normal header.   The biggest advantage of Extension Headers is the possibility to use broadcasting.",PARTIAL_CORRECT,0.5,"[0.5668625831604004, 0.7307534217834473, 0.6399262547492981, 0.5633582472801208, 0.642800509929657, 0.5606066584587097]","[(41, 59)]",[['The Extension Headers are located between the normal header and the payload']],1.0
6.2_IPP,Extension headers allow to append further options not covered by the fixed header and are located between the fixed header and the payload.  In contrast to IPv4 options the extension headers are entirely optional and can adapt to changing circumstances without touching the protocol itself.,CORRECT,1.0,"[0.5910126566886902, 0.6620320081710815, 0.617415189743042, 0.533888578414917, 0.6081709265708923, 0.5370018482208252]","[(0, 34)]",[['Extension headers allow to append further options not covered by the fixed header and are located between the fixed header and the payload']],1.0
6.2_IPP,"Extension headers are pieces of additional information that can be placed between the main header of an IP packet and the actual payload. They allow implementation of additional functionalities, for example predefining a static route through the network, but also information about fragmentation of larger packages. Therefore, they are the successor of the fragmentation- and options-field of an IPv4 header. In comparison, the new system with extension headers is much more flexible and adaptive to the wanted additions, because the extension headers are only optional, and also help to overcome the size limitations that were defined by the sizes of the fields in IPv4. What is more, the extension header idea is better for future developments, because new extension headers can be easily developed and attached to the existing system without changing the fixed header of an IPv6 packet.",CORRECT,1.0,"[0.5748399496078491, 0.6421064138412476, 0.5880967378616333, 0.5232669711112976, 0.5946836471557617, 0.5117385983467102]","[(0, 31), (204, 205), (211, 212)]","[['Extension headers are pieces of additional information that can be placed between the main header of an IP packet and the actual payload', 'fixed', '6']]",0.75
6.2_IPP,"Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information.  If present, they are located between the fixed header and the payload data.  The main advantage of the extension headers compared to IPv4 is the simplicity and flexibility of their use: unlike IPv4, there is no limitation on the size of the option area (40 bytes) and in the future further extension headers can be specified without having to change anything in the IPv6 packet format. The extension headers allow, for example, to use the options from IPv4 packets (such as fragmentation) that are omitted in the fixed IPv6 header.",CORRECT,1.0,"[0.7276149988174438, 0.7540727257728577, 0.7339193224906921, 0.611166775226593, 0.6976392865180969, 0.6000787615776062]","[(0, 18), (19, 24), (28, 45), (46, 48), (49, 55), (61, 67), (68, 70), (71, 73)]","[['Extension headers are used to extend the fixed IPv6 header with additional', 'optional network layer information', 'they are located between the fixed header and the payload data', 'The main', 'advantage of the extension headers', 'is the simplicity and ', 'y of', 'their use']]",1.0
6.2_IPP,"Extension headers are optional extensions to the fixed header. This provides flexibility to implement new features in the protocol. For such extensions, it is not necessary to change the fixed headers. Each header points to a next header and therefore this forms a header chain. The last header points to “no next header” and the payload, e.g. TCP or UDP, follows. Therefore, extension headers are located between the fixed header and the payload. Examples for extension headers are hop-by-hop options, destination options, encapsulating security payload (ESP) or mobility. As a main advantage vs IPv4, optional extension headers provide a high degree of flexibility, overcome the size limitations of a highly predefined header in IPv4 and grant the potential for future extensions.",CORRECT,1.0,"[0.6690777540206909, 0.7524636387825012, 0.6576036810874939, 0.5896468758583069, 0.6984537839889526, 0.5809172987937927]","[(2, 7), (8, 9), (10, 13), (105, 122)]","[['headers are optional ', 'to', 'fixed ', 'extension headers are located between the fixed header and the payload']]",1.0
6.2_IPP,"Extension headers in IPv6 are placed between fixed header and payload. The advantages compared to IPv4 is that these are optional, it helps to overcome size limitation and allow to append new options without changing the fixed header.",CORRECT,1.0,"[0.6221252083778381, 0.7302865982055664, 0.7613078951835632, 0.5724987387657166, 0.6584365367889404, 0.5817243456840515]","[(0, 19), (49, 64)]","[['Extension headers in IPv6 are placed between fixed header and payload', 'allow to append new options without changing the fixed header']]",1.0
6.2_IPP,Extension Headers are additional information like Routing and Fragmentation for network device to decide how to process the IPv6 packet.  Extension Headers are located between fixed header and payload.  main advantages: - optional - help to overcome size limitation - append new options without changing the fixed header,CORRECT,1.0,"[0.6192954182624817, 0.7669072151184082, 0.7586885094642639, 0.5807143449783325, 0.6643672585487366, 0.5840067267417908]","[(29, 45), (66, 80)]","[['Extension Headers are located between fixed header and payload', '- append new options without changing the fixed header']]",0.75
6.2_IPP,"Extension headers are optional headers located between the fixed header and payload. As they are optional, less data can be transferred by leaving them out. They also help overcome size limitations and allow appending new options without changing the fixed header in the future.",PARTIAL_CORRECT,0.75,"[0.627826452255249, 0.7178976535797119, 0.7566840648651123, 0.5747475028038025, 0.6570823788642883, 0.5785055756568909]","[(0, 20), (47, 48), (51, 66), (68, 69)]","[['Extension headers are optional headers located between the fixed header and payload', 'size', 'allow appending new options without changing the fixed header', 'future']]",1.0
6.2_IPP,"Extensions Header in IPV6 contain supplementary information used by network devices (such as routers ,switches , and endpoint hosts) to decide how to direct or process an IPV6 packet and they are located between fixed Header and payload. The main advantage of extension headers compared  to IPV4 to allow to append new options without changing the fixed header.",CORRECT,1.0,"[0.5821039080619812, 0.7465524077415466, 0.7006951570510864, 0.5772210955619812, 0.6391900777816772, 0.5833300948143005]","[(46, 61), (62, 92)]","[['and they are located between fixed Header and payload', 'The main advantage of extension headers compared to IPV4 to allow to append new options without changing the fixed header']]",1.0
1.6,Binary encoding should be used in this network because all three end systems have perfect clocks wherefore a self-clock feature isn't necessary. It also provides better utilization of the bandwidth than Manchester encoding or differential Manchester encoding.,CORRECT,1.0,"[0.6112614274024963, 0.5744958519935608, 0.6518846750259399, 0.6770963668823242, 0.47811129689216614]","[(0, 35)]","[[""Binary encoding should be used in this network because all three end systems have perfect clocks wherefore a self-clock feature isn't necessary""]]",0.0
1.6,"They should use ""Binary Encoding"" because of the perfekt timed clocks and furtermore this mechanism has the best transfer rate (1 bit per Baud).",CORRECT,1.0,"[0.5935553312301636, 0.613578200340271, 0.6368608474731445, 0.6078103184700012, 0.5052973628044128]","[(0, 35)]","[['They should use ""Binary Encoding"" because of the perfekt timed clocks and furtermore this mechanism has the best transfer rate (1 bit per Baud']]",1.0
1.6,"Bianry Encoding, since it has good utilization of bandwidth which could solve the traffic problem. On the other hand, the 3 users have already perfect clocks, the no ""self-clocking"" feature of binary coding could be neglected.",CORRECT,1.0,"[0.5885335803031921, 0.4831770658493042, 0.4896256923675537, 0.4981066584587097, 0.5158419609069824]","[(0, 5)]",[['Bianry Encoding']],1.0
1.6,I would use Binary Encoding. It is efficient since it uses 1 bit per baud. It has no self-clocking feature but that is not needed since all user have perfect clocks.,CORRECT,1.0,"[0.7244695425033569, 0.5936054587364197, 0.6205220818519592, 0.6486650705337524, 0.4535242021083832]","[(0, 8)]",[['I would use Binary Encoding']],1.0
1.6,Binary encoding can be used. It has the highest bandwidth (1 bit per Baud) and is simple and cheap. The 'self-clocking' feature of the more complex manchester encoding and differential manchester encodings is not necessary since the users have perfect clocks.,CORRECT,1.0,"[0.7684859037399292, 0.5756655335426331, 0.6273108720779419, 0.6711223125457764, 0.502557635307312]","[(0, 7)]",[['Binary encoding can be used']],1.0
1.6,"I would use the binary encoding in this network. The ""self-clocking"" feature of the Manchester Encoding isn't an advantage in this scenario since all users have perfect clocks. Therefore the perfect clocks can even out the Binary Encoding's disadvantage of not having a ""self-clocking"" feature and only the advantages of being cheap, simple and the good utilization of the bandwidth remain.",CORRECT,1.0,"[0.72646564245224, 0.5979722738265991, 0.6281804442405701, 0.647341251373291, 0.4853425920009613]","[(0, 12), (13, 15), (18, 23), (24, 25), (30, 31), (46, 88)]","[['I would use the binary encoding in this network', 'The ""', 'ing"" feature of the', 'En', 'an', 'Therefore the perfect clocks can even out the Binary Encoding\'s disadvantage of not having a ""self-clocking"" feature and only the advantages of being cheap']]",1.0
1.6,"Because all users have a perfect clock, the binary encoding is best to be used. It is simple, cheap and the bandwith is with 1 bit/Baud well utilized. (The Manchester encodings in comparison have only 0.5 bit/Baud.)",CORRECT,1.0,"[0.7094107866287231, 0.6272108554840088, 0.6366488337516785, 0.6575831770896912, 0.4794161021709442]","[(11, 21)]",[['the binary encoding is best to be used']],1.0
1.6,"Binary Encoding als Non-return to zero-level (NRZ-L) wäre zu empfehlen, da es hierbei eine gute Ausnutzung der Bandbreite (1 Bit pro Baud) bereitgestellt werden kann. Des Weiteren erfordert diese Kodierung eine sehr akurate Zeitmessung der Teilnehmer, da kein self-clocking stattinden kann (bei einer Abfolge gleicher Werte verändert sich die Kurve nicht), dies ist aber gegeben.",CORRECT,1.0,"[0.6081738471984863, 0.5250181555747986, 0.5572592616081238, 0.632746160030365, 0.46668359637260437]","[(0, 23)]",[['Binary Encoding als Non-return to zero-level (NRZ-L) wäre zu empfehlen']],0.75
1.6,"I would suggest to use binary encoding, because they are all interconnected and have perfect clocks, that is why they do not need a self-clocking encoding and it is simple and cheap, so it has a good utilization of the bandwidth ( 1 bit per Baud), what helps against congestion.",CORRECT,1.0,"[0.762767493724823, 0.5835152864456177, 0.632217526435852, 0.7163090109825134, 1.0000001192092896]","[(0, 10), (32, 35), (36, 41), (46, 49)]","[['I would suggest to use binary encoding', 'do not need', 'a self-clocking', 'simple and cheap']]",1.0
1.6,Binary Encoding. Because the Binary Encoding uses the least bandwidth among these three techniques. And the local network with 3 users is tolerant of frequency errors happened in Binary Encoding.,CORRECT,1.0,"[0.8432166576385498, 0.6279814839363098, 0.638272225856781, 0.67030268907547, 0.5093844532966614]","[(0, 4), (6, 8), (9, 25), (27, 28), (33, 34), (35, 41), (42, 47)]","[['Binary Encoding', 'Because the', 'Binary Encoding uses the least bandwidth among these three techniques', 'the', 'is', 'of frequency errors happen', 'in Binary Encoding']]",1.0
1.6,"We can use Bit encoding - it has a good utilization of the bandwidth, and it can work because the users have perfect clocks.  another technique we can use is Manchester encoding - is it not sensitive to  מoise on the line and therefore can deal with more users using the line.",PARTIAL_CORRECT,0.5,"[0.6978967189788818, 0.6559584140777588, 0.6333402395248413, 0.6928611993789673, 0.5793564319610596]","[(0, 19), (38, 39), (40, 42), (48, 51), (52, 53), (62, 63), (64, 67)]","[['We can use Bit encoding - it has a good utilization of the bandwidth', 'can', 'is Manchester', 'not sensitive', 'מ', 'deal', 'more users ']]",1.0
1.6,"Since we want to transmit with as high of a baud rate as possible we first look at binary encoding. For binary encoding we need perfectly synchronous clocks. Since all our users have perfect clocks, binary encoding is better, since the baud rate is twice as high.",CORRECT,1.0,"[0.7752450704574585, 0.5903444886207581, 0.6365383863449097, 0.6800506711006165, 0.5233462452888489]","[(0, 24), (25, 39), (52, 57)]","[['Since we want to transmit with as high of a baud rate as possible we first look at binary encoding', 'For binary encoding we need perfectly synchronous clocks', 'binary encoding is better']]",1.0
1.6,"I would use binary encoding, since the premise is that all users have perfect clocks. This makes the ""self-clocking"" feature of the other two encoding methods not necessary. Binary encoding also makes good utilization of the bandwidth (1bit per baud) which is good, since the 3 users generate lots of traffic.",CORRECT,1.0,"[0.7921247482299805, 0.628178060054779, 0.6309679746627808, 0.6400542259216309, 0.4867643415927887]","[(0, 8), (46, 68)]","[['I would use binary encoding', 'Binary encoding also makes good utilization of the bandwidth (1bit per baud) which is good']]",1.0
1.6,"In this local network with 3 users, the encoding technique Binary Encoding should be used. This technique is simple, cheap, and has a good utilization of the bandwidth. The disadvantage of the no ""self-clocking"" feature is compensated through the fact that the users have perfect clocks. In contrast, the Manchester and Differential Manchester Encoding have a worse utilization of the bandwidth  (0.5 bit/baud) than Binary Encoding (1 Bit/Baud) and the ""self-clocking"" feature is unnecessary in this case.",CORRECT,1.0,"[0.6805272698402405, 0.6450383067131042, 0.629368782043457, 0.6836928725242615, 0.5013300180435181]","[(8, 19), (80, 91), (92, 93), (94, 121)]","[['the encoding technique Binary Encoding should be used', 'a worse utilization of the bandwidth (0.5', '/', ') than Binary Encoding (1 Bit/Baud) and the ""self-clocking"" feature is unnecessary in this case']]",1.0
1.6,"A binary encoding would be most beneficial. Since all clients have perfect clocks, it doesn't need a self clocking feature as used by Manchester encoding and differential Manchester Encoding. It also can transmit a double of the data, effectively increasing the channels capacity",CORRECT,1.0,"[0.6891785860061646, 0.6016766428947449, 0.5838409662246704, 0.6356453895568848, 0.44889840483665466]","[(0, 11)]",[['A binary encoding would be most beneficial']],1.0
1.6,Binary encoding should be used.  Perfeclty clocked users do not need any self-clocking encoding such as Manchester. More traffic would benefit from more efficient encoding technique.,CORRECT,1.0,"[0.7532414793968201, 0.5783162713050842, 0.624021589756012, 0.6632703542709351, 0.49063169956207275]","[(0, 7)]",[['Binary encoding should be used']],1.0
1.6,"Baudot time multiplex system. 3 users have perfect clocks, so all channels can be processed in a fixed grid within a certain time. Each channel is assigned a fixed time window (time slot).The time windows can be synchronized and of the same length or asynchronous and depending on requirements. This is Time Division Multiplex.",INCORRECT,0.0,"[0.4974050521850586, 0.41519930958747864, 0.43598759174346924, 0.41910141706466675, 0.5123484134674072]","[(0, 1)]",[['Bau']],1.0
1.6,"Because the network has a perfect clock, we don't need an encoding technique with the self-clocking feature. Because the network is often congested we need a good utilization of the bandwidth (1 bit per Baud).",CORRECT,1.0,"[0.5800137519836426, 0.5636319518089294, 0.6217368245124817, 0.699225902557373, 0.5001410245895386]","[(11, 27)]","[[""we don't need an encoding technique with the self-clocking feature""]]",1.0
1.6,The network should use binary encoding: - Because of the perfect clocks there is no need for a self-clocking encoding - Binary encoding has better bandwith utilization than Manchester/differential Manchester encoding which is important because this network is often congested,CORRECT,1.0,"[0.5607578754425049, 0.5902057886123657, 0.6347119808197021, 0.6584066152572632, 0.4506066143512726]","[(0, 66)]",[['The network should use binary encoding: - Because of the perfect clocks there is no need for a self-clocking encoding - Binary encoding has better bandwith utilization than Manchester/differential Manchester encoding which is important because this network is often congested']],0.75
1.6,"Recommended encoding technique: Binary Encoding (NRTZ). Reasons: 1. Of all the encoding techniques presented in the lecture, binary encoding offers the best use of bandwidth (1 bit per baud versus 0.5 bits per baud for (differential) Manchester encoding) for the scenario described (heavy link utilization). 2. Since all participants have perfect clocks, there is no risk of clock drift/deviation.",CORRECT,1.0,"[0.667172908782959, 0.5888325572013855, 0.5795499682426453, 0.5935329794883728, 0.49061277508735657]","[(0, 12), (31, 72)]","[['Recommended encoding technique: Binary Encoding (NRTZ', 'binary encoding offers the best use of bandwidth (1 bit per baud versus 0.5 bits per baud for (differential) Manchester encoding) for the scenario described (heavy link utiliz']]",1.0
1.6,"Binary encoding. 1.All users have perfect clocks, so good ""self-clocking"" feature is not necessary. 2.It is mentioned that all users generate more traffic than the link’s capacities. But the utilization of the bandwidth of Manchester Encoding or Differential Manchester Encoding is 0.5 bit/Baud, only half of the utilization of Binary encoding.",CORRECT,1.0,"[0.9375958442687988, 0.5982092022895813, 0.6126573085784912, 0.6382995843887329, 0.4687958061695099]","[(0, 4), (73, 84)]","[['Binary encoding', 'only half of the utilization of Binary encoding']]",1.0
1.6,Binary Encoding as it is simple to implement and uses the bandwidth well. It's also easily doable as all parties have a perfect clock and therefore there is no problem receiving and differentiating multiple bits of the same type after another.,CORRECT,1.0,"[0.6222699880599976, 0.6768974661827087, 0.6098939776420593, 0.6186487078666687, 0.5522276163101196]","[(0, 17)]",[['Binary Encoding as it is simple to implement and uses the bandwidth well']],0.625
1.6,"In this scenario, the simple Binary Encoding technique should be used. That is, because it has the best utilization of the bandwidth among the presented techniques, which is important to use such a congested network as efficiently as possible. Furthermore, the downside of the technique not having a self-clocking feature is not a problem here since all users are interconnected and have perfect clocks.",CORRECT,1.0,"[0.6689121723175049, 0.581684947013855, 0.6220317482948303, 0.6411694288253784, 0.5491560697555542]","[(0, 4), (5, 15)]","[['In this scenario', 'the simple Binary Encoding technique should be used']]",1.0
1.6,Character oriented encoding is used.,INCORRECT,0.0,"[0, 0, 0, 0, 0]","[(1, 2), (3, 4)]","[['', '']]",0.75
4.2_LM_v1.0,"Frame bursting artificially increases the length of sent frames without adding meaningless padding by concatenating multiple frames, which are then sent together. Using frame bursting higher network speeds can be realized while maintaining the collision domain diameter that leads to better efficiency.  On the downside the latency for the frames is increased since they must wait for the next burst.",CORRECT,1.0,"[0.7016327381134033, 0.6055963635444641, 0.6516187787055969]","[(0, 31)]",[['Frame bursting artificially increases the length of sent frames without adding meaningless padding by concatenating multiple frames']],1.0
4.2_LM_v1.0,"Frame bursting is a transmission technique used at the data link layer of the OSI model, It can be effectively deployed in Gigabit Ethernets to increase network throughput. This is achieved by allowing a sender to transmit concatenated sequences of multiple frames in a single transmission. Advantage: better efficiency than the carrier extension since multiple frames are sent in a single transmission. But carrier extension wastes bandwidth by sending a single frame at a time. Disadvantage: the end to end delay is increased because frames need to wait until the buffer is full or a timeout occurs and transmission happens. In contrast, carrier extension each frame would be transmitted alone without waiting for other frames.",CORRECT,1.0,"[0.789836585521698, 0.6391677856445312, 0.6147133708000183]","[(41, 70), (71, 75), (76, 93)]","[['This is achieved by allowing a sender to transmit concatenated sequences of multiple frames in a single transmission', 'Advantage: better', 'efficiency than the carrier extension since multiple frames are sent in a single transmission']]",1.0
4.2_LM_v1.0,"Frame bursting is concatenated sequence of multiple frames sent in single transmission. Advantage: When many frames are waiting at sender, it can be efficient. Disadvantage: When there are too less frames at sender, the sender keeps waiting too much before sending or at timeout adds too much padding data to send to receiver (inefficient).",CORRECT,1.0,"[0.7850964069366455, 0.5940514802932739, 0.6514726877212524]","[(0, 19)]",[['Frame bursting is concatenated sequence of multiple frames sent in single transmission']],1.0
4.2_LM_v1.0,"Frame bursting is a feature of the shared broadcast mode. It allows the sender to transmit concatenated sequences of multiple frames in a single transmission. For example, we have eight packets and a buffer. We have to wait for all these eight packets to come and put them together on the line. If something is wrong, all of the eight packets have to be repeated.  Disadvantage: If we only have to send one or two packets, we have to wait for eight packets to arrive, it takes a long time. So we artificially increase the end to end delay. Advantage: It allows us to ""burst"" a sequence of packets resulting in higher throughput without abandoning the transmission medium.  There is a trade-off between efficiency and the end to end delay we are going to send. If we introduce end to end delay at the lower layer, the upper layer cannot do anything about it; it cannot speed it up anymore even if desired. So, thus, this is possible but not entirely ideal.",CORRECT,1.0,"[0.7893813252449036, 0.5893223881721497, 0.6082608103752136]","[(16, 40)]",[['It allows the sender to transmit concatenated sequences of multiple frames in a single transmission']],1.0
4.2_LM_v1.0,Frame bursting is  a Transmission technique which is used to increase the Transmission rate of data Frames in the data link layer. Advantage:the number of collision chances is reduced. Disadvantage:Frame Bursting does not address the primary goal of reducing the header Overhead.,INCORRECT,0.0,"[0.4879835546016693, 0.58870929479599, 0.5280029773712158]","[(1, 3), (10, 11), (16, 17), (18, 19)]","[['burst', '', 'increase', '']]",0.875
4.2_LM_v1.0,Frame bursting is a feature that allows for a higher throughput and efficiency. This works by allowing the sender to transmit a series of frames in succession in a single transmission without giving up control on the transmission medium. An advantage compared to carrier extension is that it has better efficency while a disadvantage is that it needs multiple frames waiting for transmission.,CORRECT,1.0,"[0.779478907585144, 0.6249235272407532, 0.7238942980766296]","[(25, 29), (30, 50), (51, 52), (65, 66), (75, 76), (77, 93)]","[['allowing the ', 'to transmit a series of frames in succession in a single transmission without giving', 'control', 'extension', '', 'a disadvantage is that it needs multiple frames waiting for transmission']]",0.875
4.2_LM_v1.0,"Frame bursting is one of IEEE 802.3z features of shared broadcast mode.It allows a sender to put several buffered frames together and transmit those concatenated frames in a single transmission to the receiver, without giving up the control over the transmission medium. The advantage of frame bursting is the increased efficiency resulting from a higher throughput of individual data packets due to concatenation of single frames. The disadvantage is, that this method can increase the waiting time of other senders (that are currently not sending) and the end-to-end delay.",CORRECT,1.0,"[0.7632902264595032, 0.718521773815155, 0.6879341006278992]","[(20, 55), (68, 73), (75, 83), (84, 93), (94, 106)]","[['It allows a sender to put several buffered frames together and transmit those concatenated frames in a single transmission to the receiver', 'The advantage of frame', 'ing is the increased efficiency result', 'from a higher throughput of individual', 'packets due to concatenation of single frames']]",1.0
4.2_LM_v1.0,"Frame bursting allows the sender to transmit concatenated sequence of multiple frames in single transmission , this is a solution to the problem of the improvement of the speed and its consequences to the length of the cable. Advantage: It is more efficient than the carrier extension. Disadvantage: with this you artificially increase the end to end delay, which can be a problem when the frame is critical.",CORRECT,1.0,"[0.7781644463539124, 0.6044102907180786, 0.6436210870742798]","[(0, 25)]",[['Frame bursting allows the sender to transmit concatenated sequence of multiple frames in single transmission ']],1.0
4.2_LM_v1.0,"The Frame bursting is one of the features of Shared Broadcast Mode. It consists in, on the sender's side, to concatenate a sequence of multiple frames in one single transmission.   Comparing to the carrier extension (the other feature of Shared Broadcast Mode), it needs frames to wait for transmission (disadvantage) but it has a better efficiency (advantage)  This will lead to higher among of collision or we should decrease the LAN size.",CORRECT,1.0,"[0.9633764028549194, 0.6196580529212952, 0.6251296401023865]","[(30, 46)]",[['to concatenate a sequence of multiple frames in one single transmission']],1.0
4.2_LM_v1.0,To be able to transmit data over lager distances at higher speed and still avoiding collisions you send bigger sequences by collecting several packets and sending them all together.  Advantage: You have a higher efficiency compared to carrier extension. You have a minimum of 70 percent (frame size 64 byte and user data 46 byte) user data compared to a minimum 9 percent of.  Disadvantage: You have a delay in time while waiting for other packets until you have collected enough to send.,CORRECT,1.0,"[0, 0, 0]",[],[[]],0.875
4.2_LM_v1.0,"Frame bursting allows the sender to concat frames in a single transmission to increase CSMA-CD distance. It has a higher efficiency than Carrier extension (extending min. frame length),but frames are needed to wait for transmission. Also, carrier extension has a higher overhead.",CORRECT,1.0,"[0.6870549321174622, 0.6020286679267883, 0.6174657940864563]","[(0, 27)]",[['Frame bursting allows the sender to concat frames in a single transmission to increase CSMA-CD distance']],1.0
4.2_LM_v1.0,"Frame bursting allows the sender to send many frames concatenated. If the station has several frames buffered and it has already sent a frame on the carrier, it can send the next frame directly after getting the acknowledgement from the receiver, without a dedicated time between frames.  Advantages: ""Frame bursting"": Higher speed, due to less waiting time between sending frames. ""Carrier extension"": Simple to implement  Disadvantages: ""Frame bursting"": Requires many frames to be sent simultaneously ""Carrier extension"": Low efficiency",CORRECT,1.0,"[0.6574721336364746, 0.5978102087974548, 0.629347562789917]","[(0, 18)]",[['Frame bursting allows the sender to send many frames concatenated']],1.0
4.2_LM_v1.0,"The sender buffers a number of frames and concatenates them, so they can be sent in a single transmission. The disadvantage is, that the end-to-end delay is increased, because the sender buffers the frames instead of sending them out as soon as they are created. The advantage is that no ""rubbish"" data has to be sent, like with carrier extension, so the data efficiency is much higher.",CORRECT,1.0,"[0.7026007771492004, 0.6146020889282227, 0.6494235396385193]","[(0, 17)]",[['The sender buffers a number of frames and concatenates them']],1.0
4.2_LM_v1.0,Frame Bursting allows sender to transmit concentrated Sequence of multiple Frames in single transmission.  Advantage: The rate of efficiency is increasing in Transmission  Disadvantage: Frames needs to wait for Transmission.,CORRECT,1.0,"[0.7407152056694031, 0.7312940955162048, 0.6472981572151184]","[(0, 20), (36, 38), (42, 43), (45, 46), (47, 48)]","[['Frame Bursting allows sender to transmit concentrated Sequence of multiple Frames in single transmission', 'Disadvantage', 'needs', 'for', 'Transmission']]",1.0
5.7,"Hop 1:(A, B, forward)(A, C, forward)(A, D, forward)     Hop 2:(B, E, forward) (B, C, drop) <= A->C is shorter  (C, B, drop) <= A->B is shorter  (C, E, drop) <= A->B->E is shorter (C, F, forward)  (C, D, drop) <= A->D is shorter  (D, C, drop) <= A->C is shorter  (D, F, drop)  <= A->C->F is shorter  Hop 3:   (E, C, drop) <= A->C shorter  (E, F, drop) <= A -> C-> F is shorter  (E, G, forward)  (F, D, drop) => A->D is shorter  (F, E, drop) => A -> B-> E is shorter  (F, G, drop) => A -> B -> E -> G is shorter  Hop 4:  (G, F, drop) => A->C->F is shorter  (G, H, forward)",PARTIAL_CORRECT,0.375,"[0.5354945063591003, 0.5404707193374634, 0.5955814719200134, 0.5441705584526062, 0.6605340838432312, 0.6451741456985474, 0.6006119251251221]","[(0, 1), (21, 23), (223, 224)]","[['Hop', 'Hop 2:', '4:']]",0.625
5.7,"Hop 1:(A, B, forward)(A, C, forward)(A, D, drop) // C and F do both not send packets to A over D Hop 2:(B, E, forward)(C, F, drop) // E and G do both not send packets to A over D Hop 3:(E, G, forward)Hop 4:(G, H, drop) // no destination other than G is left for H",CORRECT,1.0,"[0.5194826126098633, 0.4931860566139221, 0.5763912200927734, 0.49376562237739563, 0.6425864696502686, 0.6345022320747375, 0.5568265318870544]","[(0, 3), (67, 69), (74, 79), (82, 83)]","[['Hop 1:(', '3:(', ')Hop 4:(G', 'drop']]",1.0
5.7,"Hop 1: (A, B, forward), (A, C, forward), (A, D, forward)  Hop 2: (B, E, forward) (C ,F, forward)  Hop 3: (E, G, forward)  Hop 4: (G, H, forward)",PARTIAL_CORRECT,0.75,"[0.5265050530433655, 0.5157071948051453, 0.5825232863426208, 0.5179833173751831, 0.6723654866218567, 0.670940637588501, 0.5695189237594604]","[(0, 3), (24, 26), (40, 43), (48, 53)]","[['Hop 1: (', '2: (', 'Hop 3: (', ') Hop 4: (G']]",0.375
5.7,"Hop 1: (A, B, forward) (A, C, forward) (A, D, forward)  Hop 2: (B, C, drop), C hat das Paket bereits empfangen. (B, E, forward) (C, B, drop), B hat das Paket bereits empfangen. (C, D, drop), D hat das Paket bereits empfangen. (C, E, drop), E bekommt Pakete von A normalerweise über B. (C, F, forward) (D, C, drop), C hat das Paket bereits empfangen. (D, F, drop), F bekommt Pakete von A normalerweise über C.  Hop 3: (E, C, drop), C hat das Paket bereits empfangen. (E, F, drop), F hat das Paket bereits empfangen. (E, G, forward) (F, D, drop), D hat das Paket bereits empfangen. (F, E, drop), E hat das Paket bereits empfangen. (F, G, drop), G bekommt Pakete von A normalerweise über E.  Hop 4: (G, F, drop), F hat das Paket bereits empfangen. (G, H, drop) H hat keine Nachbar, an die das Paket weitergereicht werden kann.",PARTIAL_CORRECT,0.625,"[0.5354945063591003, 0.5404707193374634, 0.5955814719200134, 0.5441705584526062, 0.6605340838432312, 0.6451741456985474, 0.6006119251251221]","[(0, 3), (23, 25), (233, 234)]","[['Hop 1: (', 'Hop 2:', 'Hop']]",0.625
5.7,"Hop 1: (A, B, forward) (A, C, forward) (A, D, drop) <= D can't forward packet further because costs would be higher than on other routes Hop 2: (B, E, forward) (C, F, drop) <= F can't forward packet further because costs would be higher than on other routes Hop 3: (E, G, forward) Hop 4:  (G, H, drop) <= H can't forward packet further, no further nodes there",CORRECT,1.0,"[0.5485020875930786, 0.5638834834098816, 0.5855107307434082, 0.5473661422729492, 0.6602276563644409, 0.6435430645942688, 0.6045464277267456]","[(0, 2), (3, 4), (91, 92), (97, 101)]","[['Hop 1:', 'A', '(', ') Hop 4: (']]",0.75
5.7,"Hop 1: (A, B, forward) (A, C, forward) (A, D, drop) because A sends to D, but D doesn't forward anywhere else (neither to C or F, because those nodes are reached over other links)  Hop 2: (B, E, forward) (C, F, drop) because F won't forward the packet anywhere else (F / E / G, because those nodes are ) Hop 3: (E, G, forward)  Hop 4: (G, H, drop) because H is only connected to G and receives the packet from G, so it doesn't need to forward it anywhere else",CORRECT,1.0,"[0.5144475102424622, 0.5067430734634399, 0.5596926212310791, 0.498430073261261, 0.6354185938835144, 0.630641520023346, 0.5619960427284241]","[(0, 3), (113, 114), (119, 123)]","[['Hop 1: (', '(', ') Hop 4: (']]",0.375
5.7,"Hop 1: (A, B, forward) (A, C, forward) (A, D, drop): Because D recognize that F and C won't receive packets via D.   Hop 2: (B, E, forward) (C, F, drop): Because F recognize that E,D and G won't receive packets via F.   Hop 3: (E, G, forward)   Hop 4: (G, H, drop): There is only one possibility for  H to receive the packet (via G ) and it can't be send it anywhere else.",CORRECT,1.0,"[0.5259420275688171, 0.5160804986953735, 0.5735865235328674, 0.5150647759437561, 0.6586436629295349, 0.6473749279975891, 0.5733163356781006]","[(0, 4), (82, 84), (90, 94), (97, 99)]","[['Hop 1: (A', '3: (', 'Hop 4: (G', 'drop):']]",0.375
5.7,"Hop1:  (A, B, forward) (A, C, forward) (A, D, drop) // D will receive the packet and won't forward it   Hop 2:  (B, E, forward) (C, F, drop) // F will receive the packet and won't forward it   Hop 3:  (E, G, forward)  Hop 4:  (G, H, drop) // H will receive the packet and won't forward it",PARTIAL_CORRECT,0.75,"[0.5128546953201294, 0.4957249164581299, 0.5596926212310791, 0.498430073261261, 0.6354185938835144, 0.630641520023346, 0.5533877015113831]","[(0, 1), (68, 69), (74, 78)]","[['Hop', '(', ') Hop 4: (']]",0.375
5.7,"Hop 1:  (A, B, forward)(A, C, forward)(A, D, forward) Hop 2: (B, C, dropped) C would not send packets to A via B, costs 4, direct path to B costs 2(B, E, forward)(C, B, dropped) same reason as before(C, D, dropped) C would not send packets to A via D, costs 4, direct path to D costs 2(C, E, dropped) E would send packet via B(C, F, forward)(D, C, dropped) same reason as (C, D)(D, F, dropped) f would send packet via C, costs of 1 instead of 3 Hop 3: (E, F, dropped) e would send packet via B, costs of 1 instead of 2 (over F and C)(E, G, forward)(F, E, dropped) same reason as before(F, G, dropped) g would send packet via e, because costs of 1 instead of 2 Hop 4: (G, H, forward)",PARTIAL_CORRECT,0.375,"[0.5144475102424622, 0.5070252418518066, 0.5579385757446289, 0.5047768950462341, 0.6338717341423035, 0.617822527885437, 0.5692316889762878]","[(0, 3), (21, 22), (245, 248)]","[['Hop 1: (', 'Hop', 'Hop 4: (']]",0.375
5.7,"Hop 1: (A,C,forward)(A,B,forward)(A,D,forward) Hop 2: (B,E,forward)(C,F,forward) Hop 3: (E,G,forward) Hop 4: (G,H,drop) => dropped because the package arrived from the port with shortest path to S but there is no other port to forward the package to.",PARTIAL_CORRECT,0.75,"[0.5578543543815613, 0.5279891490936279, 0.6227455735206604, 0.528989851474762, 0.724019467830658, 0.7081243395805359, 0.5846279859542847]","[(0, 3), (22, 23), (36, 39), (41, 42), (43, 49)]","[['Hop 1: (', '2:', 'Hop 3: (', 'G', 'forward) Hop 4: (G']]",0.375
5.7,"Hop1 (A,B, forward) (A,C, forward) (A,D, forward)  Hop2 (B,E,forward) (C,F,forward)  Hop3 (E,G,forward)  Hop4 (G,H,forward)",PARTIAL_CORRECT,0.625,"[0.49764469265937805, 0.46888166666030884, 0.5454738140106201, 0.46666693687438965, 0.6317155361175537, 0.6079225540161133, 0.5533877015113831]","[(0, 1), (25, 26)]","[['Hop', '(']]",0.625
5.7,"Hop 1 (A, B, forward) (A, C, forward) (A, D, forward) Hop 2 (B, E, forward) (C, F, forward) Hop 3 (E, G, forward) Hop 4 (G, H, forward)",PARTIAL_CORRECT,0.75,"[0.570854663848877, 0.5171650052070618, 0.6055434346199036, 0.5082062482833862, 0.6821984648704529, 0.6682778596878052, 0.5759034752845764]","[(0, 2), (24, 25), (39, 40), (48, 51), (55, 56)]","[['Hop 1', '2', 'Hop', 'Hop 4 (', 'forward']]",0.375
5.7,"Hop 1: (A, B, forward) (A, C, forward) (A, D, drop) <= There is no edge over which it is the best route to send packets over D to A  Hop 2: (B, E, forward) (C, F, drop) <= There is no edge over which it is the best route to send packets over F to A  Hop 3: (E, G, foward)  Hop 4: (G, H, drop) <= H does not have any other neighbor to send the packet to",CORRECT,1.0,"[0.5238961577415466, 0.5160804986953735, 0.5735865235328674, 0.5150647759437561, 0.6586436629295349, 0.6473749279975891, 0.5733163356781006]","[(0, 3), (86, 87), (95, 99)]","[['Hop 1: (', '3:', 'Hop 4: (G']]",0.375
5.7,"Hop 1: (A, B, forward)(A, C, forward)(A, D, forward) Hop 2: (B, E, forward)(B, C, drop) <= not the minimal route / part of minimal spanning tree. C would use (C,A)(C, B, drop) <= not the minimal route / part of minimal spanning tree. B would use (B, A) (C, E, drop) <= not the minimal route / part of minimal spanning tree. E would use (E, B, A)(C, F, forward)(C, D, drop) <= not the minimal route / part of minimal spanning tree. D would use (D, A)(D, C, drop) <= not the minimal route / part of minimal spanning tree. C would use (C, A)(D, F, drop) <= not the minimal route / part of minimal spanning tree. F would use (F, C, A) Hop 3: (E, C, drop) <= not the minimal route / part of minimal spanning tree. C would use (C, A)(E, F, drop) <= not the minimal route / part of minimal spanning tree. F would use (F, C, A)(E, G, forward)(F, D, drop) <= not the minimal route / part of minimal spanning tree. D would use (D, A)(F, E, drop) <= not the minimal route / part of minimal spanning tree. E would use (E, B, A)(F, G, drop) <= not the minimal route / part of minimal spanning tree. G would use (G, E, B, A) Hop 4: (G, F, drop) <= not the minimal route / part of minimal spanning tree. F would use (F, C, A)(G, H, forward) Hop 5: No further transmissions because no more routes except to G available.",PARTIAL_CORRECT,0.375,"[0.4491555690765381, 0.49183088541030884, 0.5095075964927673, 0.4966079592704773, 0.5471985936164856, 0.5398537516593933, 0.5267041325569153]","[(1, 2), (22, 23)]","[['1:', '2:']]",0.375
6.3_IPP,DHCP extends the functionality of RARP. It is used for automatic IP address assignment.,PARTIAL_CORRECT,0.5,"[0.609799325466156, 0.6659437417984009, 0.5634740591049194, 0.5735654830932617, 0.7709653377532959, 0.6476554274559021]","[(4, 5), (8, 9), (12, 21)]","[['the', 'of', 'It is used for automatic IP address assignment']]",0.75
6.3_IPP,"The Dynamic Host Configuration Protocol (DHCP) is a protocol designed as a replacement for the RARP and BOOTP protocols, with some additional functionality. As such, it is is a protocol used for managing client IP addresses in a LAN.   When a client first joins a network, it sends out a so-called 'DHCP Discover packet', which is a way for the client to tell the DHCP server (usually the local router) that it needs a valid IP address.   The DHCP server then responds, assigning an IP address and optionally some additional addresses (like the default netmask or router) to this host. The assigned address will be valid only for a certain duration specified by the host in the response.   The client now has to renew its IP address (by sending out yet another DHCP Discover packet) before the assigned address expires.  As long as the address hasn't expired, it is safe for the client to assume that his current address is still valid, even after being disconnected from the network for some time.",CORRECT,1.0,"[0.7165330052375793, 0.5836001038551331, 0.6794461011886597, 0.5489646792411804, 0.6137921810150146, 0.7652201652526855]","[(0, 12), (13, 31), (53, 54), (142, 143), (147, 148), (150, 152), (153, 154)]","[['The Dynamic Host Configuration Protocol (DHCP) is ', 'protocol designed as a replacement for the RARP and BOOTP protocols', 'client', 'additional', 'the', 'netmask', 'router']]",0.5
6.3_IPP,"The DHCP protocol is used to simplify the configuration of ip adresses of end systems. It is used to dynamically assign ip adresses to the participants of a network, while still enabling administrators to configure ip adresses manually. Every end system is able to configure itself with the help of the dhcp-server. The end system sends a dhcp discovery broadcast, the dhcp identifies itself and afterwards they negotiate the ip adress, as well as other parameters like time server, name server, domain name and subnet mask.",CORRECT,1.0,"[0.5983783602714539, 0.6614307165145874, 0.5557746291160583, 0.6945503950119019, 0.6833365559577942, 0.7007308602333069]","[(0, 19), (20, 36), (37, 39), (49, 50), (52, 54)]","[['The DHCP protocol is used to simplify the configuration of ip adresses of end systems', 'It is used to dynamically assign ip adresses to the participants of', 'a network', '', 'ip adresse']]",1.0
6.3_IPP,"The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on Internet Protocol networks whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on a network so they can communicate with other IP networks. A DHCP server enables computers to request IP addresses and networking parameters automatically from the Internet service provider (ISP), reducing the need for a network administrator or a user to manually assign IP addresses to all network devices.  DHCP is used for: Simplifies installation and configuration of end systems Allows for manual and automatic IP address assignment May provide additional configuration information (DNS server, netmask, default router, etc.)",CORRECT,1.0,"[0.5737375617027283, 0.7562539577484131, 0.5614731907844543, 0.7024809718132019, 0.7121515274047852, 0.6644413471221924]","[(0, 60), (113, 150)]","[['The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on Internet Protocol networks whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on a network so they can communicate with other IP networks', 'DHCP is used for: Simplifies installation and configuration of end systems Allows for manual and automatic IP address assignment May provide additional configuration information (DNS server, netmask']]",0.75
6.3_IPP,The DHCP is used to add clients into a network by giving them the required information/addresses.,PARTIAL_CORRECT,0.25,"[0.5401644110679626, 0.4801750183105469, 0.4595460593700409, 0.5173534154891968, 0.5019413232803345, 0.6055135726928711]","[(3, 4), (12, 13), (16, 18), (19, 20)]","[['is', 'by', 'the required', '/']]",1.0
6.3_IPP,"DHCP is a protocol to centrally manage the distribution of ip addresses in a network. The DHCP simplifies the installation and configuration of end systems. Moreover, it allows for manual and automatic IP address assignment and may provide additional configuration information such as DNS server, netmask, default router, etc.",CORRECT,1.0,"[0.6130921244621277, 0.6716248393058777, 0.5543596148490906, 0.8465889692306519, 0.746155321598053, 0.6804868578910828]","[(22, 34), (35, 36), (38, 63)]","[['The DHCP simplifies the installation and configuration of end systems', 'More', 'it allows for manual and automatic IP address assignment and may provide additional configuration information such as DNS server, netmask']]",0.75
6.3_IPP,The dhcp protocol is a protocol to configure systems that join a network. It is used to assign ip addresses to systems within the network.  If a system joins the network it can ask the dhcp server for network configuration and an ip address that it should use in the future.,PARTIAL_CORRECT,0.5,"[0.696827232837677, 0.6385055780410767, 0.5456554889678955, 0.6451758742332458, 0.5760517716407776, 0.6016514301300049]","[(0, 17), (42, 43), (45, 53), (54, 55), (58, 59), (60, 61), (63, 64)]","[['The dhcp protocol is a protocol to configure systems that join a network', 'it', 'the dhcp server for network configuration and', '', 'it', 'use', 'future']]",0.5
6.3_IPP,"The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on Internet Protocol networks whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on a network.   DHCP simplifies installation and configuration of end systems, and allows for manual and automatic IP address assignment.  End systems can broadcast DHCP DISCOVER packets to retrieve their IP from the DHCP server.",CORRECT,1.0,"[0.6303166151046753, 0.7776798009872437, 0.5806469321250916, 0.8277072310447693, 0.8824759125709534, 0.6435454487800598]","[(0, 50), (51, 61), (62, 73)]","[['The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on Internet Protocol networks whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on a network', 'DHCP simplifies installation and configuration of end systems', 'and allows for manual and automatic IP address assignment']]",0.75
6.3_IPP,"DHCP has replaced RARP (and BOOTP) as it has Extended functionality. Its uses are: 1.Simplifies installation and configuration of end systems 2.Allows for manual and automatic IP address assignment 3.May provide additional configuration information like DNS server, netmask, default router, etc.",CORRECT,1.0,"[0.7165330052375793, 0.6621671915054321, 0.8015669584274292, 0.733918309211731, 0.7346602082252502, 0.6762321591377258]","[(0, 21), (28, 58), (59, 61)]","[['DHCP has replaced RARP (and BOOTP) as it has Extended functionality', 'Simplifies installation and configuration of end systems 2.Allows for manual and automatic IP address assignment 3.May provide additional configuration information like DNS server', 'netmask']]",0.75
6.3_IPP,DHCP is a network management protocol which extends the functionality of RARP and BOOTP. DHCP simplifies installation and cofiguration of end systems. It also allows for manual and automatic IP address assignment.,CORRECT,1.0,"[0.6219698786735535, 0.680687427520752, 0.6656765341758728, 0.7862322926521301, 0.861685574054718, 0.6375565528869629]","[(0, 23), (24, 36), (37, 49)]","[['DHCP is a network management protocol which extends the functionality of RARP and BOOTP', 'DHCP simplifies installation and cofiguration of end systems', 'It also allows for manual and automatic IP address assignment']]",0.75
6.3_IPP,"The Dynamic Host Configuration Protocol (DHCP) is Internet Protocol based on the special server that uses for manually or automatically IP addresses assignment and other network configuration parameters, such as subnet masks and default gateways, to each device on a network so they can communicate with other IP networks. This server need not be on the same LAN as the requesting host. Since the DHCP server may not be reachable by broadcasting, a DHCP relay agent is needed on each LAN.",CORRECT,1.0,"[0.5554604530334473, 0.699178159236908, 0.5538966655731201, 0.5303123593330383, 0.6490542888641357, 0.5810196995735168]","[(0, 39)]",[['The Dynamic Host Configuration Protocol (DHCP) is Internet Protocol based on the special server that uses for manually or automatically IP addresses assignment and other network configuration parameters']],1.0
6.3_IPP,It is used to assignIP addresses to hosts in a network.,PARTIAL_CORRECT,0.25,"[0.5666466355323792, 0.4553717076778412, 0.4422995448112488, 0.48611387610435486, 0.42534223198890686, 0.4128913879394531]","[(0, 1), (5, 6), (11, 12)]","[['It', 'IP', 'in']]",0.625
6.3_IPP,"DHCP is a protocol that provides quick, automatic, and central management for the distribution of IP addresses within a network. It simplifies installation and configuration of end systems, also allowing for manual and automatic IP address assignment.  It is used for providing configuration information such as DNS server, netmask, default router, etc)",CORRECT,1.0,"[0.6346613168716431, 0.6466074585914612, 0.5538721084594727, 0.8792595863342285, 0.8479537963867188, 0.6239196062088013]","[(29, 38), (39, 50), (51, 63)]","[['It simplifies installation and configuration of end systems', 'also allowing for manual and automatic IP address assignment', 'It is used for providing configuration information such as DNS server']]",0.75
6.3_IPP,DHCP is a network management protocol which configures end devices on IP Networks (mostly LANs) by assigning them an IP address and other network configuration parameters.,PARTIAL_CORRECT,0.5,"[0.6084214448928833, 0.7585750818252563, 0.5843637585639954, 0.5567526817321777, 0.5773128271102905, 0.6003685593605042]","[(0, 37)]",[['DHCP is a network management protocol which configures end devices on IP Networks (mostly LANs) by assigning them an IP address and other network configuration parameters']],0.25
6.3_IPP,It’s a network protocol used on IP networks to dynamically assign an IP address and other information to any device (host) on a network so they can communicate using IP.,PARTIAL_CORRECT,0.5,"[0.5647379159927368, 0.716307520866394, 0.5607131719589233, 0.5358731150627136, 0.5826804041862488, 0.5787218809127808]","[(0, 40)]",[['It’s a network protocol used on IP networks to dynamically assign an IP address and other information to any device (host) on a network so they can communicate using IP']],1.0
6.3_IPP,"The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on Internet Protocol networks whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on a network so they can communicate with other IP networks. It is used for simplified installation and configuration of end systems into network. Allows for manual or automatic assignment of IP addresses. May also provide additional configuration information like DNS server, netmask, default router, etc",CORRECT,1.0,"[0.6297870874404907, 0.7562539577484131, 0.5617849230766296, 0.7746846079826355, 0.7850584983825684, 0.7675662040710449]","[(0, 60), (61, 75), (76, 89), (90, 100)]","[['The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on Internet Protocol networks whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on a network so they can communicate with other IP networks', 'It is used for simplified installation and configuration of end systems into network', 'Allows for manual or automatic assignment of IP addresses', 'May also provide additional configuration information like DNS server']]",0.75
6.3_IPP,"DHCP is used to manually/automatically assign IP addresses to physical devices inside of a network with the help of a DHCP server. A client with no IP address sends a broadcast DHCP discover packet to everyone on the network. The Server will respond with a DHCP offer, where he offers an IP address to the client. The Client will then respond with a DHCP request (telling the server he wants the IP address). The Server will assign the IP address to the Client for a certain time period (DHCP ACK). After this leasing time, the client has to renew the leasing of the IP address otherwise the DHCP Server will remove the IP address of the client again.",PARTIAL_CORRECT,0.5,"[0.5204806923866272, 0.6625192165374756, 0.5372190475463867, 0.5397574305534363, 0.641118586063385, 0.5521668195724487]","[(0, 32)]",[['DHCP is used to manually/automatically assign IP addresses to physical devices inside of a network with the help of a DHCP server']],1.0
4.3,xxx.xxx.xxx.0  xxx.xxx.xxx.255,INCORRECT,0.0,"[0, 0]",[],[[]],0.625
4.3,0.x.x.x -> network address 127.x.x.x -> Loopback (x.0.0.0 -> Gateway in all Types of network) (x.255.255.255 -> Broadcast in all Types of network),CORRECT,1.0,"[0, 0]",[],[[]],0.625
4.3,"Class A contains all IP addresses with first octet from 0 to 127 (IP address format is octet1.octet2.octet3.octet4)  According to slide 45 of Internet Protocols: Addresses in range 127.0.0.0 to 127.255.255.255 are reserved, because they are used for loopback testing. Addresses in range 0.0.0.0 to 0.255.255.255 are reserved, because they refer to hosts of the current network.  (So, excluding these 2 groups, each network with starting octet X, 0<X<127 of Class A has address X.0.0.0 for the network, X.255.255.255 for broadcasting and the rest addresses between these 2 for hosts).",CORRECT,1.0,"[0.5173793435096741, 0.5735755562782288]","[(0, 6), (7, 14), (17, 20), (35, 36), (44, 48), (50, 59), (69, 70)]","[['Class A contains all IP', 'addresses with first octet from 0', 'IP address format', 'According', 'Addresses in range', '.0.0 to 127.255.255.255 are reserved', '']]",1.0
4.3,(0.0.0.0/8 Depends if 0 is countes as a class A network): Current Network 10.0.0.0/8: Private networks 127.0.0.0/8: Loopback  Quelle: RFC 5735,CORRECT,1.0,"[0, 0]",[],[[]],0.625
4.3,0.0.0.0 to 0.255.255.255 10.0.0.0 to 10.255.255.255 127.0.0.0 to 127.255.255.255,CORRECT,1.0,"[0, 0]",[],[[]],0.625
4.3,0.0.0.0/8: current network adresses 127.0.0.0/8: loopback adresses,CORRECT,1.0,"[0, 0]",[],[[]],0.625
4.3,10.0.0.0 - 10.255.255.255172.16.0.0 - 172.31.255.255127.0.0.0 - 127.255.255.255,PARTIAL_CORRECT,0.5,"[0, 0]",[],[[]],0.625
4.3,0.0.0.0 to 0.255.255.255: current network 127.0.0.0 to 127.255.255.255: loopback adresses,CORRECT,1.0,"[0, 0]",[],[[]],0.625
4.3,127.255.255.255 (Broadcast) 1.0.0.0 to 126.0.0.0 (Network ID),INCORRECT,0.0,"[0, 0]",[],[[]],0.625
4.3,127.X.X.X (127.0.0.0～127.255.255.255),CORRECT,1.0,"[0, 0]",[],[[]],0.625
4.3,10.0.0.0 bis 10.255.255.255 private netze,PARTIAL_CORRECT,0.5,"[0, 0]",[],[[]],0.625
4.3,Network Addresses:    [0-127].0.0.0 Broadcast Addresses: [0-127].255.255.255,PARTIAL_CORRECT,0.5,"[0, 0]",[],[[]],0.625
4.3,"Just to note: originally I understood the task to mean reserved addresses within the network (i.e. concerning the host part), but then there was an official statement in the forum that the network part was meant. If it is indeed the host part, then *.0.0.0 and *.255.255.255 would be reserved within each Class A network. Reserved addresses in Class A networks: 0.0.0.0 - 0.255.255.255 (host at this network)10.0.0.0 - 10.255.255.255 (Class A private network range)127.0.0.0 - 127.255.255.255 (local host)",CORRECT,1.0,"[0.5751652717590332, 0.5549039244651794]","[(14, 15), (16, 20), (27, 28), (29, 30), (81, 82), (83, 86), (87, 88), (99, 100), (101, 102), (108, 109), (116, 117)]","[['', 'within the network', 'the', 'part', 'Reserved', 'addresses in Class', 'networks', 'host', 'this', '-', 'private']]",1.0
4.3,from 0.0.0.0 to 127.255.255.255,INCORRECT,0.0,"[0, 0]",[],[[]],0.625
4.3,IP : 0.0.0.0 IP Range: 127.0.0.1 to 127.255.255.255 are network testing addresses (also referred to as loop-back addresses),CORRECT,1.0,"[0.3922349512577057, 0.4842224717140198]","[(28, 29), (33, 34)]","[['loop', ')']]",1.0
4.3,IP Ranges: 0.0.0.0 - 0.255.255.255 127.0.0.0 - 127.255.255.255,CORRECT,1.0,"[0, 0]",[],[[]],0.625
4.3,127.0.0.0~127.255.255.255,CORRECT,1.0,"[0, 0]",[],[[]],0.625
4.3,"0.0.0.0-0.255.255.255 10.0.0.0-10.255.255.255, 100.64.0.0-100.127.255.255 127.0.0.0-127.255.255.255,",CORRECT,1.0,"[0, 0]",[],[[]],0.625
4.3,"All 0 -> 0-127.0.0.0:  Network Address (or excluding 0.0.0.0 and 127.0.0.0 in respect to reserved addresses according the IETF Special-Purpose IP Address Registries from RFC 6890) All 1 -> 0-127.255.255.255: Broadcast Address (or excluding 0.255.255.255 and 127.255.255.255 in respect to reserved addresses according the IETF Special-Purpose IP Address Registries from RFC 6890) Additionally the following Class A Network (Parts) are reserved according to RFC 6890 https://datatracker.ietf.org/doc/html/rfc6890#section-2.2.2 127.0.0.0/8 loopback adresses 10.0.0.0/8 Private-Use 0.0.0.0/8   ""This host on this network"" 100.64.0.0/10 Shared Address Space",CORRECT,1.0,"[0.5751652717590332, 0.607799768447876]","[(3, 7), (10, 17), (18, 22), (25, 28), (29, 34), (36, 39), (40, 41), (42, 59), (61, 62), (74, 75), (84, 85), (96, 98), (99, 105), (106, 108), (109, 117), (137, 138), (142, 143), (144, 146), (159, 160)]","[['0-127.0.0.0', '(or excluding 0.0.0.0', '127.0.0.0', 'reserved addresses', 'according the IETF Special', 'urpose IP Address', 'ies', 'RFC 6890) All 1 -> 0-127.255.255.255: Broadcast Address (', 'ding', 'reserved', 'P', 'Additionally', 'following Class A Network (', 's)', 'reserved according to RFC 6890', '-', '0.0', 'loopback', '""']]",1.0
4.3,For each of the 2^7 = 128 networks the first and the last address are reserved. - Network address (all zeros) - Broadcast address (all ones),PARTIAL_CORRECT,0.5,"[0, 0]",[],[[]],0.625
12.1_PE,"B -> C -> A  B is the least propable, because there is only this one combination out of 64 possible combinations. The propability is 1,38% ( 0,6*0,6*0,6*0,3*0,3*0,3). C is more propable, because out of the 64 combinations, 20 combinations can satisfy this condition (formula would be 6!/3!*3!) and results in 27,63% propability. The most propable case is A, because it contains B and has the propabilities of having 4 Hs, 5Hs and 6Hs added onto it, which results in 82,08% propability.",PARTIAL_CORRECT,0.75,"[0.5675868988037109, 0.4519297480583191, 0.4562620222568512, 0.5096777677536011, 0.5181301236152649, 0.5072227716445923]","[(33, 34), (38, 43), (44, 47), (140, 141)]","[['is', '*0,6*0,6*', '*0,3*', 'ability']]",1.0
12.1_PE,B -> least likely  C -> in between A -> most likely  All three Events have the same minimum amount of H's in their sequence which indicates that the probability order is based on the number of permutation.  B has least likelihood because it has the least amount of possible permutations (exactly one). A has the most amount of permutation because it also allows permutations with more than 3 H's. So the permutations of C are a proper subset of the permutations of Event A.  In this case the probability of H is larger than 0.5 so that is even more likely that there are permutations with more than three H's. But it would also hold true if this was not the case.,CORRECT,1.0,"[0.7096692323684692, 0.44261813163757324, 0.44334498047828674, 0.549400806427002, 0.5508164763450623, 0.5487895607948303]","[(1, 2), (3, 4), (5, 6), (7, 13), (14, 18), (21, 22), (23, 24), (26, 31), (32, 37), (38, 41), (42, 49), (50, 52), (53, 54), (61, 63), (73, 74), (83, 84), (86, 88), (107, 109), (111, 112), (114, 115), (121, 122), (124, 125)]","[['->', 'least', 'ly', '-> in between A ->', 'likely All three', 'same', '', ""H's in "", 'sequence which indicat', 'that the probabil', 'order is based on the number', 'permutation', 'B', 'because it', 's', '', 'permutation', 'permutation', 'C', 'a', 'mutation', 'Event']]",0.75
12.1_PE,Order: B-C-A The probability of having HHHTTT is the lowest because its the most specific outcome. Only one possible path.  The probability of seeing exactly three H’s is the second lowest. It includes the probability of HHHTTT and all other possible orders to achieve exactly three H’s.  Having at least three H’s is the most probable outcome of those three. It includes the probability of B and C plus all outcomes with more than three H’s.,CORRECT,1.0,"[0.6247708797454834, 0.4695727229118347, 0.4507877826690674, 0.5066735744476318, 0.5213187336921692, 0.5157599449157715]","[(7, 8), (9, 29), (37, 38), (39, 41), (42, 43), (44, 46), (47, 52), (53, 54), (63, 64), (75, 77), (101, 102), (104, 105), (108, 110), (112, 113), (116, 117), (121, 122)]","[['The', 'ity of having HHHTTT is the lowest because its the most specific outcome', 'ity', 'seeing', 'ly', 'H’', 'is the second lowest', 'It', 'and', '’s', 'It', 'the', 'B and', 'all', 'with', '’']]",0.75
12.1_PE,"By calculating using the binomial distribution probability formula, it can be concluded that the probability of event C occurring is 0.2765.  The probability of event A occurring is: P[event A]=P[you see exactly three H’s]+P[you see four H’s]+P[you see five H’s]+P[you see six H’s] =P(k=3)+P(k=4)+P(k=5)+P(k=6)= 0.2765+0.311+0.1866+0.0467=0.8208 (P is the binomial distribution) The probability of event B occurring is 0.6*0.6*0.6*0.4*0.4*0.4=0.013824.  Therefore the order is event B to event C to event A.",CORRECT,1.0,"[0.5904142260551453, 0.48188894987106323, 0.4690459966659546, 0.7190247178077698, 0.7162907719612122, 0.7169544100761414]","[(7, 10), (12, 13), (15, 30), (31, 44), (45, 48), (50, 51), (56, 57), (58, 59), (65, 66), (67, 68), (74, 75), (76, 77), (79, 80), (83, 84), (85, 86), (87, 89), (90, 93), (94, 98), (99, 110), (111, 113), (115, 117), (118, 121), (122, 125), (126, 154)]","[['nomial distribution', 'formula', 'can be concluded that the probability of event C occurring is 0.2', 'The probability of event A occurring is: P[event', ']=P[', 'exact', ']+', '[', ']+', '[', ']+', '[', 'six', ']', '=', '(k', ')+P(', '=4)+P(', '=5)+P(k=6)= 0.2765+0', '311+0', '+0.0', '=0.8208', 'P is the', 'nomial distribution) The probability of event B occurring is 0.6*0.6*0.6*0.4*0.4*0.4=0.013824.']]",1.0
12.1_PE,B -> C -> A  A: 0.6^3 * 0.4^3 * 20 + 0.6^4 * 0.4^2 * 15+ 0.6^5 * 0.4 * 6 + 0.6^6 = 0.8208 B: 0.6^3 * 0.4^3 = 0.013824 C: 0.6^3 * 0.4^3 * 20 = 0.27648,CORRECT,1.0,"[0.3987535536289215, 0.5421794056892395, 0.5292035937309265, 0.5607069730758667, 0.5506822466850281, 0.5477262139320374]","[(1, 70)]",[['-> C -> A A: 0.6^3 * 0.4^3 * 20 + 0.6^4 * 0.4^2 * 15+ 0.6^5 * 0.4 * 6 + 0.6^6 = 0.8208 B: 0.6^3 * 0.4^3 = 0.013824 C: 0.6^3 * 0.4^3 * 20 = 0.27648']],0.75
12.1_PE,"Event B: 0.6^3 * 0.4^3 = 0.013824 = 1.3824% Event C: P(X=3) = 20×0,6 ^3× (1-0,6)^3 = 0.27648 = 27.648% Event A: P(X>= 3) = P(X=3) + P(X=4) + P(X=5) + P(X=6) = 0.8208 = 82.08 %",CORRECT,1.0,"[0.4009813070297241, 0.4882339835166931, 0.46944648027420044, 0.5964298248291016, 0.5877795815467834, 0.5858227014541626]","[(0, 93)]","[['Event B: 0.6^3 * 0.4^3 = 0.013824 = 1.3824% Event C: P(X=3) = 20×0,6 ^3× (1-0,6)^3 = 0.27648 = 27.648% Event A: P(X>= 3) = P(X=3) + P(X=4) + P(X=5) + P(X=6) = 0.8208 = 82.08 %']]",0.25
12.1_PE,"- Event B (lowest probability because there is only one sequence fulfilling this property) - Event C (superset of Event B and additionally containing all other sequences containing three H's) - Event A (superset of Event C and additionally containing all sequences with four H's, five H's and six H's)",CORRECT,1.0,"[0.6974146366119385, 0.48008546233177185, 0.4731356203556061, 0.5932753682136536, 0.5955561399459839, 0.5868730545043945]","[(0, 4), (6, 8), (9, 12), (13, 14), (15, 16), (18, 19), (21, 25), (26, 27), (28, 29), (30, 34), (39, 40), (41, 42), (43, 46), (51, 53), (54, 55)]","[['- Event B', 'probability', 'because there is', 'one', 'sequence', 'ing', ') - Event', '(', 'set', 'Event B and ', 'other', 'sequence', 'containing three', '- Event', '(']]",0.75
12.1_PE,"From less probable to most probable: B, C, A. Event B is very unlikely, because it is requiring a strict sequence of heads and tails, which can be calculated by 0.6^3 * 0.4^3 = 1.4%.  Event C is more likely than C, because it just requires 3 heads, which is less strict than B and includes B, it can be calculated by BinCoef(6, 3) * 0.6^3 * 0.4^3 = 27.7%. A is more likely than C, because it is less strict and having at least three heads as well includes C, having exactly three heads. It can be calculated as the sum for all k=3 to 6: BinCoeff(6, k) 0.6^k * 0.4^{6-k} = 81.1%.",PARTIAL_CORRECT,0.75,"[0.6023382544517517, 0.5242676138877869, 0.4985208511352539, 0.597110390663147, 0.6062213182449341, 0.6128495931625366]","[(49, 61), (64, 67), (69, 71), (107, 120), (122, 123), (183, 184)]","[['calculated by 0.6^3 * 0.4^3 =', 'Event C is', 'ly than', '3) * 0.6^3 * 0.4^3 = 27.7%', 'is', '*']]",0.75
12.1_PE,"Order: Event B, Event C, Event A  Reason: Actually , Event B is a subset of C, and C is a subset of A, so the order must be  B -> C -> A.               P(Event B) =  0.6 * 0.6 * 0.6 * 0.4 * 0.4 * 0.4 = 216/15625 = 0.013824               due to the equation of the binomial distribution               P(Event C) = 864/3125 = 0.27648               P(Event A) = 5213/625 = 0.8208",CORRECT,1.0,"[0.5412306785583496, 0.5534035563468933, 0.4681551158428192, 0.8545271158218384, 0.8569803833961487, 0.8461653590202332]","[(18, 20), (24, 25), (32, 35), (48, 98), (99, 110), (112, 117)]","[['B is', 'of', 'subset of', 'P(Event B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 * 0.4 = 216/15625 = 0.013824 due to the equation of the binomial distribution P(Event C) = 864/', '= 0.27648 P(Event A) =', '625 = 0.8208']]",0.75
12.1_PE,"Event A ist the most probable event, because there are many sequences that accomplish it. So all the probabilities of these sequences can be added to calculate the probability of Event A. Event C iss less proabable than A, because there are less sequences to accomplish ist than there are to accomplish A. For example A sequence with 4 H's would fulfill A but not C. But all of the sequences that fulfill C also would fulfill A. So C has the same probabilities that are beeing added to calculate the probability of A, but A has additional probabilities. Event B ist the least probable, because the only sequence that fulfills it, is HHHTTT. And since this sequence also fulfills A and C, the probability of the occurrence of this sequence is just one of the probabilities that are been added to calculate the probability of A and C.",CORRECT,1.0,"[0.5615187287330627, 0.49817973375320435, 0.47013789415359497, 0.5291444659233093, 0.5396251082420349, 0.5309138298034668]","[(25, 29), (30, 32), (33, 44), (45, 48), (121, 122), (134, 135), (137, 139), (191, 193), (194, 197), (198, 204), (205, 206), (208, 211), (213, 218), (219, 220), (221, 222)]","[['all the probabilities', 'these', 'sequences can be added to calculate the probabil', 'of Event A', 'has', '', 'probability', 'probability', 'the occurrence', 'this sequence is just one', 'the', 'that are been', 'to calculate the probabil', 'of', 'and']]",1.0
12.1_PE,"Event B Event C Event A  Event B: This is because the probability of seeing exactly in sequence HHHTTT is very low as there can be many different combinations such as HTHHTH, HTHTHT and others similar to that but for having the sequence HHHTTT there is only a single combination so the probability is very low.  Event C: Then the probability of seeing exactly three H's as the probability for showing up a head is 0.6 so there is more chances that a head shows up so the probability of head is more so exactly three H's probability is also low.  Event A: The probability of seeing head at least three is more because the probability of head is more 0.6 so the probability of a tail is 0.4 so we consider for this circumstance 0 T, 1T, 2T and 3T so summation of all these gives us the probability of at least three H's",PARTIAL_CORRECT,0.5,"[0.6871870756149292, 0.48965731263160706, 0.492037832736969, 0.5459415316581726, 0.5561909079551697, 0.553169310092926]","[(1, 3), (4, 5), (6, 7), (9, 10), (14, 16), (20, 21), (23, 24), (28, 30), (34, 35), (37, 39), (81, 113), (114, 116), (118, 121), (122, 144), (146, 177)]","[['B Event', 'Event', 'Event', 'This', 'probability', 'ly', 'sequence', 'very', 'be', 'combination', ""Event C: Then the probability of seeing exactly three H's as the probability for showing up a head is 0.6 so there"", 'more chance', 'a head', ""shows up so the probability of head is more so exactly three H's probability is also low"", 'A: The probability of seeing head at least three is more because the probability of head is more 0.6 so the probability of ']]",0.75
12.1_PE,"Event B = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 * 0.4 = 0.013824 Event C = P(k = 3) = 6 über 3 * (0.6)^3 * 0.4^3 = 0.27648 Event A = P(k >= 3) = 6 über 3 * (0.6)^3 * 0.4^3 + 6 über 4 * (0.6)^4 * 0.4^2 + 6 über 5 * (0.6)^5 * 0.4^1 + 6 über 6 * (0.6)^6 = 0.8208  From least to most probable = B,C,A",CORRECT,1.0,"[0.3833232820034027, 0.49320271611213684, 0.4874959886074066, 0.5683868527412415, 0.5598846077919006, 0.5569626688957214]","[(0, 126)]",[['Event B = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 * 0.4 = 0.013824 Event C = P(k = 3) = 6 über 3 * (0.6)^3 * 0.4^3 = 0.27648 Event A = P(k >= 3) = 6 über 3 * (0.6)^3 * 0.4^3 + 6 über 4 * (0.6)^4 * 0.4^2 + 6 über 5 * (0.6)^5 * 0.4^1 + 6 über 6 * (0.6)^6 = 0.8208 From least to most probable = B']],0.25
12.1_PE,"Event B as it is 0.6^3*0.04^3 ~ 0.0138 Event C as it is 6 over 3 * 0.6^3 * 0.4^3 ~0.276 Event A as it is 6 over 3 * 0.6^3 * 0.4^3 + 6 over 4 * 0.6^4 * 0.4^2 + 6 over 5 * 0.6^5 * 0.4^1 + 6 over 6 * 0.6^6 * 0.4^0 ~ 0.82 B is a specific sequence and c is different permutations of the same amout of hits so it B + the other combinations, A is all combinations to get 3 plus all the ones to get 4 5 and 6.",CORRECT,1.0,"[0.5115140080451965, 0.5440589189529419, 0.5347111225128174, 0.5257437825202942, 0.5188415050506592, 0.5151941776275635]","[(0, 96), (97, 99), (103, 104), (105, 107)]","[['Event B as it is 0.6^3*0.04^3 ~ 0.0138 Event C as it is 6 over 3 * 0.6^3 * 0.4^3 ~0.276 Event A as it is 6 over 3 * 0.6^3 * 0.4^3 + 6 over 4 * 0.6^4 * 0.4^2 + 6 over 5 * 0.6^5 * 0.4^1 + 6 over 6 * 0.6^6 * 0.4^0 ~ 0.82 B is a specific sequence and c', 'different per', 'same', 'out of']]",0.75
12.1_PE,"B: P(HHHTTT) = 0,6^3 * 0,4^3 = 0,013824  C: P(X = 3) = (6 über 3) * (0,6)^3 * (0,4)^3 = 20 * (27/125) * (8/125) = 0,27648  A: (most likely) P(X >=  3) = 1 - P (X less than equal to 2) = 1- P(X = 0) + P(X = 1) + P(X = 2) = 1  - ((6 über 0) * (0,6)^0 * (0,4)^6 + (6 über 1) * (0,6)^1 * (0,4)^5 + (6 über 2) * (0,6)^2 * (0,4)^4 = 1- (0,004096 + 0,03686 + 0,13824) =0,8208",CORRECT,1.0,"[0.3815992474555969, 0.47433170676231384, 0.46945443749427795, 0.5768438577651978, 0.5774097442626953, 0.5748870372772217]","[(0, 183)]","[['B: P(HHHTTT) = 0,6^3 * 0,4^3 = 0,013824 C: P(X = 3) = (6 über 3) * (0,6)^3 * (0,4)^3 = 20 * (27/125) * (8/125) = 0,27648 A: (most likely) P(X >= 3) = 1 - P (X less than equal to 2) = 1- P(X = 0) + P(X = 1) + P(X = 2) = 1 - ((6 über 0) * (0,6)^0 * (0,4)^6 + (6 über 1) * (0,6)^1 * (0,4)^5 + (6 über 2) * (0,6)^2 * (0,4)^4 = 1- (0,004096 + 0,03686 + 0,13824) =0,8208']]",0.25
2.4,"I would recommend using non-persistent CSMA for the following reasons: 1) The channel is expected to have a high load and non-persistent CSMA ensures a low number of collisions compared to other protocols and works thus better on high loads. 2) More systems will be added to the LAN in the future so scalability is very important. Non-Persistent CSMA is perfect in this case, because it requires no changes no matter how many systems are added in the channel.  One Potential weakness of using non-persistent CSMA is that the throughtput will be low if only a few Systems are trying to use the channel. It can happen that multiple stations wait, even when the channel is idle.",CORRECT,1.0,"[0.5945956707000732, 0.684748649597168, 0.7298640608787537, 0.6008173823356628, 0.57848060131073, 0.5485596060752869, 0.5430498123168945, 0.5385782718658447, 0.4970013499259949, 0.5722479820251465, 0.5574302077293396, 0.6024972796440125, 0.535995602607727, 0.5469588041305542, 0.5371783971786499, 0.5365839004516602]","[(0, 62), (84, 95), (116, 119), (120, 153)]","[['I would recommend using non-persistent CSMA for the following reasons: 1) The channel is expected to have a high load and non-persistent CSMA ensures a low number of collisions compared to other protocols and works thus better on high loads', 'Non-Persistent CSMA is perfect in this case', 'One Potential', 'weakness of using non-persistent CSMA is that the throughtput will be low if only a few Systems are trying to use the channel']]",1.0
2.4,"Non-persistent CSMA would be recommended in this case for 2 reasons. At first, CSMA avoid collision as much as possible by checking the channel before sending anything. Non-persistent CSMA provides the highest throughput in case the channel load is high. However, it has a potential weakness, the channel will be delayed longer than other MAC procedures. Other MAC procedures are not sufficient in terms of channel load and efficiency.",CORRECT,1.0,"[0.599709153175354, 0.6456180810928345, 0.6769336462020874, 0.5538966059684753, 0.552758514881134, 0.5220236778259277, 0.5368121266365051, 0.4985637664794922, 0.5218544602394104, 0.5015134811401367, 0.5537129044532776, 0.48730698227882385, 0.5535946488380432, 0.47196242213249207, 0.5237123370170593, 0.5310853123664856]","[(0, 16), (41, 60)]","[['Non-persistent CSMA would be recommended in this case for 2 reasons', 'Non-persistent CSMA provides the highest throughput in case the channel load is high']]",1.0
2.4,"The company should go with a standard CSMA/CD MAC procedure. The main reason for this is that it is possible to add stations easily to an existing network. Furthermore, it is a cost efficient MAC procedure which is a benefit due to the tight funding. A possible weakness is that the througput could be poor due to collisions due to high channel load.",CORRECT,1.0,"[0.6321383714675903, 0.5896007418632507, 0.59194415807724, 0.5638821721076965, 0.6696614027023315, 0.503560483455658, 0.5451180934906006, 0.5033039450645447, 0.4658055901527405, 0.48464909195899963, 0.5812969207763672, 0.4735414385795593, 0.47243213653564453, 0.46660637855529785, 0.5116810202598572, 0.5195263624191284]","[(0, 14)]",[['The company should go with a standard CSMA/CD MAC procedure']],1.0
2.4,"I'll choose CSMA/CD, because it costs efficient, it can detect the collision,but it has short frame.",PARTIAL_CORRECT,0.75,"[0.5941257476806641, 0.5234869718551636, 0.5153197050094604, 0.49164608120918274, 0.6988550424575806, 0.4362204074859619, 0.5164914727210999, 0.4085069000720978, 0.4108150899410248, 0.42964720726013184, 0.447343111038208, 0.4278089106082916, 0.44715967774391174, 0.41135427355766296, 0.41805869340896606, 0.4273693561553955]","[(0, 9)]","[[""I'll choose CSMA/CD""]]",1.0
2.4,"I would recommend the non-persistent CSMA. First, it has high efficiency and high throughput. From a rate of about 5 attempts per packet time, it beats most of the other systems in terms of throughput. Second, the normalized throughput increases with increasing attempts per packet time. This enables and even supports expandability. A potential weakness is the throughput at low attempt rates. In these cases the non-persistent CSMA is inefficient.",CORRECT,1.0,"[0.6447409987449646, 0.6712152361869812, 0.7409238815307617, 0.5788076519966125, 0.5438008308410645, 0.5115598440170288, 0.5752645134925842, 0.4960255026817322, 0.4627816677093506, 0.4944234788417816, 0.5258861780166626, 0.48389172554016113, 0.48595941066741943, 0.5496327877044678, 0.506104052066803, 0.5047274827957153]","[(0, 10), (100, 101), (102, 114)]","[['I would recommend the non-persistent CSMA', 'In', 'these cases the non-persistent CSMA is inefficient']]",0.75
2.4,"Based on the channel utilization slide of the lecture I would recommend the use of p-persistent CSMA (with a low value for p), because it has a high channel utilization that: (1) scales well for more systems sharing the channel (2) reduces the amount of collisions with the use of fixed time slots and medium sensing before sending (wait until medium is not busy)  One disadvantage is that it can not terminate the sending when a collision occurs, instead, it waits until a random time interval, senses the channel and retransmit the frame if the medium is not busy.",CORRECT,1.0,"[0.6102334856987, 0.6272482872009277, 0.5964813232421875, 0.5467157363891602, 0.5103122591972351, 0.5825331807136536, 0.553032636642456, 0.6010386943817139, 0.4926340579986572, 0.5619925260543823, 0.6296846270561218, 0.5813995003700256, 0.5678592920303345, 0.585572361946106, 0.6448699831962585, 0.5515084266662598]","[(0, 31), (84, 86)]","[['Based on the channel utilization slide of the lecture I would recommend the use of p-persistent CSMA (with a low value for p', 'medium is']]",1.0
2.4,"I would recommend CSMA/CD. The reason is that CSMA/CD checks the channel before and during sending frames. Also if the sending station detects a collision it immediately interrupts the transmission, which saves time, bandwidth and avoids wasteful transmissions. And because of the collision detection, its efficiency is better than the ""simple"" CSMAs. Furthermore, the advantage in contrast to coordinated access like Token Ring is if more and more systems are added it takes more time until a station that wants to send gets the token.  A weakness of CSMA/CD would be if more systems are added the performance decreases.",CORRECT,1.0,"[0.6433407664299011, 0.5589678883552551, 0.5491893887519836, 0.5291492342948914, 0.7367425560951233, 0.4990352988243103, 0.5631374716758728, 0.5293001532554626, 0.46874162554740906, 0.48468858003616333, 0.5354859828948975, 0.4667297601699829, 0.4674032926559448, 0.43700453639030457, 0.49514535069465637, 0.5041436553001404]","[(0, 8), (9, 29), (98, 121), (123, 124), (125, 126), (141, 164)]","[['I would recommend CSMA/CD', 'The reason is that CSMA/CD checks the channel before and during sending frames', 'the advantage in contrast to coordinated access like Token Ring is if more and more systems are added it', 'more', '', 'A weakness of CSMA/CD would be if more systems are added the performance decreases']]",1.0
2.4,"Not sure what is meant with ""... expect the channel load to be high compared to the hardware they can provide.""  Token Ring:  + Good throughput even if the utilization is high and scalable for the future growth of the company. - It can come to some delays because of the waiting time for the token.",CORRECT,1.0,"[0.6759195327758789, 0.5076441764831543, 0.5245097279548645, 0.5398603677749634, 0.47530597448349, 0.5537522435188293, 0.5598998665809631, 0.547918438911438, 0.5213052034378052, 0.5052343010902405, 0.5371266007423401, 0.5652496814727783, 0.5537194013595581, 0.690629780292511, 0.5495598316192627, 0.5424779057502747]","[(26, 52), (68, 69)]","[['Token Ring: + Good throughput even if the utilization is high and scalable for the future growth of the company', 'time']]",1.0
2.4,"I recommend the token ring, because (1) only one system can send at a time (the one with the token), so the channel load is reduced and (2) the token ring procedure is collision-free and works decentralized.  Potential weakness: the token can be lost if the system which is currently holding the token unexpectedly disconnects from the network.",PARTIAL_CORRECT,0.875,"[0.7890876531600952, 0.5130417346954346, 0.5282672047615051, 0.49322831630706787, 0.47778409719467163, 0.49236685037612915, 0.6574654579162598, 0.49767184257507324, 0.47870713472366333, 0.5064697265625, 0.5446356534957886, 0.4885748028755188, 0.4638552665710449, 0.45361289381980896, 0.49624013900756836, 0.5156523585319519]","[(0, 7), (28, 53)]","[['I recommend the token ring', 'so the channel load is reduced and (2) the token ring procedure is collision-free and works decentralized']]",1.0
2.4,"Token ring Advantages: still expandable, high usage, due to token ring: sending only possible when sender has ring; prevention of collisions, no random waiting time Disadvantage: more expansive than other MAC procedures",PARTIAL_CORRECT,0.75,"[0.7450460195541382, 0.5004157423973083, 0.515497088432312, 0.5026124119758606, 0.4481353163719177, 0.5313761234283447, 0.6247753500938416, 0.5844286680221558, 0.47252777218818665, 0.4961780607700348, 0.5286743640899658, 0.496563196182251, 0.45679745078086853, 0.4479086995124817, 0.5213148593902588, 0.5399014353752136]","[(0, 10), (15, 33)]","[['Token ring Advantages: still expandable', 'due to token ring: sending only possible when sender has ring']]",0.625
2.4,"Token Ring, +, Good throughput - even during increased utilization +, expandable  -, Delays because of waiting for token",PARTIAL_CORRECT,0.875,"[1.0, 0.5079636573791504, 0.4851023554801941, 0.5106340646743774, 0.5012410879135132, 0.4885038733482361, 0.7140818238258362, 0.4659314453601837, 0.46856600046157837, 0.4835343062877655, 0.5174698829650879, 0.45820707082748413, 0.4581572413444519, 0.4453260898590088, 0.48914942145347595, 0.4816664159297943]","[(0, 3)]",[['Token Ring']],1.0
2.4,I would recommend to use token ring for the following reasons: - As they expect the channel load to be high it is no advised to use CSMA/CD or a variant of it as that will cause a lot of collsions. Whereas token still performs reasonable well during increased utilization - The other requirement is that it should support 20 systems and should be expandable later. Token ring can support a maximum of 250 stations and can be extended with coax or optic fiber later on (for increased transmission rate).   One potential weakness is: - As their funding is tight CSMA could still be considered as it is a lot more cost efficient than token ring.,PARTIAL_CORRECT,0.875,"[0.7230479717254639, 0.6882020831108093, 0.6548267602920532, 0.658362627029419, 0.5897360444068909, 0.6065407395362854, 0.6165856719017029, 0.5526959896087646, 0.5258095860481262, 0.5651329159736633, 0.5884471535682678, 0.6457242965698242, 0.6108599901199341, 0.7135514616966248, 0.5984106659889221, 0.5277895927429199]","[(0, 58), (95, 129), (147, 149), (156, 157), (158, 159), (160, 161), (162, 170)]","[['I would recommend to use token ring for the following reasons: - As they expect the channel load to be high it is no advised to use CSMA/CD or a variant of it as that will cause a lot of collsions', 'Token ring can support a maximum of 250 stations and can be extended with coax or optic fiber later on (for increased transmission rate', 'CSMA', 'it', '', 'lot', 'cost efficient than token ring']]",1.0
2.4,"For this use case I would recommend CSMA/CD as MAC. The reasons for this are 1. that due to the high channel load collisions are expected and terminating the sending after an detected collision minimizes the time the channel is clogged up compared to CSMA without collision detection or even ALOHA. 2. CSMA is easier scalable than contention free access MACs since there is no need to authorize a sender in any form before sending, every sender checks the channel on its own and can send data when the channel is free. A potential weakness could be, depending on the access mode used by CSMA. Since currently the channel load is high compared to the hardware capacities using the non-persistent access mode with its higher efficiency could further strain the hardware. Although this could change in future when the system is expanded.",CORRECT,1.0,"[0.6168542504310608, 0.6063444018363953, 0.6111404299736023, 0.636603832244873, 0.6425672769546509, 0.5987803339958191, 0.535900890827179, 0.626223623752594, 0.567192018032074, 0.6106384992599487, 0.6594548225402832, 0.5615156292915344, 0.5535593628883362, 0.567879855632782, 0.6266324520111084, 0.6156390309333801]","[(0, 14), (77, 78), (79, 84), (86, 90)]","[['For this use case I would recommend CSMA/CD as MAC', 'is', 'easier scalable than', 'free access MACs']]",1.0
2.4,"CSMA/CD is recommended because 1) it provides better throughput than other MAC procedures in overall, especially when the number of systems sharing the same channel is expected to increase further. This is important because the channel load is high due to the limited provided hardware. Secondly, 2)  CSMA / CD saves time and bandwidth due to interrupting the transmission when a collision is detected (which is highly probable ). A potential weakness of CSMA \ CD's ability of collision detection depends on the maximum distance between the stations within the network. If the LAN network expands further there's a risk that CSMA / CD won't be possible anymore.",CORRECT,1.0,"[0.749153733253479, 0.5983197093009949, 0.5763517022132874, 0.552634060382843, 0.7621157765388489, 0.49288827180862427, 0.7289076447486877, 0.48205772042274475, 0.490727961063385, 0.5177594423294067, 0.52059006690979, 0.5505964159965515, 0.50823974609375, 0.6797584295272827, 0.5175536870956421, 0.5172233581542969]","[(0, 23), (67, 103), (105, 127), (128, 129), (130, 131), (135, 136), (142, 143), (156, 161), (163, 164), (165, 168)]","[['CSMA/CD is recommended because 1) it provides better throughput than other MAC procedures in overall', '2) CSMA / CD saves time and bandwidth due to interrupting the transmission when a collision is detected (which is highly probable', ""A potential weakness of CSMA \\ CD's ability of collision detection depends"", 'the', 'maximum', 'stations', 'the', 'CSMA / CD', 't', 'possible anymore']]",1.0
2.4,"I would recommend non-persistent CSMA. It does not need a precise timer which is great for a tight budget and it has a high efficiency at the cost of longer delays for single stations. It can be expanded pretty easily by just adding new stations. ALOHA is not a good choice here, because of its low channel usage and CSMA/CD needs a reliable collision checking while 1-persistent CSMA has a low throughput at higher load and p-persistent CSMA needs a precise timer.",CORRECT,1.0,"[0.6394948363304138, 0.6747860908508301, 0.7441709637641907, 0.5862559080123901, 0.5548931360244751, 0.5981120467185974, 0.567969024181366, 0.6234816312789917, 0.5293620824813843, 0.5532205700874329, 0.6459041833877563, 0.559868335723877, 0.5573391318321228, 0.6033276915550232, 0.6351153254508972, 0.5981137156486511]","[(0, 9), (80, 83), (86, 129)]","[['I would recommend non-persistent CSMA', 'its low channel', 'CSMA/CD needs a reliable collision checking while 1-persistent CSMA has a low throughput at higher load and p-persistent CSMA needs a precise timer']]",1.0
2.4,"CSMA/CD will be better. Because it's random access procedures and can add new systems more easily than coorinated ones. Using a collision detection will save more time and bandwidth than ALOHA and other CSMA procedure. The weakness is that the station in CSMA/CD procedure cannot send and receive frame at the same time, so  this procedure is only suitable for Half-duplex commnuication.",CORRECT,1.0,"[0.5728965997695923, 0.6078633666038513, 0.6070010662078857, 0.560646116733551, 0.7753943204879761, 0.5227923393249512, 0.5087375044822693, 0.5049536824226379, 0.48491907119750977, 0.4890861511230469, 0.5368843674659729, 0.5035400390625, 0.5074546337127686, 0.5071194767951965, 0.5306233763694763, 0.5004482865333557]","[(0, 7), (57, 58), (59, 81)]","[['CSMA/CD will be better', 'The', 'weakness is that the station in CSMA/CD procedure cannot send and receive frame at the same time']]",1.0
2.4,"CSMA/CD: Reasons: 1. there are 20 systems sharing the channel, so it should be Random Access. 2. stations know whether the channel is in use or not before trying to use it, so it should be With carrier sense  Potential weakness: 1. CSMA/CD has no maximum waiting time.",PARTIAL_CORRECT,0.375,"[0.6909091472625732, 0.5601275563240051, 0.5735026597976685, 0.5703428983688354, 0.681411862373352, 0.5028854012489319, 0.6996442079544067, 0.4768570065498352, 0.47440770268440247, 0.5338477492332458, 0.5241491198539734, 0.4797050356864929, 0.4984184801578522, 0.4705800414085388, 0.5027406811714172, 0.4983629882335663]","[(0, 9), (60, 71)]","[['CSMA/CD: Reasons:', 'CSMA/CD has no maximum waiting time']]",1.0
6.1_IPP,1. To support billions of end-systems 2. To reduce routing tables 3. To simplify protocol processing 4. To increase security 5. To support real time data traffic (quality of service) 6. To provide multicasting 7. To support mobility (roaming) 8. To be open for a change 9. To coexist with the existing protocol,CORRECT,1.0,"[0.7937748432159424, 0.7567229270935059, 0.7023918628692627, 0.6439021229743958, 0.7340978384017944, 0.5913020372390747, 0.6264952421188354, 0.7076236009597778, 0.6536893248558044, 0.6531013250350952]","[(1, 16), (17, 27), (28, 70)]","[['To support billions of end-systems 2. To reduce routing tables', 'To simplify protocol processing 4. To increase security', 'To support real time data traffic (quality of service) 6. To provide multicasting 7. To support mobility (roaming) 8. To be open for a change 9. To coexist with the existing protocol']]",1.0
6.1_IPP,more/larger addresses; multicasting; mobility; better security; simplification of the protocol,CORRECT,1.0,"[0.5770652294158936, 0.6427129507064819, 0.6356067657470703, 0.6844338774681091, 0.6238052248954773, 0.6791620254516602, 0.8098474740982056, 0.5987164974212646, 0.609249472618103, 0.6501724720001221]","[(0, 1), (2, 3), (4, 5), (6, 8), (9, 14), (15, 20)]","[['more', 'larger', 'addresses', 'multicasting', 'mobility; better security', 'simplification of the protocol']]",1.0
6.1_IPP,"Here are 5 objectives of the IPv6:   -To support billions of End systems (2^128), much more than IPv4 (2^32). -To simplify the protocol. For example, the header of the IPv6 is much simpler than the header of IPv4.  -To coexist with the older protocol. For example, thanks to tunneling, IPv6 can coexist with IPv4.  -To add more security in the network.  -To be open for eventual future evolutions (for example with the extension headers).",CORRECT,1.0,"[0.6362050175666809, 0.6484307646751404, 0.6441784501075745, 0.5927927494049072, 0.5793260335922241, 0.6028590202331543, 0.6130183935165405, 0.6298690438270569, 0.6922652125358582, 0.6442219018936157]","[(1, 3), (4, 24), (37, 42), (50, 51), (59, 60), (61, 62), (67, 77), (99, 102), (104, 105), (108, 113), (114, 126)]","[['are 5', 'objectives of the IPv6: -To support billions of End systems (2^128', 'To simplify the protocol', 'the', 'the', 'header', '-To coexist with the older protocol', 'To add more', 'the', '-To be open for', 'eventual future evolutions (for example with the extension headers']]",1.0
6.1_IPP,To support billions of end-systems To reduce routing tables To simplify protocol processing To increase security,CORRECT,1.0,"[0.7284179329872131, 0.72137850522995, 0.653937041759491, 0.5925871729850769, 0.5771550536155701, 0.5835116505622864, 0.5554149150848389, 0.5917394161224365, 0.6171183586120605, 0.5561211705207825]","[(0, 23)]",[['To support billions of end-systems To reduce routing tables To simplify protocol processing To increase security']],1.0
6.1_IPP,-support billions of end-systems (with specific addresses)  -reduce routing tables -simplify protocol processing  -increase security -support real time data traffic (QoS) -support mobility -be open for change in future with extension headers,CORRECT,1.0,"[0.6206184029579163, 0.6748070120811462, 0.6495416760444641, 0.5520588159561157, 0.6413000226020813, 0.5502691268920898, 0.5303748250007629, 0.6625286936759949, 0.6882924437522888, 0.5250696539878845]","[(0, 61)]",[['-support billions of end-systems (with specific addresses) -reduce routing tables -simplify protocol processing -increase security -support real time data traffic (QoS) -support mobility -be open for change in future with extension headers']],1.0
6.1_IPP,IPv6 is able to support billions of end-systems because it is using much longer adresses than IPv4. Since IPv4 is still very popular and the internet protocols version can't be switched instantly IPv6 have to coexist with other protocols. The extension headers used by IPv6 enable changes in the future. To simplify protocol processing IPv6 uses simplified headers.,CORRECT,1.0,"[0.6466638445854187, 0.6467487215995789, 0.7603731751441956, 0.5884565711021423, 0.5770885348320007, 0.5880869626998901, 0.6144731044769287, 0.6059601902961731, 0.6223607659339905, 0.7433912754058838]","[(0, 29), (58, 64), (83, 97)]","[['IPv6 is able to support billions of end-systems because it is using much longer adresses than IPv4', 'to coexist with other protocol', 'To simplify protocol processing IPv6 uses simplified headers']]",1.0
6.1_IPP,"1. Enlarge the available address pool:     By increasing the IP address length from 32 bits to 128 bits, a greater number of addresses can be assigned to end systems. 2. Simplify protocol processing:     Any previous shortcomings in IPv4 can be removed and optimized in IPv6. 3. Provide Multicasting:     Packets can now be sent to multiple destination addresses, which makes multicasting possible. 4. Better Security:     Security means are already integrated in IPv6.",CORRECT,1.0,"[0.544516384601593, 0.5174107551574707, 0.5854055285453796, 0.5876390337944031, 0.5784999132156372, 0.5824384689331055, 0.7060145735740662, 0.5433074831962585, 0.568840503692627, 0.5768543481826782]","[(43, 68), (70, 84), (98, 99)]","[['Simplify protocol processing: Any previous shortcomings in IPv4 can be removed and optimized in IPv6', 'Provide Multicasting: Packets can now be sent to multiple destination ', ':']]",1.0
6.1_IPP,-Provide more adresses -simplify protocol processing -be usable while IPv4 is still in use -increase security,CORRECT,1.0,"[0.486021488904953, 0.6148118376731873, 0.6496318578720093, 0.5671351552009583, 0.5297164916992188, 0.5234686732292175, 0.5139480233192444, 0.5913543105125427, 0.617153525352478, 0.5082913041114807]","[(0, 33)]",[['-Provide more adresses -simplify protocol processing -be usable while IPv4 is still in use -increase security']],1.0
10.1_TC,"In TCP there is a Sequence Number field to identify packets individually for reliability. There is no Sequence Number in UDP. The UDP header does not have an options field, while the TCP header does. In TCP there is an Advertised Window field for the Sliding Window Protocol for Flow Control. There is no Flow Control and therefore no Advertised Window field in UDP. In TCP there there is only a Data Offset field that specifies the header length. In UDP the whole Packet Length is transmitted.",CORRECT,1.0,"[0.6547195911407471, 0.7735680937767029, 0.7048254609107971, 0.7627674341201782, 0.6836522221565247, 0.7514059543609619, 0.7561299204826355, 0.6960836052894592, 0.6709281802177429, 0.7214118838310242, 0.6836190819740295]","[(0, 1), (2, 4), (8, 12), (15, 16), (17, 18), (33, 36), (38, 43), (44, 45), (50, 51), (52, 53), (56, 58), (59, 62), (63, 68), (69, 70), (98, 101), (102, 103), (104, 108), (109, 117)]","[['In', 'TCP there', 'Sequence Number field to', 'packet', 'individual', 'The UDP', 'does not have an', 'field', 'TCP', 'header', 'In ', 'there is an', 'Advertised Window field for', 'S', 'TCP there there', 'only', 'a Data Offset', 'that specifies the header length']]",1.0
10.1_TC,"TCP has a Error Control. So the users can be sure, that all packages have been transmitted in the right order. TCP has an included flow control, to assure, that the two clients don't get an overflow of packages. Mulitplexing: In UDP you only have on port at the receiver, where to send the data. For TCP you have to, one at each side. Connections are established and torn down in TCP, with the three-way-handshake. For UDP there is no guarantee the connection is established or closed.",INCORRECT,0.0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",[],[[]],0.875
10.1_TC,"In TCP the ports are at both ends. In TCP it has error control, flow control, congestion avoidance while in UDP has only checksum.",INCORRECT,0.0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",[],[[]],0.875
10.1_TC,"TCP-Header has the following information in his header that UDP not have:  Sequence Number (to identify the lost segments and maintain the sequencing in transmission),  Acknowledgment Number (to send a verification of received segments and to ask for the next seg-ments),  Urgent (Used to point any urgent data in segment), Flags, Window size (Used to set the number of segments that can be sent before waiting for a confirmation from the destination), Options",CORRECT,1.0,"[0.6291759610176086, 0.64225172996521, 0.5992605090141296, 0.6458515524864197, 0.604536235332489, 0.627414345741272, 0.6375290155410767, 0.6173079013824463, 0.6178181171417236, 0.6127984523773193, 0.620792031288147]","[(0, 18), (19, 20), (21, 23), (25, 29), (33, 34), (36, 37), (39, 40), (41, 43)]","[['TCP-Header has the following information in his header that UDP not have', '', 'Number (', 'y the lost segment', 'the', 'in', 'A', 'ment Number']]",0.75
10.1_TC,"A UDP header has a length of 8 bytes whereas a TCP header has a length of 20 bytes. A UDP header has a field for the packet length, unlike a TCP header. A UDP header doesn’t contain a sequence number, while a TCP header does. A UDP header neither contains an acknowledgement number but a TCP header has an extra field for that.",PARTIAL_CORRECT,0.875,"[0.6932763457298279, 0.7392149567604065, 0.6835655570030212, 0.7627674341201782, 0.6610087752342224, 0.7497109174728394, 0.7262493968009949, 0.6826998591423035, 0.7619397640228271, 0.7058881521224976, 0.7194433212280273]","[(0, 30), (31, 46), (50, 51), (52, 54), (56, 72), (76, 77), (80, 81), (84, 113)]","[['A UDP header has a length of 8 bytes whereas a TCP header has a length of 20 bytes', 'A UDP header has a field for the packet length', 'a', 'TCP ', 'A UDP header doesn’t contain a sequence number', 'a', 'header', 'A UDP header neither contains an acknowledgement number but a TCP header has an extra field for that']]",1.0
10.1_TC,"The UDP header is a short header (only contains Receiver Port, Packet Length and optional Sender Port, Checksum).  The header of the TCP is more complicated. Additionally to Sender Port, Receiver Port and Checksum, it has a sequence number (to identify the segment or the starting sequence number). It also has an acknowledgement number (which is needed i.a. for the connection setup). In the TCP header you can also set flags (like FIN for the disconnection). You can also add further information in the options field.",CORRECT,1.0,"[0.668240487575531, 0.7204797863960266, 0.6509005427360535, 0.7213096618652344, 0.6515243649482727, 0.7052001953125, 0.7012988924980164, 0.6343478560447693, 0.6906435489654541, 0.6521552801132202, 0.696705162525177]","[(0, 18), (86, 87), (88, 89), (109, 110), (111, 112)]","[['The UDP header is a short header (only contains Receiver Port', 'cknowledg', 'number', 'header', 'can']]",1.0
10.1_TC,"Some additional features which are present in the TCP header are: sequence number, acknowledgement number, options, urgent pointer and flags (the TCP header contains possible additional information and has protocol specific services). The UDP header has a size of 8 bytes, while the size of the TCP header is at least 20 bytes.",CORRECT,1.0,"[0.6698049306869507, 0.748261570930481, 0.6856983304023743, 0.7436165809631348, 0.7124481201171875, 0.7147846221923828, 0.7836802005767822, 0.6968588829040527, 0.6551728844642639, 0.6943800449371338, 0.6739531755447388]","[(0, 19), (21, 22), (23, 25), (28, 31), (32, 46), (47, 51), (52, 64), (67, 68), (71, 72), (73, 74)]","[['Some additional features which are present in the TCP header are: sequence number', 'a', 'ement number', 'urgent pointer', 'flags (the TCP header contains possible additional information', 'has protocol specific services', 'The UDP header has a size of 8 bytes', 'the', '', '']]",0.75
10.1_TC,"The UDP header includes the packet length (header + data) whereas the TCP header only includes the header length. The TCP header includes an acknowledgement number, advertised window and a sequence number which you do not find in the UDP header. The acknowledgement number states the sender which packets have arrived yet. The advertised window field gives the sender a feedback about how many more bytes the receiver will accept using the sliding window protocol. And the sequence number is necessary to be able to compute the packets in order.",CORRECT,1.0,"[0.6964604258537292, 0.8798303008079529, 0.8069817423820496, 0.7873511910438538, 0.7187219858169556, 0.7782310843467712, 0.7754634022712708, 0.6880888342857361, 0.6907760500907898, 0.7369142174720764, 0.6781426668167114]","[(0, 33), (34, 47), (49, 52), (54, 57), (58, 69), (73, 75)]","[['The UDP header includes the packet length (header + data) whereas the TCP header only includes the header length', 'The TCP header includes an acknowledgement number', 'ed window and', 'sequence number', 'which you do not find in the UDP header', 'cknowledgement']]",1.0
10.1_TC,"UDP: sender and receiver port, packet length, checksum, data TCP Headers are much longer than UDP Headers. There are some fields in the TCP header, which an UDP header doesn't contain: - Sequence Number - Acknowledge Number - Flags - Advertised window size - Options",CORRECT,1.0,"[0.6312049627304077, 0.7392149567604065, 0.6741524934768677, 0.7627674341201782, 0.6604816317558289, 0.7497109174728394, 0.7262493968009949, 0.6516339778900146, 0.6557840704917908, 0.672930896282196, 0.6441819667816162]","[(24, 26), (36, 37), (39, 42), (43, 44), (48, 85)]","[['are much', 'are', 'fields in the', 'TCP', ""which an UDP header doesn't contain: - Sequence Number - Acknowledge Number - Flags - Advertised window size - Options""]]",1.0
10.1_TC,"UDP-headers include: - source port - destination port - packet length - (optional to use) checksum Each of the fields is 16 Bit long (in sum 8 Bytes). UDP does not need much header-informations, since its a fast, connectionless protocol.  TCP-headers also include a checksum, source and destination port, but also much more information, like: - a sequence number - an acknowledgement number - different control flags - the data offset - the window size - an urgent pointer The much larger (min. 20 Byte) header is needed since TCP is a connection-oriented protocol, which sets more on reliability than speed.",CORRECT,1.0,"[0.658923864364624, 0.7693042159080505, 0.7038163542747498, 0.7389765381813049, 0.6669559478759766, 0.728212833404541, 0.7331031560897827, 0.668129563331604, 0.6836737394332886, 0.7200971841812134, 0.6398643255233765]","[(0, 3), (4, 5), (7, 8), (9, 10), (11, 12), (13, 14), (15, 18), (19, 20), (21, 22), (23, 24), (90, 92), (93, 131)]","[['UDP-', 'include', '-', 'port', '-', 'port', '- packet', 'length', '-', 'optional', 'like:', '- a sequence number - an acknowledgement number - different control flags - the data offset - the window size - an urgent pointer The']]",1.0
10.1_TC,"UDP: Header consists of three mandatory and one optional header. Source-port, destination-port, packet length are mandatory, checksum is optional and just calculated for the header  TCP: The checksum is calculated over header and user data, to ensure correct transmission. To ensure reliablity, the TCP-Header has additionally fields for a sequence number, the acknowledgement number and certain flags to reduce/avoid congestion and enable flow control.  The TCP header is more complex but ensures reliable transmission at the cost of speed and use of bandwidth. The UDP header just contains necessary information, is very fast but unreliable.",CORRECT,1.0,"[0.7097881436347961, 0.7598233819007874, 0.7029137015342712, 0.7682029008865356, 0.6934794187545776, 0.7366292476654053, 0.7332596778869629, 0.7164119482040405, 0.6644899249076843, 0.7115521430969238, 0.7215072512626648]","[(77, 83), (84, 94), (97, 98), (100, 101), (118, 126), (129, 130), (131, 133), (148, 152), (153, 154)]","[['the TCP-Header has', 'additionally fields for a sequence number', 'a', 'number', 'The TCP header is more complex', 's', 'able transmission', 'header just contains', 'necessary']]",1.0
10.1_TC,UDP headers do not include the followings: 1. sequence number 2. acknowledgement number 3. HL/RESV/Flags 4. advertised window 5. urgent pointer,CORRECT,1.0,"[0.6408529877662659, 0.7299528121948242, 0.6790390014648438, 0.7436165809631348, 0.67672199010849, 0.7147846221923828, 0.7836802005767822, 0.6567001342773438, 0.5960274934768677, 0.6772788763046265, 0.6345362663269043]","[(21, 22), (30, 31), (34, 37)]","[['number', 'advertis', 'urgent pointer']]",0.5
4.13,"Yes. When low utilization makes it more likely that the corresponding path is used, the load on this path rises and a state might occur where the routing path starts oscillating. This will lead to inconsistency of the routing table of sender and receiver.",CORRECT,1.0,"[0, 0]",[],[[]],0.75
4.13,"During the transmission of the data, the most favorable path could change, causing the second part of the data to take a different path.  If the second part of the data arrives at the destination first, the receiver must wait for the second part and arrange the two parts correctly again.",CORRECT,1.0,"[0, 0]",[],[[]],0.75
4.13,"Ja, da es zu sogenanntem Oszillierendem Verhalten kommen kann wenn die aktuelle Auslastung einer Leitung als Metrik benutzt wird, wodurch permanent die Route gewechselt wird. Dies passiert dadurch das ein Packet über Route X zu G geschickt wird, wodurch die Auslastung dieser Route steigt, was wiederum A dazu animiert eine andere Route zu wählen -> usw.",PARTIAL_CORRECT,0.75,"[0.6097245216369629, 0.593113124370575]","[(3, 4), (5, 6), (13, 23), (24, 26), (27, 30), (31, 35)]","[['es', 'so', 'm Verhalten kommen kann wenn die aktuelle Aus', 'einer', 'Leitung als Met', 'benutzt wird']]",0.75
4.13,One problem can be that the selected path utilized so that it will have to take another path. This path will be longer and will need more traffic.,CORRECT,1.0,"[0, 0]",[],[[]],0.75
4.13,"it certainly could, firstly, evaluating currend load without taking path transfer capacity into consideration could lead to misjudges. Secondly, avoiding certain busy path could lead to more hops, for example, a packet may take the path A-B-D-E-C-F-I-J-H-G, the packet may have avoid a few busy pathway but the total routing time could be longer.",CORRECT,1.0,"[0.5186442136764526, 0.5574760437011719]","[(13, 15), (19, 21)]","[['end load', 'path transfer']]",0.75
4.13,"Nein, denn dies führt zu Schwankungen, wenn es mehr als einen Pfad zwischen einem beliebigen Paar  von Endsystemen im Netzwerk gibt. Das bedeutet, dass das Routing instabil ist und es gibt uneffiziente Paketumlagerungen.",CORRECT,1.0,"[0.44791942834854126, 0.3649238646030426]","[(28, 29)]",[['von']],1.0
4.13,"I think the network topology is perfect. Because there so many paths between A and G, A-B-C-F-G, A-E-I-F-G etc. If some paths is fail, the data could through another path to send. But the problem is the right part is a little simple. It's not reliable and steady. It will be better, if there are more connection between G and the other nodes in right part, for example G-I, or G-j.",INCORRECT,0.0,"[0, 0]",[],[[]],0.75
4.13,"When there are multiple transmiisions, with load may lead to an oscillation of the load, i.e., if A wants to send a message to H under the condition that CF is overload and EI is avaliable, it will choose EI to transmit message, when CF is avaliable, it will choose CF. Hence, routing tables may oscillate frequently.",PARTIAL_CORRECT,0.75,"[0.3089749217033386, 0.7115878462791443]","[(10, 22)]",[['with load may lead to an oscillation of the load']],1.0
4.13,A könnte viele packets in einer kurzen Zeit senden und damit G (oder einen der Zwischenknoten) überlasten. Flow control muss also beachtet werden.,PARTIAL_CORRECT,0.5,"[0, 0]",[],[[]],0.75
4.13,It could be a problem that the packets are oscillating. So the packets will never arrive to G.,PARTIAL_CORRECT,0.5,"[0, 0]",[],[[]],0.75
4.13,"Using metrics like load or utilization can lead to 'oscillations' - which means that every time the load or utilization changes, the path taken will change, and the load and utilization will change while packets are being routed.",PARTIAL_CORRECT,0.75,"[0.27169787883758545, 0.6665244698524475]","[(0, 33)]","[[""Using metrics like load or utilization can lead to 'oscillations' - which means that every time the load or utilization changes""]]",1.0
4.13,"Yes, because the path load is then reduced for the chosen path and if  the receiver needs a certain path on which throughput is critical (e.g. G  to F), it can not use it properly, because the load is higher at the time of receiving. For example F to G is on the path  from A to G, then the load on F to G is reduced at the time of  receiving. If at the time of receiving the receiver G wants to send  critical data fast to F, it cannot use the path G to F properly and  needs maybe to elude to path G to H to F.",CORRECT,1.0,"[0, 0]",[],[[]],0.75
4.13,"Yes this strategy could lead to problems as it could lead to oscillations. If there are two possible path (i.e link CF or link EI) the choice of which path to take could flip around as choosing one path increases the load on that path and in return making the other path more favorable increasing the load on this other path, so the decision on which path to take could swap around repeatedly.",PARTIAL_CORRECT,0.75,"[0.587725818157196, 0.667900800704956]","[(0, 2), (5, 10), (11, 16), (17, 18)]","[['Yes this', 'could lead to problems as', 'could lead to ', 'ations']]",0.75
4.1_LM_v1.0,"The collision domain diameter will shrink, exactly by the same Factor Value we increase the speed of Transmission.  i.e .. when we have with Transmission rate of 10 Mbps and a Distance of 3000m, then we gonna have by Transmission rate of 100Mbps just a distance of 300m between the locations the speed ist possible.",CORRECT,1.0,"[0.6980776190757751, 0.44611942768096924, 0.4893057346343994]","[(0, 7), (8, 10)]","[['The collision domain diameter will', 'shrink']]",0.5
4.1_LM_v1.0,It is divided by the same factor of 10.,CORRECT,1.0,"[0.5138907432556152, 0.5552079081535339, 0.5511199831962585]","[(0, 9)]",[['It is divided by the same factor of']],1.0
4.1_LM_v1.0,"The collision domain diameter is reduced by the same factor, e.g. from 3km to 300m.",CORRECT,1.0,"[0.6895142197608948, 0.5078498721122742, 0.49805083870887756]","[(0, 13)]",[['The collision domain diameter is reduced by the same factor']],1.0
4.1_LM_v1.0,The collision domain diameter decreases by a factor of 10. That means the maximum distance between two locations on the network has to be 10 times smaller.,CORRECT,1.0,"[0.6948017477989197, 0.5756237506866455, 0.5127053260803223]","[(0, 15)]",[['The collision domain diameter decreases by a factor of 10.']],1.0
4.1_LM_v1.0,this “ collision domain diameter” will decrease by a factor of 10,CORRECT,1.0,"[0.6245946288108826, 0.5816112756729126, 0.5259642601013184]","[(0, 17)]",[['this “ collision domain diameter” will decrease by a factor of 10']],1.0
4.1_LM_v1.0,"The collision domain diameter will shrink with the same factor,so when the original speed is 10Mb/s and the collision domain diameter is 3km, an increase of the speed by the factor 10 to 100Mb/s will decrease the collision domain diameter to 300m.",CORRECT,1.0,"[0.6822136044502258, 0.6001518368721008, 0.5654571056365967]","[(0, 14), (21, 22), (30, 32), (38, 49), (50, 57), (58, 65)]","[['The collision domain diameter will shrink with the same factor', 'speed', 'ollision domain', 'an increase of the speed by the factor 10 to', 'Mb/s will decrease the', 'ollision domain diameter to 300m']]",1.0
4.1_LM_v1.0,the collision domain diameter have to shrink (divided by 10),CORRECT,1.0,"[0.6854650974273682, 0.5634480714797974, 0.5333265662193298]","[(0, 8), (9, 16)]","[['the collision domain diameter have to', 'shrink (divided by 10)']]",1.0
4.1_LM_v1.0,The diameter gets smaller by the same factor.,CORRECT,1.0,"[0.6116927862167358, 0.48885515332221985, 0.45236867666244507]","[(0, 11)]",[['The diameter gets smaller by the same factor']],1.0
4.1_LM_v1.0,The maximum distance has to shrink by the factor of 10 and the LAN also has to get smaller which is not possible or at some point not feasible.,CORRECT,1.0,"[0.590144157409668, 0.5670685768127441, 0.5111002326011658]","[(0, 28)]",[['The maximum distance has to shrink by the factor of 10 and the LAN also has to get smaller which is not possible']],1.0
4.1_LM_v1.0,The collision domain diameter decreases by the factor 10.,CORRECT,1.0,"[0.7198626399040222, 0.5480067729949951, 0.4994613826274872]","[(0, 13)]",[['The collision domain diameter decreases by the factor 10.']],1.0
4.1_LM_v1.0,"For doing so you have to shrink the maximal distance between two locations. In the given example the speed of the network should be increased by factor 10 from 10 Mb/s to 100 Mb/s. To achieve this without changing everything else, you have to reduce the collision domain diameter by factor 10.",CORRECT,1.0,"[0.6461975574493408, 0.6334890723228455, 0.5648162961006165]","[(27, 31), (32, 38), (39, 41), (57, 70)]","[['the network should be', 'creased by factor 10 from 10', '/s', 'you have to reduce the collision domain diameter by factor 10.']]",1.0
4.1_LM_v1.0,The collision domain diameter will decrease by a factor of 10.,CORRECT,1.0,"[0.6708670258522034, 0.5818659663200378, 0.515968382358551]","[(0, 15)]",[['The collision domain diameter will decrease by a factor of 10.']],1.0
4.1_LM_v1.0,The collision domain diameter will be reduced by the factor of 10.,CORRECT,1.0,"[0.6667553782463074, 0.6191073060035706, 0.5499979853630066]","[(0, 15)]",[['The collision domain diameter will be reduced by the factor of 10.']],1.0
4.1_LM_v1.0,"The collision domain diameter = 412m, i.e., ca. 300m instead of ca. 3000m",CORRECT,1.0,"[0.658051609992981, 0.4924088716506958, 0.5244471430778503]","[(0, 10)]",[['The collision domain diameter = 412m']],1.0
4.1_LM_v1.0,The sender must still be able to detect collisions during simultaneous transmission and must also not exceed the maximum network extension. The collision domain diameter for 100 Mb/s is 10 times smaller than for 10 Mb/s if you use CSMA/CD => 3000m to 300m.,CORRECT,1.0,"[0.6092314124107361, 0.5719705820083618, 0.6235557198524475]","[(29, 31), (32, 37), (39, 53), (58, 61), (62, 65)]","[['The c', 'domain diameter for 100', 's is 10 times smaller than for 10 Mb/s if you', '=> 3000', 'to 300m']]",1.0
4.1_LM_v1.0,"With a speed increased by a factor of 10, the collision domain diameter does decrease by a factor of 1/10 when using the same minimum packet size (e.g. 64 byte with Ethernet). This is because the send does finish much quicker (10 times as quick) while the time the electricity change needs to travel from sender to receiver and backwards remains the same.",CORRECT,1.0,"[0.6100648045539856, 0.5799093842506409, 0.6052863597869873]","[(0, 3), (4, 40), (42, 43), (45, 48)]","[['With a', 'increased by a factor of 10, the collision domain diameter does decrease by a factor of 1/10 when using the same minimum packet size (', 'g', 'byte with Ethernet']]",1.0
6.3,"1. Phase: Slow start 2. Phase: Congestion Avoidance In the first phase Congestion Window is doubled until there is a time out or the Slow Start Threshold is reached.  If there isn't any time out, the Congestion Window is incremeted by one. After a timeout the Congestion Window will be set to one and the ss_thresh willl be set to the half cwnd. This process continues at the begining Congestion Window size of 1.",CORRECT,1.0,"[0.5931359529495239, 0.643218457698822, 0.6747991442680359, 0.595680296421051, 0.7051275968551636]","[(1, 42), (53, 59), (60, 63), (68, 87), (88, 95)]","[['Phase: Slow start 2. Phase: Congestion Avoidance In the first phase Congestion Window is doubled until there is a time out or the Slow Start Threshold is reached', 'the Congestion Window is in', 'ted by one', 'timeout the Congestion Window will be set to one and the ss_thresh will', 'be set to the half cwn']]",0.75
6.3,"The congestion control consists of two phases: slow start and congestion avoidance. After the initialization of cwnd and ss_thresh, the slow start tries to discover the proper sending rate as quickly as possible by incrementing the cwnd by 1 for each acknowledged package. This is continued until the ss_thresh is reached or a packet gets lost, then the congestion avoidance starts. Now each time a congestion occurs, the ss_thresh is set to cwnd/2, the cwnd is reset to 1 and the slow-start is entered again.",PARTIAL_CORRECT,0.625,"[0.5900967717170715, 0.6847116351127625, 0.6800995469093323, 0.6622716188430786, 0.6882847547531128]","[(0, 20), (37, 38), (40, 42), (43, 45), (47, 49), (54, 60), (61, 71), (98, 107), (121, 122), (123, 124), (125, 129), (130, 131), (134, 151)]","[['The congestion control consists of two phases: slow start and congestion avoidance', 'the', 'tries', 'discover the', 'sending rate', 'by incrementing the cwn', 'by 1 for each acknowledged package', 'then the congestion avoidance starts', 's', '_', 'resh is set to', 'wn', 'the cwnd is reset to 1 and the slow-start is entered again']]",0.875
6.3,"The two phases are ""Slow start"" and ""Congestion Avoidance"". To make sure the network is not overloaded immediately, a TCP sender will start to send ""slowly"": First one segment, then as long as the segments get acknowleged double the rate each time, until the ss_thresh value is reached. This means after the first ACK is received, the sender will send two segments at once, then four, eight, etc until the ss_thresh value is reached or no ACK is received. If the ss_thresh value is reached (phase 2) the sender will increase the rate linearly by one each time. If a packet times out the ss_thresh value is set to 50% of the current rate and the cycle is repeated with phase 1.",PARTIAL_CORRECT,0.875,"[0.6058492064476013, 0.6893852949142456, 0.716397225856781, 0.5930848121643066, 0.6961154937744141]","[(0, 18), (71, 72), (78, 79), (121, 122), (123, 124), (136, 138), (139, 149), (151, 163), (164, 166)]","[['The two phases are ""Slow start"" and ""Congestion Avoidance', 'the', 'value', 'th', 'value', 'If the', 'ss_thresh value is reached', '2) the sender will increase the rate linearly by', 'each']]",0.75
6.3,"The first phase, slow start, will double cwnd every round-trip time by increasing it by 1 for each received ACK. When cwnd reaches ss_thresh, the congestion avoidance phase is entered. The congestion avoidance phase will additively increase cwnd by 1 every round-trip time.If congestion is encountered in any of the phases, ss_thresh is set to half the value of cwnd, cwnd is set to 1 and the slow start phase is entered.",CORRECT,1.0,"[0.5856353640556335, 0.6308495402336121, 0.7018929719924927, 0.6688734292984009, 0.6883339881896973]","[(10, 19), (20, 21), (22, 23), (48, 59), (60, 83), (103, 104), (116, 132)]","[['cwnd every round-trip time by', 'increas', 'it', 'the congestion avoidance phase is entered', 'The congestion avoidance phase will additively increase cwnd by 1 every round-trip time', 'th', 'cwnd is set to 1 and the slow start phase is entered']]",0.875
6.3,"Phase 1: Slow start (cwnd < ss_thresh) Phase 2: Congestion avoidance (cwnd >= ss_thresh) In Phase 1, cwnd is initialized to 1, then it increases exponentially until it reaches to ss_thresh. In Phase 2, cwnd increases one by one until it reaches the congestion, then new ss_thresh will be set to 2. Then cwnd is reset to 1 and phase starts.",PARTIAL_CORRECT,0.75,"[0.6113841533660889, 0.5396180748939514, 0.6249697208404541, 0.5966222286224365, 0.6378498077392578]","[(0, 39), (46, 47), (57, 63), (64, 69), (111, 113)]","[['Phase 1: Slow start (cwnd < ss_thresh) Phase 2: Congestion avoidance (cwnd >= ss_thresh) In Phase 1,', 'to', 'until it reaches to', 'ss_thresh', 'reset to']]",0.75
6.3,"The goal of the slow start phase is to quickly find a good sending rate.  For each ACK that is received, the cwnd is incremented, effectively doubling the cwnd within the round trip time. The congestion avoidance phase starts as soon as either a packet loss occured or cwnd is greater or equals to ss_thresh and the cwnd is only incremented once each round trip time.  When a timeout occures, ss_thresh is set to half of cwnd, cwnd is reset back to one and the slow start phase is entered again.",PARTIAL_CORRECT,0.75,"[0.8689485192298889, 0.5576838254928589, 0.6916600465774536, 0.6777982711791992, 0.6906925439834595]","[(0, 2), (4, 6), (9, 11), (12, 14), (18, 19), (53, 109), (134, 152)]","[['The goal', 'slow start', 'to quick', 'find ', 'rate', 'The congestion avoidance phase starts as soon as either a packet loss occured or cwnd is greater or equals to ss_thresh and the cwnd is only incremented once each round trip time', 'cwnd is reset back to one and the slow start phase is entered again']]",0.75
6.3,"Phase 1 - Slow Start: For each received ACk, the cwnd is increased by one until the ss_thresh (Threshold) is reached. Phase 2 - Congestion Control: During congestion avoidance the cwnd increases linear by one per RTT. If a timeout occurs (congestion) the ss_tresh is set to half of the current window size (cwnd) and cwnd is set to 1. Then slow start will begin again.",PARTIAL_CORRECT,0.875,"[0.6247941851615906, 0.5919485688209534, 0.6941568851470947, 0.6864447593688965, 0.7291978001594543]","[(0, 14), (16, 29), (30, 33), (35, 36), (37, 39), (40, 41), (42, 70), (71, 74), (75, 79), (80, 83), (84, 93), (94, 96), (97, 102), (103, 106), (107, 110), (115, 116)]","[['Phase 1 - Slow Start: For each received ACk', 'cwnd is increased by one until the s', '_thresh', 'hreshold', 'is ', 'ed', 'Phase 2 - Congestion Control: During congestion avoidance the cwnd increases linear by one per RTT', 'If a', 'timeout occurs (', 'gestion) the', 'ss_tresh is set to half', 'the current', 'size (cwnd', 'and cwn', 'is set to', 'will']]",0.875
6.3,Phase 1: Slow start Phase 2: congestion avoidance  Phase 1: start with a cwnd with one and double it every time a/the acknowledgment/s comes Until the ss-thresh(default: advertised window size) is reached or a congestion occurs.  Phase 2: if a congestion didn't occur increase cwnd by one each time. until a congestions occurs. Then set ss_tresh to the half of the cwnd right now. and repeat phase 1.,PARTIAL_CORRECT,0.875,"[0.5482370257377625, 0.5529114007949829, 0.7195351719856262, 0.6190327405929565, 0.6185004115104675]","[(0, 67), (69, 90)]","[['Phase 1: Slow start Phase 2: congestion avoidance Phase 1: start with a cwnd with one and double it every time a/the acknowledgment/s comes Until the ss-thresh(default: advertised window size) is reached or a congestion occurs', ""2: if a congestion didn't occur increase cwnd by one each time""]]",0.75
6.3,"The two phases of congestion control are the ""Slow Start"" and the ""Congestion Avoidance"" phase. In the slow start phase, the cwnd is incremented by one whenever a segment is acknowledged until the the cwnd reaches the value of ss_thresh or until packet loss occurs. In the congestion avoidance phase, the ss_thresh value is set to cwnd / 2 whenever congestion occurs. Afterwards, cwnd is reset to one in that phase.",PARTIAL_CORRECT,0.75,"[0.5451757311820984, 0.6528921127319336, 0.7808700203895569, 0.612429141998291, 0.7417955994606018]","[(0, 27), (29, 30), (35, 82), (83, 92), (93, 117)]","[['The two phases of congestion control are the ""Slow Start"" and the ""Congestion Avoidance"" phase', 'the', 'the cwnd is incremented by one whenever a segment is acknowledged until the the cwnd reaches the value of ss_thresh or until packet loss occurs', 'In the congestion avoidance phase', 'the ss_thresh value is set to cwnd / 2 whenever congestion occurs']]",0.75
6.3,1) Slow start cwnd verdoppelt sich nach jedem roundtrip (exponentiale Erhöhung) ss-thresh bleibt während slow start gleich.  2) Congestion Avoidance cwnd wird nach jedem roundtrip um MSS/cwnd erhöht (lineare Erhöhung) wenn congestion eintritt wird ss_tresh = cwnd/2 gesetzt und cwnd auf 1 gesetzt.,PARTIAL_CORRECT,0.875,"[0.5087550282478333, 0.5677471160888672, 0.6505084037780762, 0.6052284836769104, 0.7371604442596436]","[(0, 38), (39, 101)]","[['1) Slow start cwnd verdoppelt sich nach jedem roundtrip (exponentiale Erhöhung) ss-thresh bleibt während slow start gleich', '2) Congestion Avoidance cwnd wird nach jedem roundtrip um MSS/cwnd erhöht (lineare Erhöhung) wenn congestion eintritt wird ss_tresh = cwnd/2 gesetzt und cwnd auf 1 gesetzt']]",0.75
6.3,"Phase 1: Slow start(getting to equilibrium) Phase 2: Congestion Avoidance.  In phase 1, cwnd is < ss_thresh, and initialize cwnd=1,  and then it increases expotentially until reach the ss_thresh, in phase 2, cwnd>=ss_thresh, it increases slowly one by one until reaches the congestion, then set the new ss_thresh=cwnd/2, and reset the cwnd=1 and continue start from phase 1.",PARTIAL_CORRECT,0.875,"[0.6024872660636902, 0.6854897141456604, 0.5700584650039673, 0.5427666306495667, 0.61538165807724]","[(0, 18)]",[['Phase 1: Slow start(getting to equilibrium) Phase 2: Congestion Avoidance']],0.875
6.3,"Phase 1. Slow start -> discover proper sending rate When starting traffic on a new connecting or when experiencing an increase in traffic after congestion, the cwnd is initalized with one. Whenever a segment is acknowledged, the cwnd is incremented by one until eather ss_thresh is reached or packet loss is experienced. Phase 2: Congestion Avoidance After leaving the slow start phase (cwnd >(=) ss_thresh), cwnd may be incremented by 1 MSS every RTT to a maximum of SMSS. When a timeout occurs, meaning a congestion is experienced, ss_thresh is set to half the current cwnd. Cwnd is reset to one and slow-start is entered again.",PARTIAL_CORRECT,0.875,"[0.664524495601654, 0.6585177779197693, 0.8046160936355591, 0.649376392364502, 0.7103264331817627]","[(2, 34), (47, 57), (58, 89), (90, 119), (124, 125), (126, 129), (130, 131), (182, 184), (185, 186), (190, 191)]","[['Slow start -> discover proper sending rate When starting traffic on a new connecting or when experiencing an increase in traffic after congestion', 'Whenever a segment is acknowledged', 'the cwnd is incremented by one until eather ss_thresh is reached or packet loss is experienced', 'Phase 2: Congestion Avoidance After leaving the slow start phase (cwnd >(=) ss_thresh', 'be', 'ed by 1', 'MSS', 'to one', 'slow', 'entered']]",0.875
6.3,"Slow start: in Slow Start phase, cwnd is increased by one from 1 each time a segment is acknowledged i.e. cwnd is increased exponentially, but untill cwnd reaches ss_thresh (cwnd = ss_thresh) or when there is a packet loss. The increament is lowed down when cwnd >= ss_thresh i.e. cwnd is increased successively.  Congestion Avoidance. when congestion occurs, the size of ss_thresh is set to 50% of the current size of the congestion window i.e. ss_thresh = cwnd / 2 and cwnd is reset to 1. After that, Slow Start phase is entered.",PARTIAL_CORRECT,0.875,"[0.9129219651222229, 1.0000001192092896, 0.7565459609031677, 0.6417853832244873, 0.6888307332992554]","[(0, 8), (9, 34), (35, 40), (42, 44), (118, 123), (140, 142), (156, 157), (159, 160), (161, 168), (169, 170), (171, 172), (173, 175), (176, 177), (178, 179), (183, 186), (187, 190)]","[['Slow start: in Slow Start phase', 'cwnd is increased by one from 1 each time a segment is acknowledged i.e', 'cwnd is in', 'exponentially', 'Congestion Avoidance', 'is set', 'e', 's', '_thresh = cwn', '', '2', 'cwn', 'is', 'to', 'Slow Start ', 'is entered']]",0.75
6.3,"The two phases are called ""Slow start"" and ""Congestion avoidance"". When cwnd is smaller than ss_thresh the slow start phase is in action and cwnd is rapidly increased in a short amount of time by incrementing it by one each time a segment is acknowledged resulting in doubling the rate exponetially by doubling it every RTT. If cwnd is greater (or equal) than ss_thresh the congestion avoidance phase starts where as long as non-duplicate ACKs are received the cwnd may be increased by 1 MSS every RTT (AIMD). When a timeout occurs ss_thresh is set to cwnd/2 and cwnd is set to 1 and another slow start phase is entered resulting in alternating slow start and congestion avoidance phases.",PARTIAL_CORRECT,0.875,"[0.5700080990791321, 0.5996659398078918, 0.7332066297531128, 0.5633355379104614, 0.7102705240249634]","[(0, 20), (21, 85), (89, 91), (96, 153), (155, 156), (160, 214)]","[['The two phases are called ""Slow start"" and ""Congestion avoidance', 'When cwnd is smaller than ss_thresh the slow start phase is in action and cwnd is rapidly increased in a short amount of time by incrementing it by one each time a segment is acknowledged resulting in doubling the rate', 'doubling', 'If cwnd is greater (or equal) than ss_thresh the congestion avoidance phase starts where as long as non-duplicate ACKs are received the cwnd may be increased by 1 MSS every', '(', 'When a timeout occurs ss_thresh is set to cwnd/2 and cwnd is set to 1 and another slow start phase is entered resulting in alternating slow start and congestion avoidance phases']]",0.75
6.3,"phase 1:slow start  phase2: congestion avoidance In the slow start :Each time a segment is acknowledged,  increment cwnd by one (cwnd++) Continue until  reach ss_thresh or packet loss In the phase 2:Each time congestion occurs: ss_thresh is set to 50% of the current size of the congestion window:   ss_thresh = cwnd / 2 cwnd = 1",PARTIAL_CORRECT,0.75,"[0.5354828834533691, 0.5948455929756165, 0.6650875210762024, 0.5916441679000854, 0.7128974795341492]","[(0, 30), (31, 42), (43, 44), (47, 52), (53, 55), (56, 58), (59, 110)]","[['phase 1:slow start phase2: congestion avoidance In the slow start :Each time a segment is acknowledged', 'increment cwnd by one (cwnd++)', 'Continue', 'reach ss_', 'resh or', 'packet loss', 'the phase 2:Each time congestion occurs: ss_thresh is set to 50% of the current size of the congestion window: ss_thresh = cwnd / 2 cwnd = 1']]",0.75
6.3,"Phase 1: Slow Start The congestion window is increased exponentially, for every acknowledge the congestion window is increased by 1.  Phase 2: Congestion Avoidance The congestion window is increased by 1 for every round trip. If a congestion happens it is reset to 1 and the ss_thresh is halfed",PARTIAL_CORRECT,0.875,"[0.6326598525047302, 0.6888449192047119, 0.595035970211029, 0.5772262811660767, 0.5921305418014526]","[(0, 14), (15, 27), (28, 48), (49, 50), (52, 57), (58, 61), (69, 72)]","[['Phase 1: Slow Start The congestion window is increased exponentially', 'for every acknowledge the congestion window is increased by', 'Phase 2: Congestion Avoidance The congestion window is increased by 1 for every round trip', 'If', 'congestion happens it', 'reset to 1', 'is halfed']]",0.75
6.3,"cwnd = 1 MMS, ss_thresh = window size  Phase 1: Slow start cwnd < ss_thresh  Phase 2: Congestion Avoidance cwnd >= ss_thresh",PARTIAL_CORRECT,0.25,"[0.500942051410675, 0.5662326216697693, 0.5937706828117371, 0.5627428889274597, 0.6849424839019775]","[(12, 14), (15, 51)]","[['_th', '= window size Phase 1: Slow start cwnd < ss_thresh Phase 2: Congestion Avoidance cwnd >= ss_thresh']]",0.75
6.3,"Phase 1: Slow start:  -1- initialize cwnd =1   -2- Each time a segment is acknowledged, increment cwnd by one (cwnd++)   -3-  Continue until reach ss_thresh, packet loss  Phase 2: Congestion Avoidance:    Timeout = congestion   Each time congestion occurs: ss_thresh is set to 50% of the current size of the     congestion window:  ss_thresh = cwnd / 2 and  cwnd is reset to one: cwnd = 1     and  slow-start is entered",PARTIAL_CORRECT,0.75,"[0.5667799711227417, 0.552085280418396, 0.7609615921974182, 0.618745744228363, 0.7306890487670898]","[(0, 27), (29, 30), (31, 34), (54, 135)]","[['Phase 1: Slow start: -1- initialize cwnd =1 -2- Each time a segment is acknowledged', 'c', 'd by one', 'packet loss Phase 2: Congestion Avoidance: Timeout = congestion Each time congestion occurs: ss_thresh is set to 50% of the current size of the congestion window: ss_thresh = cwnd / 2 and cwnd is reset to one: cwnd = 1 and slow-start is entered']]",0.75
6.3,"Slow_start (cwnd <= ss_thresh)  cwnd is doubled each RTT which is equal to an increase by one for every acknowledged segment.  Phase continues until ss_thresh is reached or packet loss occured Congestion Avoidance (cwnd >= ss_thresh)Additive increase multiplicative decrease cwnd+1 per RTTIf timeout occurs ss_thresh = ss_thresh / 2, and cwnd = 1enter slow_start again",PARTIAL_CORRECT,0.875,"[0.7200201153755188, 0.6111142039299011, 0.7730929255485535, 0.615861713886261, 0.720223069190979]","[(0, 44), (45, 62), (63, 103), (104, 115), (116, 120), (128, 130), (131, 133)]","[['Slow_start (cwnd <= ss_thresh) cwnd is doubled each RTT which is equal to an increase by one for every acknowledged segment', 'Phase continues until ss_thresh is reached or ', 'loss occured Congestion Avoidance (cwnd >= ss_thresh)Additive increase multiplicative decrease cwnd+1 per RTTIf timeout occur', 'ss_thresh = ss', 'thresh /', 'enter slow', 'start again']]",0.75
6.3,"The phases are slow start and congestion avoidance. In the slow phase, the cwnd starts getting bigger in size, first slowly, then rapidly, until the ssthresh is reached. Once reached, the congestion control phase begins, where the cwnd slowly grows in size until a congestion occurs (timeout). In this case the slow start phase is entered again, the cwnd is reset and a new ssthresh is calculated (half of reached cwnd before timeout.",PARTIAL_CORRECT,0.875,"[0.6166679263114929, 0.6275005340576172, 0.6112274527549744, 0.5830217003822327, 0.6139142513275146]","[(0, 13), (60, 68), (92, 104)]","[['The phases are slow start and congestion avoidance', 'the congestion control phase begins', 'In this case the slow start phase is entered again']]",0.75
6.3,"2 phases: Slow start and congestion avoidance. In the slow start phase,  the cwnd is doubled from 1 to 2, 4, 8, after each ACK is received,  when cwnd >= ss_thresh, addiitively to 9, 10, 11... until timeout(congestion) or packet loss. When congestion occurs, ss_thresh is set to 50% of the current size of cwnd, cwnd is set to 1. Repeat again with slow start.",PARTIAL_CORRECT,0.875,"[0.6448125839233398, 0.6341310739517212, 0.6104418635368347, 0.5870357155799866, 0.6308060884475708]","[(0, 13), (14, 20)]","[['2 phases: Slow start and congestion avoidance', 'In the slow start phase']]",0.75
6.3,"Phase 1: Slow start (cwnd < ss_thresh) cwnd wird mit 1 initialisiert. Senderate, sprich cwnd, wird solange langsam erhöht, bis Aufstauung (congestion) entsteht. Phase 2: Congestion Avoidance (cwnd >= ss_thresh) ss-thresh wird auf cwnd/2 gesetzt, wobei cwnd der aktuellen Fenstergröße entspricht.Anschließend wird cwnd wieder auf 1 gesetzt und zur ""Slow start""-Phase übergegangen.",PARTIAL_CORRECT,0.625,"[0.6001123785972595, 0.606162965297699, 0.6757057309150696, 0.5775054097175598, 0.7511433959007263]","[(0, 24), (58, 92), (111, 114), (115, 131)]","[['Phase 1: Slow start (cwnd < ss_thresh) cwnd wird mit 1 initialisiert', 'Phase 2: Congestion Avoidance (cwnd >= ss_thresh) ss-thresh wird auf cwnd/2 gesetzt', 'wird cwn', 'wieder auf 1 gesetzt und zur ""Slow start""-Phase übergegangen']]",0.75
6.3,"The first phase (""slow start"") doubles the cwnd after every RTT until ss_thresh is reached. After that, the second phase (""congestion avoidance"") starts and furthermore only increases cwnd +1. Each time a congestion occurs, the ss_thresh is set to 50% of the current cwnd and cwnd is reset to 1, after which ""slow start"" phase is entered again.",PARTIAL_CORRECT,0.875,"[0.603770911693573, 0.5879615545272827, 0.7998477220535278, 0.6666865944862366, 0.6889358758926392]","[(0, 31), (35, 61), (72, 73), (75, 83), (84, 86), (89, 96), (97, 110)]","[['The first phase (""slow start"") doubles the cwnd after every RTT until ss_thresh is reached', 'the second phase (""congestion avoidance"") starts and furthermore only increases cwnd +1', 'the', 's_thresh is set to 50%', 'the current', 'and cwnd is reset to', 'after which ""slow start"" phase is entered again']]",0.875
6.3,"Phase 1: Slow start(getting to equilibrium) Phase 2: Congestion Avoidence  In both phases,when timeout occurs, ss_thresh is set to 50% of the current size of the congestion window, cwnd is reset to one, and slow-start is entered.And each time a segment is acknowleged , cwnd increase by one ,when cwnd=ss_thresh or packet loss , congestion avoidence is entered from slow-start .",PARTIAL_CORRECT,0.875,"[0.6354451179504395, 0.6395577192306519, 0.6484180688858032, 0.6153486967086792, 0.6673818826675415]","[(0, 23), (51, 54), (58, 65), (66, 67), (68, 70), (73, 74), (76, 78), (105, 118)]","[['Phase 1: Slow start(getting to equilibrium) Phase 2: Congestion Avoidence In both phases', 'wnd is', 'and slow-start is entered', 'And', 'each time', 'is', 'leged', 'congestion avoidence is entered from slow-start ']]",0.75
2.2_DLL,Synchronous transmission sends data in a sort of blocks or frames.  In Unsynchronous transmission the data is sended in form of byte and character. Start and  Stop-Bits are added.,CORRECT,1.0,"[0.6662514805793762, 0.7201769948005676]","[(0, 17), (18, 22), (23, 34)]","[['Synchronous transmission sends data in a sort of blocks or frames', 'In Unsynchronous', 'the data is sended in form of byte and character']]",1.0
2.2_DLL,"Asynchronous: Each character is bounded by a start bit and a stop bit -> simple and  inexpensive, but low transmission rates Synchronous: several characters pooled to frames, defined by SYN or flag -> more complex, but higher transmission rates",CORRECT,1.0,"[0.8650386929512024, 0.7617937922477722]","[(0, 25), (26, 43)]","[['Asynchronous: Each character is bounded by a start bit and a stop bit -> simple and inexpensive', 'but low transmission rates Synchronous: several characters pooled to frames']]",1.0
2.2_DLL,"asynchronous: characters are bounded with a start and stop bit, the transmission rate is low with up to 200bit/sec  synchronous: characters are pooled in frames with a SYN or flag - this has a higher transmission rate and is also more complex",CORRECT,1.0,"[0.8087199926376343, 0.6957082748413086]","[(0, 16), (17, 18), (19, 22), (23, 47), (48, 49)]","[['asynchronous: characters are bounded with a start and stop bit', 'the', 'rate is low', 'up to 200bit/sec synchronous: characters are pooled in frames with a SYN or flag -', 'has']]",1.0
2.2_DLL,In an asynchronous transmission each byte is sent separately and has a start and an end bit. In a synchronous transmission data is sent in frames which can lead to higher transmission rates but becomes more complex.,CORRECT,1.0,"[0.7769506573677063, 0.6361928582191467]","[(0, 24), (25, 53)]","[['In an asynchronous transmission each byte is sent separately and has a start and an end bit', 'In a synchronous transmission data is sent in frames which can lead to higher transmission rates but becomes more complex']]",1.0
2.2_DLL,Asynchronous transmission sends single bytes which are bounded by a start bit and an end bit.  In comparison synchronous transmission is able to send a block of bytes (Frame). These blocks are defined by SYN or flag.,CORRECT,1.0,"[0.8214550018310547, 0.6842581629753113]","[(0, 22), (23, 42)]","[['Asynchronous transmission sends single bytes which are bounded by a start bit and an end bit', 'In comparison synchronous transmission is able to send a block of bytes (Frame']]",1.0
2.2_DLL,"In the asynchronous transmission mode, there is a start bit and a stop bit for every single character (byte) [ START | BYTE | STOP ].The synchronous transmission mode packs several bytes into a frame and a synchronisation flag is used to mark the begin and end of a new frame [ SYN | BYTE 1 | ... | BYTE n | SYN ].",CORRECT,1.0,"[0.7786928415298462, 0.6631331443786621]","[(0, 4), (5, 8), (9, 26), (27, 29), (31, 32), (33, 34), (37, 71)]","[['In the a', 'ous transmission mode', 'there is a start bit and a stop bit for every single character (byte', '[ START', 'YTE', '', 'The synchronous transmission mode packs several bytes into a frame and a synchronisation flag is used to mark the begin and end of a new frame [']]",1.0
2.2_DLL,"Asynchronous mode transmits characters separately and marks their boundary by using a start and stop bit, while synchronous mode groups multiple characters into frames where bounds are specified using control flags or a length field or invalid symbols of the physical layer. Asynchronous mode is simpler, but it's also slower than synchronous mode due to the increased overhead.",CORRECT,1.0,"[0.7457078099250793, 0.6411511301994324]","[(0, 26), (29, 30), (33, 34), (35, 37), (39, 40), (41, 49), (50, 51), (52, 55), (56, 59)]","[['Asynchronous mode transmits characters separately and marks their boundary by using a start and stop bit', 'synchron', 'multiple', 'into ', 'where', 'bounds are specified using control ', 'or', 'a length', 'or invalid symbol']]",1.0
2.2_DLL,"During asynchronous transmission each Byte of the transmission is bounded by a start and a stop bit. This makes it possible to transfer data at all time. With synchronus transmission the sender has to wait for the reciever until he is ready, so a transmission has to start with SYN flags. After the SYN Flags all Bytes of the data can be transferred without being bounded with start and stop bits. This leads to a higher transmittion rate than with the asynchronus transmission.",CORRECT,1.0,"[0.8017628788948059, 0.6250863671302795]","[(0, 26), (42, 53), (54, 58)]","[['During asynchronous transmission each Byte of the transmission is bounded by a start and a stop bit', 'transmission the sender has to wait for the reciever', 'until he is ']]",1.0
2.2_DLL,"The difference is that in synchronous transmission mode the information which is to be transmitted is packed in frames, whereas in asynchronous transmission mode a single character represents a frame, which is bounded by a so-called start bit and a stop bit. So the asynchronous transmission have low transmission rates but is simple and inexpensive, in contrast the synchronous transmission is more complex but has higher transmission rates.",CORRECT,1.0,"[0.7597385048866272, 0.6830400228500366]","[(0, 24), (26, 29), (30, 44), (45, 63), (65, 68), (69, 76), (77, 79), (86, 87), (91, 92)]","[['The difference is that in synchronous transmission mode the information which is to be transmitted is packed in frames', 'whereas in', 'asynchronous transmission mode a single character represents a frame', 'which is bounded by a so-called start bit and a stop bit', 'the a', 'ous transmission have low transmission rates', 'is simple', 'synchron', 'complex']]",1.0
2.2_DLL,"asynchronous: byte- and block-oriented synchronous: character-, count- and bit-oriented",INCORRECT,0.0,"[0.6257971525192261, 0.5867272615432739]","[(0, 17), (23, 24)]","[['asynchronous: byte- and block-oriented synchronous: character-', 'oriented']]",1.0
2.2_DLL,"While in asynchronous transmission every character is bounded by a start and a end bit, in synchronous transmission several character are bound to frames, these frames are bound by SYN or flag. The asynchronous transmission is simple and inexpensive, but has a low transmission rate, up to 200 bit/sec, while the synchronous transmission has a higher transmission rate, but is more complex.",CORRECT,1.0,"[0.8317456245422363, 0.6881356239318848]","[(0, 22), (23, 36)]","[['While in asynchronous transmission every character is bounded by a start and a end bit', 'in synchronous transmission several character are bound to frames']]",1.0
2.2_DLL,"On the asynchronous transmission, we transmit character independently from each other. Each byte is delimited by a start bit and a stop bit.   One the Synchronous transmission, whereas, several characters are regrouped in a ""frame"".   The Synchronous transmission is generally more complex but faster.",CORRECT,1.0,"[0.8385213613510132, 0.6033729314804077]","[(0, 2), (3, 5), (19, 34), (35, 37), (67, 69)]","[['On the', 'asynchron', 'Each byte is delimited by a start bit and a stop bit', 'One the', 'more complex']]",1.0
12.3_PE,"It’s not realistic, because in the Real-World the high traffic in the internet depends often on the day and the time of the day. For example, weekend or holiday and morning, afternoon or evening. So, it can be that in the morning there are many zeros in the time slots and the evening there much ones, because for example everyone is watching Netflix in the end of working day or is doing some other internet things. So there can be more than one on’s in time interval delta t.",PARTIAL_CORRECT,0.75,"[0, 0]",[],[[]],0.875
12.3_PE,This assumption does not hold in real internet traffic. In case of a video streaming service for example the packages are send in big burst. So the arrival of the first package does indicate the arrival of more packages and the more packages are received in a short time the more likely it gets that no more package will arrive for some time because the buffer for the video stream is full and the streaming service stops sending.,CORRECT,1.0,"[0.6546995639801025, 0.28044503927230835]","[(39, 40)]",[['package']],0.875
12.3_PE,This assumption does not hold true for the internet as when someone uses the internet he will continue using it for a certain time and not just have a single request and then nothing for a while. Also a lot of traffic is in a burst like nature so some requests until a certain buffer is filled and then again when it is somewhat deplenished. So in general the previous state or states can hold information for future states.,CORRECT,1.0,"[0, 0]",[],[[]],0.875
12.3_PE,This assumption can not hold for real internet traffic because the underlying assumption of independence is false. Over a higher timescale the behavior of the user is undergoing changes. For example a user checks his mails in the morning for which packets arrive but then he goes to work and in that time no packets arrive. Another example disproving the assumption of independence is the on/off bursty traffic while watching videos. For some time packets arrive continuously and then if the buffer is full no packets arrive until the buffer is empty again and needs to be refilled.,PARTIAL_CORRECT,0.75,"[0, 0]",[],[[]],0.875
12.3_PE,"No, since the real internet traffic is complicated and there are dynamic behaviors of real-world service. For example, real internet TCP traffic has high burstiness and exhibits long range dependence properties at large time-scales. The arrivals for each interval are not independent and there are dependence and correlation of the traffic arrival process in the internet. Meanwhile, the real internet traffic has self-similar characteristics, thus, this assumption cannot hold for real internet traffic.",CORRECT,1.0,"[0, 0]",[],[[]],0.875
12.3_PE,"Yes the assumption that time between packet arrivals are independent holds true for real internet traffic. Packets transferred between one node to another suffer from various delays such as propagation delay, processing delay, queuing delay, transmission delay etc. Each of these are independent of each other. Hence the arrival interval of packets which is a function of these delays is also independent.",INCORRECT,0.0,"[0, 0]",[],[[]],0.875
12.3_PE,"No, because sometimes many users want to access the server at the same time, while at other times, only few request the server. For example a livestream of a football match: everybody sends requests to the server at kickoff, but only few do after the game (to watch the highlights). That means that the arrivals are not independent. They can depend on other events.",PARTIAL_CORRECT,0.75,"[0, 0]",[],[[]],0.875
12.3_PE,"No this assumption does not hold for real internet traffic. Internet traffic is often very bursty, e.g. if we load a website we need to load a lot of resources at once, while we won't load nearly as much if we just look at the website. This means the probability that traffic arrives, if traffic arrived in the previous interval is greater than if there was no traffic in the previous interval.",CORRECT,1.0,"[0, 0]",[],[[]],0.875
12.3_PE,"No, this assumption of the arrivals being “memoryless” does not hold for real internet traffic.  If Δt = 1ms, for example, that means every of these time intervals has to be considered independent from each other. So in each of these intervals it is a “coin flip” whether data is sent or not.  Obviously this is not true for real internet traffic because while streaming a movie or playing an online game, for example, the arrivals are connected and dependent on each other.",CORRECT,1.0,"[0, 0]",[],[[]],0.875
12.3_PE,"No, this assumption will most likely not hold true for real internet traffic. This has multiple reasons:  Packets on the internet are grouped into frames for sending, making lone packets being sent separately rather unlikely.   The nature of data transfer on the internet also makes lone packets very unlikely. When making a request for data through the internet (for example loading a web page), the response includes a lot of data (markup, text, images) which are all sent in a short amount of time, and after the page has been loaded the user will most likely spend some time browsing the page before making another request.   Therefore we cannot treat arriving packets as independent from one another, because there is a very high chance that an arriving packet is related to the previous packet.",CORRECT,1.0,"[0, 0]",[],[[]],0.875
12.3_PE,"No, it is not true for real time internet traffic. The arrivals of packet is not independent on time interval as while loading or streaming something the next video is loaded automatically if the previous video is about to end.eg. youtube,netflix etc.. this proves that it is not independent of the time interval.",PARTIAL_CORRECT,0.75,"[0.6008219122886658, 0.41299957036972046]","[(21, 23), (24, 25), (32, 33)]","[['independent on', 'interval', 'something']]",0.875
12.3_PE,This assumption does not hold for real internet traffic. Real traffic is for example dependent on the daytime. Furthermore the application is relevant. Some might use bursty traffic.,PARTIAL_CORRECT,0.75,"[0, 0]",[],[[]],0.875
12.3_PE,"This assumption is a simplification, that makes it easier to work and calculate with. In reality, there is seldomly only one packet is send and then nothing happens afterwards, but communication consists of multiple packets. Therefore, if there is one packet, then it is very propable, that there will be a lot following packets. I.E. if someone is streaming in the afternoon and causing a number of packets, the propability of the packets will concentrate on one timeframe. And this (and the behaviour of the other participants) causes the propability for a larger timeframe like the morning to be different then in the evening.",CORRECT,1.0,"[0.33699074387550354, 0.5628786087036133]","[(118, 119)]",[['packet']],0.875
12.3_PE,"Yes. Because Internet traffic can be also modeled as a sequence of arrivals of discrete entities, such as packets, cells, etc. Mathematically, this leads to the usage of two equivalent representations: counting processes and interarrival time processes.",INCORRECT,0.0,"[0, 0]",[],[[]],0.875
10.3_TC,"At the start, the bridges table is empty, it uses flooding for an unknown destination. During the backward learning process, the bridge works in promiscuous mode as it receives any frame on any of its LANs, then the bridge receives frames with sources address Q on LAN L, Q can be reached over L and therefore create table entry accordingly.",PARTIAL_CORRECT,0.5,"[0.6612415313720703, 0.6922807097434998, 0.5654498338699341, 0.5703571438789368, 0.5599721670150757, 0.5106684565544128, 0.5733814835548401]","[(32, 52), (53, 68)]","[['the bridge works in promiscuous mode as it receives any frame on any of its LANs', 'then the bridge receives frames with sources address Q on LAN L']]",0.625
10.3_TC,"The bridge table stores the information, which station it can reach over which LAN (output line). The bridge works in the promiscuous mode, which means that it receives every frame of each connected LAN and during the backwards learning phase when the bridge receives frames with a source address S on a LAN L it ""learns"" that S can be reached over L and creates a table entry accordingly. These entries are associated with timestamps and updated when new frames were received from the source (e.g. S). To forward a frame the bridge will look at the source and destination LANs and drop the frame if they're identical (and therefore prevent unnecessary traffic) but if they are different the bridge can look up in the table to which LAN the frame has to be rerouted. Only if the destination is unknown the network will be flooded with the frame. Because the bridge is not visible as such for the other components of the network, these other components are simplified and they don't have to deal with the forwarding process.",PARTIAL_CORRECT,0.75,"[0.6005183458328247, 0.6341627240180969, 0.5283142924308777, 0.5078662633895874, 0.5221235156059265, 0.5349307656288147, 0.5486584305763245]","[(34, 35), (36, 101), (136, 137), (138, 140), (141, 142), (144, 145), (150, 151), (152, 153), (177, 178)]","[['which', 'means that it receives every frame of each connected LAN and during the backwards learning phase when the bridge receives frames with a source address S on a LAN L it ""learns"" that S can be reached over L and creates a table entry accordingly', '', 'frame the', 'will', 'the', 'and', 'the', 'the']]",0.625
10.3_TC,table holds infromation that a certain address can be reached by a certain LAN. During backwards learning the bridge updates its table by the incoming traffic knowing that the source of the received packet is reachable over the LAN form where the packet came. Look if the address is in the table if yes then send it to the LAN over which it is reachable if not use flooding. No longer need to flood if the path is known. Another one would be that it is a rather simple approach.,CORRECT,1.0,"[0.6233367919921875, 0.6577023267745972, 0.5416287183761597, 0.684021532535553, 0.5367496013641357, 0.5635897517204285, 0.5580020546913147]","[(24, 25), (26, 29), (30, 37), (38, 65)]","[['Dur', 'backwards learning', 'bridge updates its table by the', 'coming traffic knowing that the source of the received packet is reachable over the LAN form where the packet came']]",1.0
10.3_TC,"The table holds the routing entries to forward packets to their destination. The table is initially empty and will be filled with the information of routes during the backwards learning phase. The table entries will be scanned and updated when receiving frames, thus it will adapt to changes in topology, which is a benefit.",INCORRECT,0.0,"[0.6657641530036926, 0.6731067299842834, 0.5372037291526794, 0.5724741816520691, 0.615071713924408, 0.5045762658119202, 0.6002352833747864]","[(2, 3), (46, 48), (49, 63)]","[['', 'The table', 'entries will be scanned and updated when receiving frames']]",0.625
10.3_TC,"The invisible bridge contains a table which holds information about which address can be reached in which of the connected LANs around it. This table is initially empty, but then filled during the process of backward learning - when the bridge receives a packet from a LAN L with the sender address A, it can be concluded that A is part of the LAN L and therefore routable on this network. As the name clearly states, the bridge in the network is transparent as such, instead it is just addressed with the network receiver address by any senders in one LAN, so that it then can use its table to figure out in which destination-LAN the package should be sent. So one can conclude that the table prevents flooding from the transparent bridge and therefore unnecessary traffic. The other overall feature of the usage of a transparent bridge is the decreased complexity of transmission for all nodes in the combined LANs, because they can just sent packages to all nodes in all connected LANs without having to deal with the routing between the LANs by itselves.",PARTIAL_CORRECT,0.75,"[0.6366654634475708, 0.7031545042991638, 0.5154463052749634, 0.5194286704063416, 0.5307596921920776, 0.5354581475257874, 0.5586220622062683]","[(57, 58), (59, 77), (200, 201), (206, 208), (210, 211)]","[['', 'the bridge receives a packet from a LAN L with the sender address', '', 'decreased', 'of']]",1.0
10.3_TC,"All bridges inspect all the traffic and build up tables (bridge tables), these tables hold information to manage the traffic and each entry contains an address and the LAN that leads to that address.  The bridge table is initially empty and uses flooding for an unknown destination.  During the backward learning phase (Learning process) the bridge works in promiscuous mode and receives any frame on any of its LANs. If the bridge receives frames with source address Q on LAN L and Q can be reached over L, then it will create table entry accordingly.  These tables are adapted to changes in topology. Each entry is associated with a timestamp (frame arrival time), and the timestamp of an entry (Z, LAN, TS) is updated when the frame received from Z.  The table scanned periodically and old entries purged if no update for some time, usually several minutes (e.g., because the system moved and reinserted at a different position, or flooding was used if the machine was quiet for some minutes).  The main benefit of bridge tables in the forwarding process is to increase reliability by connecting LANs via VARIOUS bridges in parallel.",PARTIAL_CORRECT,0.75,"[0.6517512798309326, 0.656335175037384, 0.5686620473861694, 0.5920925140380859, 0.5549018979072571, 0.5646597146987915, 0.5568383932113647]","[(65, 96), (97, 120), (253, 254), (255, 259), (260, 263), (264, 267), (268, 271), (274, 276)]","[['During the backward learning phase (Learning process) the bridge works in promiscuous mode and receives any frame on any of its LANs', 'If the bridge receives frames with source address Q on LAN L and Q can be reached over L', 'of', 'tables in the', 'ing process is', 'increase reli', 'by connecting', 'VARIOUS']]",0.5
10.3_TC,"The bridge table contains mappings of station to the output line that has to be used to reach the station. The bridge uses promiscuous mode to observe the sent frames and if a frame from a specific source station is sent over a connected LAN the bridge knows that this station can be reached over that LAN and the bridge table is updated. In the forwarding process the destination is looked up in the bridge table and the frame is rerouted to the correct output LAN, if it differs from the current LAN. If the station is not found, flooding is used. A benefit of this setup is that the stations can transparently reach other stations in a different network like they were in the same.",PARTIAL_CORRECT,0.75,"[0.6123717427253723, 0.6214607954025269, 0.58653724193573, 0.6156368851661682, 0.5401919484138489, 0.5288322567939758, 0.5255857706069946]","[(24, 79), (81, 96), (97, 107)]","[['The bridge uses promiscuous mode to observe the sent frames and if a frame from a specific source station is sent over a connected LAN the bridge knows that this station can be reached over that LAN and the bridge table is updated', 'the forwarding process the destination is looked up in the bridge table and', 'frame is rerouted to the correct output LAN']]",0.75
10.3_TC,"This bridge table has MAC addresses and ports of bridge in it. At the very beginning, the table is empty, then for example, bridge sees that a frame on port 1 coming from source address A, it knows that A must be reachable via port 1, then it makes an entry in its table.  Bridge receives a frame, then it looks up the corresponding destination on its table, if the destination is found, and source address and the destination is identical, the frame would be dropped, if not identical, the bridge will forward this frame to its destination. But if the destination is not found, it will flood.  This table increases the reliability.",PARTIAL_CORRECT,0.75,"[0.6257808804512024, 0.7867620587348938, 0.515728771686554, 0.5085932612419128, 0.5572698712348938, 0.4746890664100647, 0.5743546485900879]","[(71, 77)]",[['Bridge receives a frame']],0.75
2.3_DLL_v1.1,Both sides must send data to use piggybacking to be able to attach ACKs to data frames otherwise the sender will assume a frame loss.,INCORRECT,0.0,"[0.4390409588813782, 0.39472007751464844]","[(5, 6), (18, 19)]","[['data', '']]",0.625
2.3_DLL_v1.1,"Need to know the initial sequence number, aswell as the next sequence number and acknowledgement.",INCORRECT,0.0,"[0, 0]",[],[[]],0.625
2.3_DLL_v1.1,"The connection has to be duplex and both sides have to have data to send (Otherwise the frame is 0 characters + the acknowledgement, which would just be a confirmation and no piggybacking).",CORRECT,1.0,"[0.6117207407951355, 0.5756815075874329]","[(0, 17), (19, 22), (25, 26), (28, 30)]","[['The connection has to be duplex and both sides have to have data to send (', 'the frame is', 'the', 'cknowledgement']]",0.875
2.3_DLL_v1.1,"To use the piggybacking extension to the sliding window protocol, we have to be in a duplex mode.",CORRECT,1.0,"[0.5882004499435425, 0.6273162364959717]","[(16, 26)]",[['we have to be in a duplex mode']],0.875
2.3_DLL_v1.1,A receiver of a data frame has to send data frames the ACKs are piggybacked onto at a rate that is high enough so that the sender doesn't have to wait for too long for the ACKs to arrive. Otherwise a timeout might occur and the sender sends the frame again.,PARTIAL_CORRECT,0.5,"[0.5761568546295166, 0.6358998417854309]","[(0, 1), (5, 8), (9, 10), (11, 13), (14, 15), (22, 23)]","[['A', 'a data frame', 'to', 'data ', 'the', 'ed']]",0.625
2.3_DLL_v1.1,"The requirement that has to be met that you can use the piggybacking extension to the sliding window protocol is, that we need the ACK field in the frame header that costs only a few bits. A seperate frame would need more costs: ACK, header and a checksum.",CORRECT,1.0,"[0.5707154870033264, 0.6848491430282593]","[(27, 34), (35, 38), (40, 41), (43, 45)]","[['we need the ACK field in', 'frame header', 's', 'a ']]",0.25
2.3_DLL_v1.1,"Piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver. Therefore, the ACK for a data frame from a sender is sent in one frame with the next data frame issued by the receiver. Thus, the requirement for piggybacking is a duplex connection (and the need of sending an ACK).",CORRECT,1.0,"[0.5421572327613831, 0.5403889417648315]","[(0, 30), (77, 78), (79, 80), (82, 84), (85, 86), (87, 89)]","[['Piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver', 'du', 'connection', 'the need', '', 'an ']]",0.625
2.3_DLL_v1.1,"Requirement: The interval of two adjacent frames, which are sent by sender, is short. So that we can use piggybacking to response these two frames with one acknowledgement.  The communication has to be duplex (so the protocol must not be ""Utopia""). And the receiving buffer from the Sender must be ,so that it is able to store the ACK plus the additional data!",PARTIAL_CORRECT,0.5,"[0.6090375781059265, 0.5464745759963989]","[(47, 65)]","[['The communication has to be duplex (so the protocol must not be ""Utopia']]",0.875
2.3_DLL_v1.1,"There must also be frames directed towards A (sender) in the transmission, so that B (receiver) sends frames back to A in a reasonable amount of time. In addition to that the amount of frames size of both parties must be similarly big, because the acknowledgement is added to frames directed at A. As a result there must be a certain balance of frames in both directions.",PARTIAL_CORRECT,0.5,"[0, 0]",[],[[]],0.625
8.3_MM,PROPERTY: GLOBAL KNOWLEDGE OF THE MULTICAST GROUP’S SPANNING TREE (MULTICAST TREE)  INITIALLY ONLY LOCAL KNOWLEDGE   ALL IS SEND LINK STATE PACKETS PERIODICALLY  -CONTAINING INFORMATION     DISTANCE TO NEIGHBORS     EXPANDED BY INFORMATION ON MULTICAST GROUPS -BY BROADCAST TO ALL THE OTHERS EACH IS CALCULATES A MULTICAST TREE -FROM THE NOW LOCALLY AVAILABLE AND COMPLETE STATE INFORMATION BASED ON THE INFORMATION ABOUT THE MULTICAST TREE - IS DETERMINES THE OUTGOING LINES - ON WHICH PACKETS HAVE TO BE TRANSMITTED,PARTIAL_CORRECT,0.5,"[0.6324940919876099, 0.6294645071029663]","[(1, 2), (3, 5), (6, 7), (8, 12), (13, 66), (67, 71), (72, 87), (88, 95), (96, 104), (105, 140), (141, 145)]","[['PROPERTY', 'GLOBAL', 'KNOW', 'EDGE OF THE MULTI', 'GROUP’S SPANNING TREE (MULTICAST TREE) INITIALLY ONLY LOCAL KNOWLEDGE ALL IS SEND LINK STATE PACKETS PERIODICALLY -CONTAINING INFORMATION DISTANCE TO NEI', 'BORS EXPANDE', 'BY INFORMATION ON MULTICAST GROUPS -BY BROADCAST', 'ALL THE OTHERS EACH', 'CALCULATES A MULTICAST TREE', '-FROM THE NOW LOCALLY AVAILABLE AND COMPLETE STATE INFORMATION BASED ON THE INFORMATION ABOUT THE MULTICAST TREE -', 'DETERMINES THE']]",0.625
8.3_MM,"A Spanning tree consists of a loop free topology including all nodes with minimum number of possible edges. It finds a minimal subnet and enables the network to minimize duplicates and reduce traffic. Modification of Link State Routing: The link state packet which contains information about the distance to neighbors can be enhanced by adding information on multicast groups. As the link state packets are broadcasted to all other nodes, every node is able to calculate a local multicast tree due to the fact that all nodes have the complete state information locally available.  Based on the multicast tree a node decides on which outgoing links a packet has to be forwarded.",CORRECT,1.0,"[0.6355966329574585, 0.7311205267906189]","[(49, 86), (87, 102), (104, 105), (106, 135)]","[['Modification of Link State Routing: The link state packet which contains information about the distance to neighbors can be enhanced by adding information on multicast groups', 'As the link state packets are broadcasted to all other ', 'every', 'node is able to calculate a local multicast tree due to the fact that all nodes have the complete state information locally available']]",0.625
8.3_MM,"Spanning Tree is known to the IS as, generates a minimum number of packet copies , that IS generates a copy of a packet for each required outgoing line and all spanning tree lines except incoming one have to be defined. It has to know the multicast basic principle, that all IS have to know the multicast tree. So all IS nodes send link state packets periodically.  The IS defines the outgoing lines and which packets have to be transmitted.",PARTIAL_CORRECT,0.5,"[0.6173335313796997, 0.6221389770507812]","[(85, 98)]",[['So all IS nodes send link state packets periodically']],0.625
8.3_MM,"You use Reverse Path Forwarding with pruning. After the tree is set up the broadcast tree you know who belongs to the multicast. - If all child nodes aren't part of the multicast tree the parent knows it itself isn't part of the multicast tree. (Bottom Up) You can modify Link state routing by not only considering the ""distance"" between neighbors but also information on multicast groups.",PARTIAL_CORRECT,0.25,"[0.6212911009788513, 0.6571398377418518]","[(72, 100)]","[['You can modify Link state routing by not only considering the ""distance"" between neighbors but also information on multicast groups']]",0.625
8.3_MM,"the spanning tree algorithm determines the packets for the broad and multicasting While the link state packets will be sent, the containing information will be expanded by information on multicast groups - every IS calculate now its multicast tree",PARTIAL_CORRECT,0.5,"[0.6312090754508972, 0.6561533212661743]","[(0, 10), (11, 29), (38, 39)]","[['the spanning tree algorithm determines the ', 's for the broad and multicasting While the link state packets will be sent', 'by']]",0.625
8.3_MM,1. There is no loop,PARTIAL_CORRECT,0.5,"[0, 0]",[],[[]],0.5
8.3_MM,"The advantage of using a spanning tree for broad-/multicasting is that no duplicate messages are sent. This reduces network load while providing the exact same performance, only at the cost of lower reliability. If we want to construct a spanning tree using Link State Routing, each node, after having received the link state packets from all other nodes, calculates a spanning tree using the received information. The node will then use the connections from the calculated spanning tree to distribute multicast packets efficiently.",PARTIAL_CORRECT,0.5,"[0.6313366293907166, 0.6885666251182556]","[(51, 67), (76, 85)]","[['If we want to construct a spanning tree using Link State Routing', 'received the link state packets from']]",0.625
8.3_MM,"Spanning trees have the following property, they connect all nodes in a graph with minimum possible edges. Since all nodes in the network are addressed by the source node that builds the spanning tree, an IS has to generate the minimum number of packet copies to broadcast or multicast to this sub-net. Each IS initially knows which multicast group it belongs to. This additional multicast information is added to the link state packets that are periodically sent out by the node. Once the complete state information is obtained, each IS calculates a spanning tree for multicast.",CORRECT,1.0,"[0.6053683757781982, 0.6948445439338684]","[(93, 119), (122, 123), (124, 126)]","[['This additional multicast information is added to the link state packets that are periodically sent out by the node', 'the', 'state information']]",0.625
8.3_MM,"Property: -no cycles / minimal path / connect only needed path for the transmitting   All IS send link state packets periodically, containing information about distance to neighbors and expanded by information on multicast groups and by broadcast to all the others. Each IS calculates a multicast tree from the now locally available and complete state information. Based on the information about the multicast tree IS determines the outgoing lines, on which packets have to be transmitted.",CORRECT,1.0,"[0.6463673114776611, 0.6780467629432678]","[(0, 1), (10, 11), (15, 17), (18, 21), (22, 31), (48, 49), (58, 78)]","[['Property', 'path', 'needed path', 'the transmitting', 'IS send link state packets periodically', 'groups', 'Each IS calculates a multicast tree from the now locally available and complete state information']]",0.625
8.3_MM,Property: subnets of subnets can be displayed and addresses which enables more possibilities for multi-/broadcast for distribution of information  modification of link state routing for spanning tree multicast:   - all IS have to know the multicast tree. →which group belonging   - Information distribution via link stated routing.  - all IS send updates (link state packages) periodically  →calculate the own tree  →DETERMINE possibilities for transmission,PARTIAL_CORRECT,0.25,"[0.617863118648529, 0.6716135740280151]","[(17, 58), (68, 69), (70, 72), (73, 74), (88, 90)]","[['which enables more possibilities for multi-/broadcast for distribution of information modification of link state routing for spanning tree multicast: - all IS have to know the multicast tree', 'distribution', 'link state', 'rout', ') period']]",0.625
2.1_DLL_v1.1,"Unconfirmed Connectionless Service: You send data without a steady connection and without any feedback if the data arrived and if it arrived correctly.  Confirmed Connectionless Service: You do not use a steady connection between sender and receiver, but you get a feedback whenever data is received.  Connection-Oriented Service: You use a steady connection between sender and receiver. Each transmission process consists of 3 phases, at first you establish a connection then you send the data and at the end you disconnect.",CORRECT,1.0,"[0.6189625263214111, 0.5854540467262268, 0.525958776473999, 0.6750058531761169, 0.6529632210731506, 0.6319992542266846]","[(0, 35), (36, 60), (75, 96)]","[['Unconfirmed Connectionless Service: You send data without a steady connection and without any feedback if the data arrived and if it arrived correctly', 'Confirmed Connectionless Service: You do not use a steady connection between sender and receiver', 'Connection-Oriented Service: You use a steady connection between sender and receiver']]",1.0
2.1_DLL_v1.1,"1.Unconfirmed Conn.less Service 2.Confirmed Conn.less Service 3.Connection-Oriented Service  Differences:  1.Unconfirmed Conn.less Service and Confirmed Conn.less Service have no flow control. But Connection-Oriented Service has no flow control. 2.confirmed Conn.less Service and Confirmed Conn.less Service have no connect or disconnect. But Connection-Oriented Service has connect or disconnect. 3. Connection-Oriented Service has no loss, no duplication, no sequencing error. But Confirmed Conn.less Service has loss, duplication,sequencing. And Unconfirmed Conn.less Service has more errors than Confirmed Conn.less Service.",CORRECT,1.0,"[0.6680182814598083, 0.7685608267784119, 0.6495398283004761, 0.6815206408500671, 0.6906574964523315, 0.6499838829040527]","[(16, 25), (27, 28), (46, 56), (58, 60), (63, 64), (66, 69), (70, 78), (79, 90), (92, 100)]","[['Connection-Oriented Service Differences:', 'confirm', 'But Connection-Oriented Service has no flow control', 'confirmed', 'Service', 'Confirmed Conn', 'less Service have no connect or disconnect', 'But Connection-Oriented Service has connect or disconnect', 'Connection-Oriented Service has no loss']]",1.0
2.1_DLL_v1.1,"Unconfirmed connectionless service (UCS), confirmed connectionless service (CCS) and connection-oriented service (COS). UCS doesn’t have correction mechanism and flow control. The data probably gets lost. CCS reply ACK when receiving the correct data and it has timeout-and-retransmit mechanism. It is more reliable than CCS but probably incurs some sequence errors. COS has connection and disconnection mechanism. It can achieve flow control, no loss and no sequencing error.",CORRECT,1.0,"[0.7209311723709106, 0.6607730388641357, 0.5891989469528198, 0.6244533061981201, 0.5983707904815674, 0.56812983751297]","[(0, 9), (10, 25)]","[['Unconfirmed connectionless service (UCS', 'confirmed connectionless service (CCS) and connection-oriented service (COS']]",1.0
2.1_DLL_v1.1,"1.Unconfirmed Conn.less Service   Features    No flow control    No connect or disconnect   2.Confirmed Conn.less Service  Features    No flow control    No connect or disconnect    Duplicates and sequence errors may happen due to “retransmit”  3.Connection-Oriented Service Connection over error free channel   No loss, no duplication, no sequencing error    Flow control 3-phased communication They are different in features.",CORRECT,1.0,"[0.5862874984741211, 0.579214334487915, 0.6268923878669739, 0.7397617697715759, 0.7409384250640869, 0.7090197801589966]","[(1, 2), (3, 5), (7, 17), (18, 19), (22, 45), (46, 47), (48, 49), (51, 63)]","[['Un', 'ed Conn', 'Service Features No flow control No connect or disconnect', 'Confirm', 'less Service Features No flow control No connect or disconnect Duplicates and sequence errors may happen due to', 're', 'mit', 'Connection-Oriented Service Connection over error free channel No loss']]",1.0
2.1_DLL_v1.1,"The three classes:  Unconfirmed Connectionless Service -Transmits isolated independent units -Data units may be lost -No flow control -No connecting or disconnecting  Confirmed Connectionless Service -Transmits independent data units  -Receiver acknowledges the reception of each single frame -Timeout + Retransmission if sender does not receive acknowledgment within a certain amount of time  -Thereby no loss of data, but duplicates and sequence errors may occur -No flow control -No connecting or disconnecting    Connection-Orientated Service  -Transmits data over error free channel (through acknowledgments) -No loss of data, no duplications, no sequencing errors -Flow control -3-phased communication: connect, data transfer, disconnect",CORRECT,1.0,"[0.5713660717010498, 0.5719592571258545, 0.5147029757499695, 0.721653163433075, 0.7255483269691467, 0.7008237838745117]","[(0, 73), (77, 79), (84, 85), (88, 89), (96, 97), (115, 158), (169, 173), (174, 179)]","[['The three classes: Unconfirmed Connectionless Service -Transmits isolated independent units -Data units may be lost -No flow control -No connecting or disconnecting Confirmed Connectionless Service -Transmits independent data units -Receiver acknowledges the reception of each single frame -Timeout', 'if ', '', '', 'of', 'may occur -No flow control -No connecting or disconnecting Connection-Orientated Service -Transmits data over error free channel (through acknowledgments) -No loss of data', '-Flow control ', 'phased communication: connect']]",1.0
2.1_DLL_v1.1,"Unconfirmed Connectionless Service: no flow control Confirmed Connectionless Service: no flow control, duplication and sequencing error may happen Connection-Oriented Service: flow control, no loss, no duplication, no sequencing error",CORRECT,1.0,"[0.5954094529151917, 0.5866075754165649, 0.6364442706108093, 0.6266756653785706, 0.6030317544937134, 0.7062785029411316]","[(0, 20), (21, 37)]","[['Unconfirmed Connectionless Service: no flow control Confirmed Connectionless Service: no flow control', 'duplication and sequencing error may happen Connection-Oriented Service: flow control']]",1.0
2.1_DLL_v1.1,"Here are the 3 service classes the data link layer offers:   1) Unconfirmed connectionLess Service: there is no ""connect and disconnect"" between sender and receiver. There is no flow control or error management  2) Confirmed connectionLess Service: There is no ""connect and disconnect"", there is no flow control but there is an acknowledgment for each frame sent.   3) Connection oriented Service: there is a flow control and a ""connect and disconnect"" protocol between the sender and the receiver",CORRECT,1.0,"[0.5803377032279968, 0.596817672252655, 0.48604199290275574, 0.6906960606575012, 0.6959065794944763, 0.6925005912780762]","[(6, 7), (9, 10), (14, 39), (49, 65), (85, 116)]","[['classes', 'link', '1) Unconfirmed connectionLess Service: there is no ""connect and disconnect"" between sender and receiver', 'Confirmed connectionLess Service: There is no ""connect and disconnect', '3) Connection oriented Service: there is a flow control and a ""connect and disconnect"" protocol between the sender and the receiver']]",1.0
2.1_DLL_v1.1,"Unconfirmed Connectionless Service: -sends data without establish a connection -if data units get lost, didn’t get any feedback -no flow control and no disconnect   Confirmed Connectionless Service: -if data units get received, the receiver send an acknowledgement, so no loss -if sender does not receive an ack within a certain time, then retransmit, it can lead to duplicates and sequence errors -no flow controls -didn’t establish a connection or disconnection with the receiver  Connection-Oriented Service: -3-phased Communication: 1. Establish a connection, 2. Transfer data, 3. Disconnect -Flow control, no loss of data units, no duplication and no sequencing error",CORRECT,1.0,"[0.6154558658599854, 0.6372403502464294, 0.5305014252662659, 0.740510106086731, 0.7571807503700256, 0.6711405515670776]","[(0, 27), (28, 29), (30, 35), (36, 60), (110, 113), (114, 115), (116, 120), (121, 147)]","[['Unconfirmed Connectionless Service: -sends data without establish a connection -if data units get lost', 'did', '’t get any feedback', '-no flow control and no disconnect Confirmed Connectionless Service: -if data units get received', '-no', '', '-didn', 't establish a connection or disconnection with the receiver Connection-Oriented Service: -3-phased Communication: 1.']]",1.0
2.1_DLL_v1.1,"The three classes:  Unconfirmed Connectionless Service Confirmed Connectionless Service Connection Oriented Service  In Unconfirmed Connectionless no confirmation of data transmitted is received, loss of data units is possible and also no flow control is present. In Confirmed Connectionless  acknowledgement of data transmitted is received, no loss of data units because of retransfer and timeout mechanisms and also no flow control is present. In Connection Oriented data is transferred over an error free channel, no loss of data units possible and flow control is also present,",CORRECT,1.0,"[0.6106289625167847, 0.6199741363525391, 0.6820403933525085, 0.654379665851593, 0.6542330980300903, 0.6019327640533447]","[(0, 37), (38, 44), (45, 46), (47, 48), (53, 68), (69, 70), (96, 100), (102, 105), (107, 108)]","[['The three classes: Unconfirmed Connectionless Service Confirmed Connectionless Service Connection Oriented Service In Unconfirmed Connectionless no confirmation of data transmitted is received', 'loss of data units is', 'and', 'no', 'In Confirmed Connectionless acknowledgement of data transmitted is', 'd', 'Connection Oriented data', 'red over an', 'channel']]",0.75
2.1_DLL_v1.1,"The 3 service classes are: Unconfirmed connectionless service (1), Confirmed connectionless service (2) and Connection-oriented service (3). The main difference between this services is the handling of the loss. While in (1) data packets are only send to the receiver, packets can get lost and loss is not being corrected. In service (2) data packets has to be acknowledged by the receiver and packets will be resend after a certain timeout. This leads to inefficient communication and can be done on a higher level. Service (3) consists of 3 phases (Connection establishment, data transfer, Disconnect). Just like in service (2) we have no loss, but Flow Control is possible in contrast to services (2) and (1).",CORRECT,1.0,"[0.6964826583862305, 0.643057644367218, 0.5923128724098206, 0.6506810784339905, 0.637328028678894, 0.5976054072380066]","[(0, 14), (15, 28)]","[['The 3 service classes are: Unconfirmed connectionless service (1)', 'Confirmed connectionless service (2) and Connection-oriented service (3)']]",0.75
2.1_DLL_v1.1,"(1) “Unconfirmed Connectionless Service”: Transmission of isolated, independent units (loss of data units possible) is a good choice on communication medium with very low error rate  (2) “Confirmed Connectionless Service”: Receipt of data units get acknowledged by receiver, therefore no loss, but duplicates and sequence errors may happen due to retransmit if no acknowledgement within a certain time. is a good choice on communication medium with high error rate e.g. wireless communication  (3) ""Connection-Oriented Service”: This service has flow control. Consists of 3-phases of communication, with Connection Initialization, Data Transfer and Disconnection.  is a good choice if bi-directional communication is needed and is a good choice for an error free communication medium (therefore no loss, no duplication, no sequencing error)",CORRECT,1.0,"[0.7284315228462219, 0.6782751679420471, 0.627658486366272, 0.679533064365387, 0.6714218258857727, 0.6238492131233215]","[(0, 12), (13, 15), (40, 41), (42, 57), (58, 64), (104, 105), (112, 114), (117, 119), (120, 134)]","[['(1) “Unconfirmed Connectionless Service”: Transmission', 'isolated', 'rate', '“Confirmed Connectionless Service”: Receipt of data units get', 'acknowledged by receiver', 'choice', 'e', 'wireless', '(3) ""Connection-Oriented Service”: This service has flow control']]",1.0
2.1_DLL_v1.1,"- Unconfirmed Connectionless Service  The Unconfirmed Connectionless Service sends data to the receiver, without announcing it (building up a connection) first in data frames without any flow control. Because of the missing connection and flow control, it is possible that complete data frames can get lost.   - Confirmed Connectionless Service  Wheras the confirmed connectionless service sends the data frames and waits for an acknowledgement of the corresponding recipient. If the recipient confirms the data frame, the next data frame is being sent. If the recipient doesn’t answer for a long time, the data frame is being resent. If for some reason, the ackknowledgement gets lost, the recipient will eventually get a data frame twice, and will not be able to detect the duplication. The correction has to be made on a higher level. It is much slower than the unconfirmed, because of waittime for timeouts and ackknowledgement messages.  - Connection Oriented Service  In the connection oriented service, the overhead is a lot higher, but the advantages are a detailed flow control, in which the recipient can detect duplicates, ask for a certain frame and can align the frames in the right order. And if the recipient reads slower than the sender transmit, it is possible to make a transmission. The participants first exchange a handshake and afterwards are transferring data. Afterwards the connection is disconnected.",CORRECT,1.0,"[0.5614129304885864, 0.5337009429931641, 0.4957181215286255, 0.5804249048233032, 0.5856044292449951, 0.5541166663169861]","[(0, 22), (71, 107), (237, 248)]","[['- Unconfirmed Connectionless Service The Unconfirmed Connectionless Service sends data to the receiver', '- Confirmed Connectionless Service Wheras the confirmed connectionless service sends the data frames and waits for an acknowledgement of the corresponding recipient', '- Connection Oriented Service In the connection oriented service']]",1.0
2.1_DLL_v1.1,"""Uncomfirmed Conn.less Service"", ""Confirmed Conn.less Service"", ""Connection-Oriented Service"" ""Uncomfirmed Conn.less Service"": Data is just send, without any feedback, that it is received. Both partys assume that no bit is missing. There is no Flow Control or a connect and disconnect feature. This way of sending data is only used on L1 communication channels with very low error rate.  ""Confirmed Conn.less Service"": Everytime data is send, the receiver sends an ACK flag, that he received it. If he doesnt send an ACK flag in a given time frame, the transmission times out and the data is retransmitted. There also is no Flow control or a connect and disconnect feature, duplicates and sequence errors can happen because of a retransmission. This service is used on L1 communication channels with high error rate.  ""Connection-Oriented Service"": 3-phased communication: 1. Connection(initializing the counters/variables of the sender and receiver) 2. Data Transfer 3. Disconnect. The data sent in setp two of this class is bidirectional, sequentiell and acknowledged, which means no data loss, no duplicates and no errors.",CORRECT,1.0,"[0.6444348692893982, 0.5776300430297852, 0.6486133933067322, 0.6892223954200745, 0.6870121359825134, 0.6882150769233704]","[(11, 12), (18, 31), (33, 37), (64, 77), (160, 174), (208, 220)]","[['Confirm', '""Connection-Oriented Service"" ""Uncomfirmed Conn', 'Service"": Data is', 'There is no Flow Control or a connect and disconnect feature', 'There also is no Flow control or a connect and disconnect feature', '""Connection-Oriented Service"": 3-phased communication:']]",1.0
2.1_DLL_v1.1,"1. Unconfirmed Connectionless Service  2. Confirmed Connectionless Service 3. Connection-Oriented Service   In the 1. service, transmission of the data happens isolated and independent. A loss of data is possible.  With service 2. if the receiver do not answer, the data is retransmit after a certain time, so there are no loss. In both is no connection or disconnection.  In the 3. service, first a connection is initialized, data is transfered and then the connection is abort.",CORRECT,1.0,"[0.6001650094985962, 0.5575106739997864, 0.519436240196228, 0.5868260264396667, 0.5723100304603577, 0.5380828380584717]","[(1, 22)]",[['Unconfirmed Connectionless Service 2. Confirmed Connectionless Service 3. Connection-Oriented Service In the']],1.0
2.1_DLL_v1.1,"Data Link Layer service classes: - Unconfirmed Connectionless Service - Confirmed Connectionless Service  - Connection-oriented Service  In Unconfirmed Connectionless and Confirmed Connectionless services there is no established connection between the sender and the receiver, while in Connection-oriented service, the data is only transferred when a connection is established between the sender and the receiver. In Connection-oriented there is also a disconnect phase.  In Unconfirmed Connectionless service when the sender sends a frame, it hopes the frame reachs the receiver without a problem. The sender does not receive any confirmation, from the receiver, that the frame was received. This is not what happens in Confirmed Connectionless and Connection-oriented services. When a message is received on the receiver side, the receiver sends a confirmation message to the sender. So, in this two services the sender has the confirmation that the message reached the receiver.",CORRECT,1.0,"[0.662298858165741, 0.6152018904685974, 0.5658408403396606, 0.6490222811698914, 0.6297546029090881, 0.6361324787139893]","[(0, 2), (4, 7), (8, 66), (91, 104), (105, 119), (120, 122), (163, 180)]","[['Data Link', 'service classes', '- Unconfirmed Connectionless Service - Confirmed Connectionless Service - Connection-oriented Service In Unconfirmed Connectionless and Confirmed Connectionless services there is no established connection between the sender and the receiver, while in Connection-oriented service', 'In Connection-oriented there is also a disconnect phase', 'In Unconfirmed Connectionless service when the sender sends', 'a frame', 'This is not what happens in Confirmed Connectionless and Connection-oriented services']]",1.0
8.1_MM,"Transport Layer, in which it writes an error detection and correction also increases energy efficiency.  Network Layer, in which it adapts routing protocols and multicast routing.",INCORRECT,0.0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",[],[[]],0.875
8.1_MM,"- Hidden Terminal Problem: Assume we have 2 senders s1,s2 and one receiver r build like this:  s1 → r ← s2  The radius of s1 can just sense the receiver and s2 can also just sense the receiver.   S1 is sending something to r. But since S2 cannot sense s1 it assumes the receiver is free and starts sending to r too. Hence s1 is hidden to c the collison detection fails → Hidden Terminal Problem.  - Exposed Terminal Problem:  Assume we have 2 senders s1,s2 and two receiver r1, r2 build like this:  r1 ← s1 --- s2 → r2  Now s1 sends to r1. s2 wants to send to r2 but it gets the signal from s1 that it is sending data at the moment. Since s1 is sending to r1 and s2 can not sense r1, it assumes r2 is busy, and hence waits unnecessarily.  --> Exposed Terminal Problem",PARTIAL_CORRECT,0.75,"[0.49280261993408203, 0.4374435245990753, 0.5376978516578674, 0.3987261652946472, 0.5033921599388123, 0.38113126158714294, 0.43008384108543396, 0.35112452507019043, 0.3379935920238495, 0.39819595217704773, 0.4418247640132904, 0.4022759199142456, 0.42072272300720215, 0.39120110869407654, 0.37873560190200806, 0.39550021290779114, 0.40744614601135254, 0.4253973066806793]","[(10, 11), (14, 15)]","[['have', 's']]",1.0
8.1_MM,"Hidden Terminals: Two nodes may be out of range for each other, but want to send to a third node that is in range for both of them. The first two nodes don't know when/if the other one is sending, so if both just send whenever they want, there might be a collision at the third node that can't be detected by the first two nodes. Exposed Terminals: When two nodes, that are in range for each other, want to send to nodes that are in range for them, but out of range for the other, they could, in theory, both send at the same time, because each of the receiving nodes will only receive a signal from the corresponding sending node (because the other one is not in range). However, without additional communication, the two sending nodes can not know that they aren't interfering with they other node. That's why one of the nodes will wait for the other to finish → underutilization.",CORRECT,1.0,"[0.4754236340522766, 0.6881387233734131, 0.44518256187438965, 0.6820804476737976, 0.5547053813934326, 0.6016663908958435, 0.5849443078041077, 0.6661626100540161, 0.39678773283958435, 0.6263470649719238, 0.45874103903770447, 0.552178144454956, 0.4750994145870209, 0.5454519391059875, 0.7616549730300903, 0.5774149894714355, 0.47335168719291687, 0.44699835777282715]","[(1, 2), (4, 5), (9, 12), (16, 17)]","[['Hidden', ':', 'be out of', 'other']]",0.75
8.1_MM,"ADAPTATION OF ROUTING PROTOCOLS due to the inherent variability of a mobile network: the packets must be routed despite convergence problems due to frequent changes in topology and environment due to mobile nodes, i.e. frequent routing table updates, unreliable/unavailable links due to receiving/transmitting problems (near and far terminals, energy saving, insufficient transmission power), so THE PATH FROM SOURCE TO DESTINATION IS MUCH MORE SHORT-LIVED OR SUBJECT TO CHANGES MUCH MORE OFTEN THAN IN FIXED NETWORKS. * ADDRESSING (AUTO-CONFIGURATION): the automatic configuration of the end systems IS DIFFICULT DUE TO ROAMING and this obviously also affects routing. When roaming at Layer 2, the IP address can be retained, but the packet must be routed via an appropriate access point: if there is a handover, the old AP would have to forward the packets to the new one; when roaming at Layer 3, a subnet change may result in the assignment of a new IP address.",CORRECT,1.0,"[0.5121110677719116, 0.6707297563552856, 0.31999799609184265, 0.6029613018035889, 0.5204105973243713, 0.6119514107704163, 0.620216429233551, 0.546501100063324, 0.4419572651386261, 0.6351513266563416, 0.5084226727485657, 0.5903819799423218, 0.5344840288162231, 0.6094874739646912, 0.5973636507987976, 0.5372833013534546, 0.49967142939567566, 0.4434039890766144]","[(0, 51)]",[['ADAPTATION OF ROUTING PROTOCOLS due to the inherent variability of a mobile network: the packets must be routed despite convergence problems due to frequent changes in topology and environment due to mobile nodes']],1.0
8.1_MM,"One issue for mobile networks is the hidden terminal problem: When there are two stations A and C out of reach of each other want to send to a station B in reach of both stations, A and C will not hear the signal of the other sender, assume the medium is free and start sending. However, at station B, both signals will collide. A second issue for mobile networks that cannot occur in wired networks is the exposed terminal problem: Sending from one station A to another station B might be blocked because of A receiving a signal from another sender C in reach of station A, despite the signal of this sender C not reaching the proposed receiver B. This issue can reduce the utilization of a link between two nodes unessessarily.",CORRECT,1.0,"[0.6130589842796326, 0.6732192039489746, 0.7672553062438965, 0.662899374961853, 0.6406174898147583, 0.6627016663551331, 0.6427918076515198, 0.6043655276298523, 0.44919243454933167, 0.6280539631843567, 0.5787137746810913, 0.5914522409439087, 0.5304694175720215, 0.5601857900619507, 0.6893557906150818, 0.5914705991744995, 0.5397384762763977, 0.5432095527648926]","[(0, 1), (2, 7), (8, 9), (11, 20), (21, 27), (28, 40), (41, 43), (92, 94), (95, 96), (104, 106), (117, 120), (124, 126), (128, 129)]","[['One', 'for mobile networks is the', 'hidden', ': When there are two stations A and', 'out of reach of ', 'other want to send to a station B in reach', 'both stations', 'occur in', 'ed', 'Sending', 'be blocked', 'receiving', 'signal']]",1.0
8.1_MM,"Hidden Terminals is one challenge in Mobile Routing. The problem is that nodes can only comunicate in a certain range and  those ranges overlap with others, leading to nodes receiving data from others, which do not know about one and another. This leads to data coalition. Another Challenge is Exposed Terminals. The problem again lies in the nature of the overlapping data transmission. To solve the previously mentioned problem only one can send at a time in their range, however this can lead to blocking communication to outside nodes which would not be effected by having communication with another one outside of the receivers range.",CORRECT,1.0,"[0.45647361874580383, 0.6881387233734131, 0.6752501726150513, 0.6820804476737976, 0.4638065695762634, 0.6016663908958435, 0.5849443078041077, 0.6661626100540161, 0.32329225540161133, 0.6263470649719238, 0.4038006663322449, 0.552178144454956, 0.36594027280807495, 0.5454519391059875, 0.7616549730300903, 0.5774149894714355, 0.36714160442352295, 0.3553210198879242]","[(1, 2), (7, 8)]","[['Hidden', 'in']]",0.5
8.1_MM,"Hidden Terminals: Two nodes (A and B) that are out of each other's range can not detect transmissions from either node to a third node (C) which is within their ranges. This can cause A and B to simultaneously attempt to transmit to C. Hence, A and C are “hidden” from each other. This leads to more collisions and reduced efficiency. Exposed Terminals: When two nodes are too close to each other it can interfere with their transmissions. When one node is transmitting, it signals to all other nodes in its vicinity that a medium (destination node) is in use and therefore the other nodes should wait before transmitting themselves. This becomes a problem when the other node in its vicinity has to delay its transmission to an entirely different node outside of the transmitting node's range. This leads to an underutilization of the channels.",CORRECT,1.0,"[0.6042239665985107, 0.6963574290275574, 0.6965468525886536, 0.6777969598770142, 0.6193899512290955, 0.5695968866348267, 0.5690987706184387, 0.6307514309883118, 0.4305552542209625, 0.6293556094169617, 0.5338326692581177, 0.573721170425415, 0.5091288685798645, 0.5394400954246521, 0.7384552955627441, 0.5896123647689819, 0.522440493106842, 0.5085256099700928]","[(5, 6), (10, 12), (13, 18), (19, 20), (22, 29), (31, 34), (35, 36), (37, 38), (39, 40), (41, 43), (46, 47)]","[['Two', 'and B', 'that are out of ', 'other', 'range can not detect transmissions from', 'node to', 'a', 'third', 'node', 'C)', '']]",1.0
8.1_MM,"1- Hidden terminals [Tobagi75]: it occurs when “for example” we have three nodes A, B, C. Nodes A and C cannot hear each other, and the transmissions by nodes A and C can collide at node B. That makes nodes A and C are hidden from each other. And that can cause more collisions, unreliability as a result, and waste of resources.  2- Exposed terminals: it happens when “for example” we have four nodes A, B, C, D. Node B sends to node A, and node C wants to send to another node like D (not A or B), node C has to wait and it is prevented from sending packets to other nodes because of co-channel interference with a neighboring transmitter (medium in use). But node A is outside the radio range of node C, therefore waiting is not necessary, and node C is “exposed” to B. That can cause underutilization of channels and lower effective throughput.",CORRECT,1.0,"[0.5560106039047241, 0.5471547245979309, 0.6410584449768066, 0.5225241184234619, 0.5939808487892151, 0.4636480510234833, 0.48617586493492126, 0.5072583556175232, 0.40108662843704224, 0.504515528678894, 0.518808901309967, 0.4527680277824402, 0.4963070750236511, 0.4439285099506378, 0.5690357685089111, 0.469315767288208, 0.48241862654685974, 0.48531439900398254]","[(8, 9), (51, 54), (58, 59)]","[['75]', 'C can colli', 'B']]",1.0
8.1_MM,"1.Hidden Terminals: it is when two stations simultaneously transmit data to one of the stations is unaware that reception is already receiving data from another station and a collision occurs at the receiving station. E.g.  We have three station A,B,C -A sends to B, C cannot receive A   -C senses a “free” medium (carrier sense fails) , C sends to B   -Collision at B, A cannot detect the collision (collision detection fails)  -A is “hidden” for C and vice versa  2.Near and Far Terminals: it's when a weak signal drowns out a strong signal. Terminals A and B send, C receives  -Signal strength decreases proportionally to square of distance  -Stronger signal of B therefore drowns out A’s weaker signal  -C cannot receive A",CORRECT,1.0,"[0.5744760632514954, 0.5817991495132446, 0.8169860243797302, 0.584434986114502, 0.5244229435920715, 0.5732191205024719, 0.5744110941886902, 0.6894370317459106, 0.40983960032463074, 0.5638728737831116, 0.47911158204078674, 0.5398167371749878, 0.4711446762084961, 0.537506103515625, 0.5643677115440369, 0.5235154032707214, 0.4554179310798645, 0.4204016625881195]","[(25, 26), (39, 40), (134, 157)]","[['reception', 'c', ""Near and Far Terminals: it's when a weak signal drowns out a strong signal""]]",0.75
8.1_MM,HIDDEN TERMINAL Because there no cable connecting every Terminal together it can happen that two or more station can not reach each other and therefor hidden. This can be a problem if for example a terminal has to be quiet so it doesn’t disturb the communication of a neighbor but it can’t get the communication request signal from the communication partner because it is hidden. This can be solved by using a busy signal or by listening to acknowledgments from the neighbor. NEAR AND FAR TERMINALS A signal from a station gets weaker with distance by the inverse square law. This lead to the situation that nearer stations are overpowering stations which are further away and drowning there signal. As a result stations which would normally be able to communicate with each other can’t do so anymore. This can be a severe problem and can only be handled with precise power control.,PARTIAL_CORRECT,0.875,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[(25, 26)]",[['']],0.875
8.1_MM,"1. application layer - the discovery of services - you will need service awareness and need places for the services security   - outside you can always be attacked, or the mobile routing could be disturbed.",PARTIAL_CORRECT,0.25,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",[],[[]],0.875
8.1_MM,"In mobile routing autonomous systems are not stationary or in fixed location unlike fixed and wired networks. Autonomous system is free to come and join one network at one time and later leave and join another network while maintain same communication session between sender and receiver and vice versa. Two challenges: 1. Reconnecting sender and receiver when they try to connect through different intermediary networks while being on motion. 2. At user application level awareness by the sender that receiver has left, so save the user session, so that when receiver reconnects, sender is automatically notified and previous user session is resumed.",CORRECT,1.0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",[],[[]],0.875
8.1_MM,"- The network structure is changing fast, so the routing tables must be adapted to these changes. The routing algorithm needs to converge fast.   - Because all nodes share the same communication medium (the ether), the signaling overhead needs to be minimized, to reduce the load in the medium.",PARTIAL_CORRECT,0.875,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",[],[[]],0.875
8.1_MM,"CSMA/CD does not work for wireless transmission. Main issue is the broadcast nature of mobile transmission. * Hidden Terminal Problem: Firstly, carrier sense fails because a station that want to send cannot “see” another station already  sending to its destination as it is not in the transmission range of the other sending station. Secondly, there is no collision detection after the collision arised. This leads to a higher amount of collisions, a wastage of resources and unreliability. For example: * station A sends to station B; station C is not in the range of A, thus, does not receive A’s signal * C performs carrier sensing as it wants to send to B, senses a free medium * C sends to B which causes collision at B; A cannot detect the collision (as it is a wireless scenario) * station A and C are hidden from each other   * Exposed Terminal Problem: The “exposed” station is waiting to transmit a signal, as it hears a signal from another transmitting station. Thus, it tries to prevent a collision which actually will not occur as the receiver of the other sending station is outside of its range. This leads to underutilization of the channel and a decreased effective throughput. For example: * station B sends to station A; station C wants to send to another station outside of B’s transmission range * C performs carrier sensing and senses a busy medium, thus it has to wait * A is outside of C’s transmission range, thus, C actually does not need to wait as it would not cause a collision at A; C is exposed to B",CORRECT,1.0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",[],[[]],0.875
8.1_MM,"Two of the many challenges of mobile routing compared to fixed / wired networks are Hidden Terminals and security issues. Hidden Terminal can occur, when the nodes are quite far apart, while some nodes are not able to detect nodes anymore, while more centered nodes are able to detect messages from both the distant nodes. Then the distant nodes are not able to detect collisions occuring in the „middle“ of the network at the centered nodes, because the signal is not transmitted over all network nodes. One of the security issues can be, that wifi is set up inside of a building. A normal ethernet network over cable would connect all the nodes inside, and then can be configured to discard all the internal packages at the outgoing router to the internet. A wifi network cannot be configured, to only nodes inside of the building are able to receive the packages. If the network is available outside of the building, then any node outside will be able to detect the network.",CORRECT,1.0,"[0.6592927575111389, 0.7521452307701111, 0.6822960376739502, 0.7280763983726501, 0.6555950045585632, 0.6851195693016052, 0.6832706332206726, 0.7458495497703552, 0.49447932839393616, 0.7071478962898254, 0.6386377215385437, 0.6075184941291809, 0.5583345890045166, 0.5895113348960876, 0.763938844203949, 0.6390160322189331, 0.5760970711708069, 0.5524246692657471]","[(5, 6), (8, 10), (15, 16), (21, 24), (25, 27)]","[['challenges', 'routing', '', 'Hidden Terminal', 'and security']]",0.875
8.1_MM,"(Due to the question in the forum, i will relate to slide 3, not to Challenges in Mobile Communications, which are on slide 10ff).  One basic challenge in Mobile Networking is the Power control: mobile devices have only a limited amount of power which should be used wisely and as little as possible.  In addition, the routing in Mobile Networking has to deal with a high amount of dynamic so it needs to find new routes as nodes move or conditions change.",CORRECT,1.0,"[0.6117568016052246, 0.6920865774154663, 0.7072393298149109, 0.6735107898712158, 0.632186770439148, 0.605084240436554, 0.6218234896659851, 0.6164171099662781, 0.4591268002986908, 0.6258389353752136, 0.5691045522689819, 0.5724804997444153, 0.5177136063575745, 0.5532439351081848, 0.7440887093544006, 0.5682210922241211, 0.5516875982284546, 0.4824984669685364]","[(34, 35), (38, 47), (49, 51), (56, 57), (59, 60), (62, 63), (64, 65), (71, 72)]","[['One', 'in Mobile Networking is the Power control:', 'have only', 'amount', '', 'be', '', 'possible']]",1.0
4.3_LM,"Before sending data from Node A to Node B, A has to reserve a frame in the bus where A comes after B. Outer nodes are restricted to sending only in one direction, while nodes in the middle may make reservations in both directions and thus have a higher chance to get a reservation.",PARTIAL_CORRECT,0.5,"[0, 0]",[],[[]],0.875
4.3_LM,"The problem with DQDB is that if we have several participants in the network and they want to exchange data, the distance between them and the propagation delay causes a fairness issue. This is because when stations are closer together, they can communicate over the bus faster than stations further away, this would still be acceptable for normal data packets, but network control packets are also sent over the bus and so network changes can spread much slower than in other architectures.",CORRECT,1.0,"[0.604811429977417, 0.6149012446403503]","[(26, 28), (29, 36), (37, 45)]","[['the distance', 'between them and the propagation ', 'causes a fairness issue']]",0.875
4.3_LM,"The problem with DQDB is that there is a difference in fairness depending on the location, as not everyone has the same access to data.",CORRECT,1.0,"[0.5447608232498169, 0.6547647714614868]","[(0, 21)]",[['The problem with DQDB is that there is a difference in fairness depending on the location']],0.875
4.3_LM,"The problem with the “Distributed Queue Dual Buses” is that it does not ensure fairness. The location of the node has an influence on its likelihood of gaining access to the data or acquiring the right to send, which results in an inequality between the nodes.  At the beginning of a bus all frames generated by the frame generator are empty. So the first node can reserve however many frames it wants. At the end of the bus it can happen that all frames are already reserved so the last nodes may not be able to send anything.",CORRECT,1.0,"[0.5801353454589844, 0.5757405757904053]","[(0, 24)]",[['The problem with the “Distributed Queue Dual Buses” is that it does not ensure fairness']],0.875
4.3_LM,The Distributed Queue Dual Bus (DQDB) architecture uses two unidirectional buses for sending and receiving data. The main challenge here ist to guarentee fairness between all participating nodes as different nodes may have advantages (if at the beginning of the bus) or disadvantages (if at the end of the bus) in write access depending on their position in the bus.,CORRECT,1.0,"[0.5153915882110596, 0.6956412196159363]","[(30, 34), (35, 70), (72, 75), (77, 91)]","[['The main challenge here', 'to guarentee fairness between all participating nodes as different nodes may have advantages (if at the beginning of the bus) or disadvantages', 'at the end', 'bus) in write access depending on their position in the bus']]",0.875
4.3_LM,"Depending on the stations location in the network, they might be able to more easily reserve bandwidth on the BUS for sending data. Stations which are farther back will have less opportunities for reserving a BUS than stations at the front. This can be fixed by introducing some formulas describing how often each station can reserve a BUS.",CORRECT,1.0,"[0, 0]",[],[[]],0.875
4.3_LM,The problem that was discussed in the lecture is fairness. The nodes reserve slots on one bus and send on the other bus. One node might reserve a lot of the available slots which makes it hard for the following nodes to reserve the space they need.,CORRECT,1.0,"[0.7432454824447632, 0.48788270354270935]","[(0, 5), (6, 7), (8, 12)]","[['The problem that was discuss', 'in', 'lecture is fairness']]",1.0
4.3_LM,"Distributed Queue Dual Buses have a fairness problem, meaning that dependent on the position of the node it will be advantaged or disadvantaged for certain comunications, as each bus only works in one direction and frames have to be requested.",CORRECT,1.0,"[0.6302915215492249, 0.5965100526809692]","[(0, 14), (18, 20), (21, 22), (26, 27), (29, 31), (34, 35)]","[['Distributed Queue Dual Buses have a fairness problem', 'dependent on', 'position', 'it', 'advantage', 'advantage']]",0.875
4.3_LM,"The problem with DQDB Architecture is that the waiting time for a node to be allowed to send is heavily dependant on its location in the queue.If you are location on any far end of a bus (extrem right  or extrem left) then you will have to wait the most before you can send, if you want to send in the opposite direction.",CORRECT,1.0,"[0.5140051245689392, 0.5839974880218506]","[(0, 4), (5, 12), (13, 17), (23, 25), (27, 31), (32, 33), (34, 35)]","[['The problem with ', 'DB Architecture is that the waiting', 'for a ', 'send is', 'dependant on its', 'in', '']]",0.875
4.3_LM,"Distributed Queue Dual Buses = 2 buses (transfer data in opposing directions), every node connected to both buses  Distributed Queue Dual Buses is an architecture whereby every node is connected to 2 buses (write and read access). These buses are responsible for data transmission in opposing directions. The problem is because of transmission of data:  Both buses are connected to a frame generator which generate a fixed size frame every 125 milliseconds. Depending on the position of the nodes in the bus they can reserve the bus for sending data with a higher probability. E.g. for a node in the middle we have a probability of 50% to successfully reserve a bus. As a consequence, fairness is a problem due to the bus topology: Depending on the position of the node the node may be more or less successful in reserving a bus for data transmission.",CORRECT,1.0,"[0.6379169821739197, 0.6519496440887451]","[(4, 5), (6, 7), (8, 10), (11, 12), (14, 15), (16, 17), (115, 120), (121, 122), (123, 144), (180, 194), (195, 198), (199, 208), (210, 221)]","[['e', 'Bus', '=', 'bus', 'transfer', 'in', 'Depending on the position', 'the', 'nodes in the bus they can reserve the bus for sending data with a higher probability', 'fairness is a problem due to the bus topology: De', 'on the position', 'the node the node may be more', 'successful in reserving a bus for data transmission']]",0.875
5.11,"The receiver cant differentiate between a new correct package or an ""old"" duplicated package, which leads to multiple data processing.",CORRECT,1.0,[0],[],[[]],1.0
5.11,A receiver might not be able to distinguish a duplicate from a normal packet and so re-execute the given task.,CORRECT,1.0,[0],[],[[]],1.0
5.11,"The duplicate packets reduce effective tool bandwidth, waste tool processing power, and consume tool storage capacity, reducing their effectiveness.",CORRECT,1.0,[0],[],[[]],1.0
5.11,"The receiver does not know which ""data"" it should use and will probably re-execute the transfer, which could lead to more network traffic.",CORRECT,1.0,[0],[],[[]],1.0
5.11,Receiver might not be able to distinguish between a real and a duplicate packet.,CORRECT,1.0,[0],[],[[]],1.0
5.11,The duplicate packets is a a problem due to the reducing of the bandwidth and the decreasing of the efficiency.,CORRECT,1.0,[0],[],[[]],1.0
5.11,The receiver cannot recognize the difference between correct data and duplicated data and would re-execute the transaction.,CORRECT,1.0,[0],[],[[]],1.0
5.11,The receiver may not be able to tell that the packet is a duplicate and re-executes an operation.,CORRECT,1.0,[0],[],[[]],1.0
5.11,Duplicate packets can be false recognized as new data and then cause problems on higher network layers.,CORRECT,1.0,[0],[],[[]],1.0
5.11,The receiver cannot differential between the correct date and the duplicated date.,CORRECT,1.0,[0],[],[[]],1.0
5.11,The receiver receiving the duplicate might not distinguish it from a real packet and could perform a wrong (unwanted) action.,CORRECT,1.0,[0],[],[[]],1.0
5.11,"Yes because the receiver will think they are different and process them multiple times, which leads to unexpected result.",CORRECT,1.0,[0],[],[[]],1.0
5.11,Duplicate packets in a network can result in a network overload if all senders would send the same packets multiple times.,CORRECT,1.0,[0],[],[[]],1.0
5.11,Besides increasing the traffic load duplicates can cause unwanted behavior when not handled properly.,CORRECT,1.0,[0],[],[[]],1.0
5.11,The receiver cannot differentiate between a correct packet and a duplicated one and would process it again.,CORRECT,1.0,[0],[],[[]],1.0
5.11,"Network has varying transit times for packets, certain loss rate and storage capabilities, as well as  packets can be manipulated, duplicated by flooding and resent by the original system after timeout.",PARTIAL_CORRECT,0.5,[0],[],[[]],1.0
5.11,"Duplicates of packages could lead to the reinitiation of a transaction, which was already considered finished by one part of the communicating party.",CORRECT,1.0,[0],[],[[]],1.0
5.11,duplicate packets will waste the bandwidth,CORRECT,1.0,[0],[],[[]],1.0
5.11,A receiver may not be able to differentiate between original and duplicated data and may so process wrong data.,CORRECT,1.0,[0.5444895029067993],"[(0, 1), (2, 7), (9, 11), (12, 17), (18, 19), (21, 23)]","[['A', 'receiver may not be ', 'differentiate', 'between original and duplicated', 'and', 'process wrong']]",1.0
5.11,"Wenn der Empfänger nicht in der Lage ist, zwischen gültigen und duplizierten Paketen zu unterscheidenkann er auf dieselbe Information zweimal reagieren.",CORRECT,1.0,[0.4600582718849182],"[(5, 6), (31, 33)]","[['nicht', 'zweimal']]",1.0
5.11,Duplicates (e.g delayed. from previous sessions) can't be distinguished from packets of the current transmission and may cause problems because they can't be handled properly.,CORRECT,1.0,[0],[],[[]],1.0
5.11,The receiver cannot distinguish duplicate packets from correct packets so it would re-excute the transaction .,CORRECT,1.0,[0],[],[[]],1.0
5.11,"If people doesn't use additional infomation to identify the packes, receiver cannot distinguish the first arrived packet and later pulicate packet, then it would re-execute the transaction.",CORRECT,1.0,[0],[],[[]],1.0
5.12,"1. to use temporarily valid TSAPs,  TSAP valid for one connection only,but process server addressing method not possible 2. to identify connections individually,  each individual connection is assigned a new SeqNo and endsystems remember already assigned SeqNo, but endsystems must be capable of storing this information 3. to identify PDUs individually, individual sequential numbers for each PDU, SeqNo basically never gets reset, but higher usage of bandwidth and memory",CORRECT,1.0,"[0.9323083162307739, 1.0, 0.7068932056427002, 0.5987151861190796, 0.8041485548019409, 0.6640163064002991, 0.6333691477775574, 0.7057092785835266, 0.8154186606407166, 0.7863476276397705, 0.8506051898002625, 0.7680467963218689, 0.824501633644104, 0.5939963459968567, 0.6594352126121521, 0.6551225185394287]","[(1, 9), (10, 17), (18, 34), (36, 60), (61, 82), (83, 88), (90, 93)]","[['to use temporarily valid TSAPs', 'TSAP valid for one connection only', 'but process server addressing method not possible 2. to identify connections individually', 'each individual connection is assigned a new SeqNo and endsystems remember already assigned SeqNo', 'but endsystems must be capable of storing this information 3. to identify PDUs individually', 'individual sequential numbers', 'each PDU']]",1.0
5.12,Temporarily valid TSAPs Identify connections individually Identify PDUs individually Pros TSAP valid for one connection only each individual connection is assigned a new SeqNo and endsystems remember already assigned SeqNo SeqNo never gets reset Cons server is reached via a designated/known TSAP endsystems must be capable of storing this information higher usage of bandwidth and memory,CORRECT,1.0,"[0.5579683780670166, 0.612826406955719, 0.6029463410377502, 0.509518563747406, 0.5207089781761169, 0.6907402276992798, 0.5534037947654724, 0.5460774302482605, 0.6627183556556702, 0.643232524394989, 0.6542863249778748, 0.5795180797576904, 0.5978030562400818, 0.5819337368011475, 0.6632957458496094, 0.5650790929794312]","[(0, 94)]",[['Temporarily valid TSAPs Identify connections individually Identify PDUs individually Pros TSAP valid for one connection only each individual connection is assigned a new SeqNo and endsystems remember already assigned SeqNo SeqNo never gets reset Cons server is reached via a designated/known TSAP endsystems must be capable of storing this information higher usage of bandwidth and memory']],1.0
5.12,"1) use a unique TSAP from the beginning till the end of the connection + ensures there won't be problem with misinterpreting connections at the same port - requires large name size of TSAP - practically impossible, because there exist ""well-known"" TSAP that exist always  2) define unique connection sequence number, with end systems also remembering previous sequence numbers + by remembering the previous connections too, the end systems can differentiate all the incoming data - can't work easily for connectionless services - end systems need enough space for storing this information  3) use sequence numbers for packets + you don't need to get bothered for resetting the sequence numbers, because for example (also stated in the lecture), a 48 bit number will practically never reach to an end - however, the bandwidth and the memory you need to send a packet gets increased, because the sequence numbers never get reset and need a number with many digits (e.g. 48 bits)",CORRECT,1.0,"[0.5191164016723633, 0.5304682850837708, 0.6650747060775757, 0.611349880695343, 0.5585184097290039, 0.6346301436424255, 0.6088985800743103, 0.6132412552833557, 0.6452078223228455, 0.6921389102935791, 0.7314282059669495, 0.5000596642494202, 0.7515770792961121, 0.6045611500740051, 0.6754661202430725, 0.6202292442321777]","[(4, 5), (18, 21), (24, 25), (29, 30), (61, 62), (69, 70), (125, 126), (127, 132), (133, 138), (140, 145), (146, 148), (149, 151), (158, 159), (160, 162)]","[['unique', 'ensures', 't', 'interpret', '-', 'always', '', 'end systems need enough', 'for storing this information', 'sequence numbers for', 'packets', 'you don', 'for', 'setting the']]",0.625
5.12,"1. to use temporarily valid TSAPs adv:simple disadv:may cause some comflict with some ""well-known"" TSAPs  2. to identify connections individually adv: reliable disadv: end systems must be able to store SeqNos  3. to identify PDUs individually: individual seq num for each PDU adv: higher usage of bandwidth and memory disadv: higher cost",CORRECT,1.0,"[0.6451296210289001, 0.5416153073310852, 0.6258127093315125, 0.5491928458213806, 0.5551128387451172, 0.6098578572273254, 0.6784619092941284, 0.6873995065689087, 0.6280332207679749, 0.6505081653594971, 0.6948572993278503, 0.6685159206390381, 0.6766728758811951, 0.5912830233573914, 0.7473029494285583, 0.5988569259643555]","[(1, 33), (34, 61), (62, 98)]","[['to use temporarily valid TSAPs adv:simple disadv:may cause some comflict with some ""well-known"" TSAPs', 'to identify connections individually adv: reliable disadv: end systems must be able to store SeqNos', 'to identify PDUs individually: individual seq num for each PDU adv: higher usage of bandwidth and memory disadv: higher cost']]",0.625
5.12,"1. Use of temporarily valid TSAPs [–] not applicable in most cases as TSAP must be known to address the correct process [+] in case of always changing TSAPs which are known to sender and receiver (i.e. through a known sequence) an attacker has a harder time tracing/interrupting the targeted traffic in case there are multiple senders/receivers 2. Identify connections individually by assigning new SeqNo [–] requires state / storing SeqNo (connection oriented system) [+] easy differentiation of connections 3. Identify PDUs individually with SeqNo's [–] a notion of a ""lifetime"" of a packet in the network is needed [–] higher usage of bandwidth and memory [+] works with connectionless system",CORRECT,1.0,"[0.5916056632995605, 0.5846137404441833, 0.6592428684234619, 0.61390221118927, 0.6646831035614014, 0.6618066430091858, 0.6028149724006653, 0.6153298020362854, 0.6589899659156799, 0.6956056952476501, 0.5926614999771118, 0.6224604249000549, 0.6509947776794434, 0.5909191370010376, 0.7133443355560303, 0.6727403998374939]","[(1, 54), (56, 58), (59, 64), (65, 66), (68, 69), (70, 71), (73, 76), (77, 78), (79, 80), (95, 134), (135, 190)]","[['Use of temporarily valid TSAPs [–] not applicable in most cases as TSAP must be known to address the correct process [+] in case of always changing TSAPs which are known to sender and receiver (i', '. through', 'a known sequence', 'an', 'has', 'a', 'time tracing', 'interrupt', 'the', 'Identify connections individually by assigning new SeqNo [–] requires state / storing SeqNo (connection oriented system) [+] easy differentiation of connections', 'Identify PDUs individually with SeqNo\'s [–] a notion of a ""lifetime"" of a packet in the network is needed [–] higher usage of bandwidth and memory [+] works with connectionless system']]",1.0
5.12,"1. to use temporarily valid TSAPs.  pro: sure would solve the duplicate problem  contra: some servers should be reached through a known TSAP, which should not be discarded after single usage. 2.to identify connections individually pro: better than temporarily valid TSAPs, at least can be used to solve duplicate problem in a connection-oriented system. contra: in a connection-less system it does not work. 3.to identify packets individually pro:solve the duplicate problem with dexterity, man can choose the sequence number range for individual case. contra: the usage of bandwidth and memory will be higher due to the packet sequence number.",CORRECT,1.0,"[0.8783600330352783, 0.6123037934303284, 0.6698387861251831, 0.5912399888038635, 0.5887434482574463, 0.6393401026725769, 0.6112039089202881, 0.7444021701812744, 0.6321009993553162, 0.642906904220581, 0.6112996935844421, 0.7509090304374695, 0.6624497771263123, 0.5948354005813599, 0.7197727560997009, 0.626255989074707]","[(0, 9), (52, 69), (80, 81), (83, 88), (95, 96), (105, 125), (141, 142), (143, 146), (147, 149)]","[['1. to use temporarily valid TSAPs', 'to identify connections individually pro: better than temporarily valid TSAPs', 'problem', 'a connection-oriented system', '-', 'to identify packets individually pro:solve the duplicate problem with dexterity', 'the', 'usage of band', 'and memory']]",1.0
5.12,"Unique TSAP for each connection:  + addresses duplicated across connections (e.g. after a crash) - usually limited number of TSAPs - some TSAPs are well known and therefore not usable (e.g. for HTTP)- doesn't address duplicates within the same connection  Sequence Number for each connection:  + solves problems specific to unique TSAPs - but also doesn't address duplicates within one connection - endsystems need to store sequence numbers, even after switching off  Sequence Number for each PDU:  + addresses duplicates between and within connections + only need info about last few used SeqNrs - higher usage of bandwidth/memory - have to choose a range for SeqNrs",CORRECT,1.0,"[0.6072525978088379, 0.7186774611473083, 0.6966403722763062, 0.6326192021369934, 0.6324690580368042, 0.6782210469245911, 0.6315789818763733, 0.6352863907814026, 0.6823938488960266, 0.6920007467269897, 0.6392962336540222, 0.6088293194770813, 0.7805880904197693, 0.6242637038230896, 0.8108972311019897, 0.6510555744171143]","[(2, 8), (9, 18), (25, 26), (31, 32), (42, 43), (65, 66), (67, 68), (70, 71), (72, 74), (75, 77), (78, 87), (88, 97), (98, 103), (112, 113), (114, 119), (120, 122), (123, 125), (132, 134), (137, 139), (142, 143), (144, 146), (147, 148), (154, 155), (158, 159), (161, 162), (168, 173), (175, 176), (177, 178), (183, 184)]","[['TSAP for each connection', '+ addresses duplicated across connections', 'a', 'u', 'some', ')', '', ""'"", 'address duplica', 'within', 'same connection Sequence Number for each connection', '+ solves problems specific to unique TSAP', '- but also ', 'one', '- endsystems need', 'store ', 'numbers', 'Sequence Number', 'PDU', 'addresses', 'tes ', 'and', 'need', '', '', 'higher usage of band', 'memory', '-', 'a']]",1.0
5.12,"1. to use temporarily valid TSAPs Advantages: TSAP valid for one connection only(always newly generated) Disadvantages: in general not always applicable:  process server addressing method not possible, because:  - server is reached via a designated/known TSAP - some TSAPs always exist as “well-known”   2. to identify connections individually Advantages:  each individual connection is assigned a new SeqNo and endsystems remember already assigned SeqNo  Disadvantages: endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed  3.to identify PDUs individually: individual sequential numbers for each PDU  Advantages: SeqNo basically never gets reset Disadvantage: higher usage of bandwidth and memory",CORRECT,1.0,"[0.6570095419883728, 0.672425389289856, 0.633402943611145, 0.666533350944519, 0.6803467273712158, 0.7161213159561157, 0.6929130554199219, 0.618133008480072, 0.7034464478492737, 0.6550748944282532, 0.5652652382850647, 0.6465502977371216, 0.6900533437728882, 0.655781090259552, 0.7325586676597595, 0.6063908338546753]","[(1, 44), (45, 48), (49, 121), (147, 190)]","[['to use temporarily valid TSAPs Advantages: TSAP valid for one connection only(always newly generated) Disadvantages: in general not always applicable: process server addressing method not possible', 'because:', '- server is reached via a designated/known TSAP - some TSAPs always exist as “well-known” 2. to identify connections individually Advantages: each individual connection is assigned a new SeqNo and endsystems remember already assigned SeqNo Disadvantages: endsystems', 'to identify PDUs individually: individual sequential numbers for each PDU Advantages: SeqNo basically never gets reset Disadvantage: higher usage of bandwidth and memory']]",1.0
5.12,1. TSAPs Ad: TSAPs only  for one connection  Dis: process server addressing method not possible  2.identify connections individually Ad:each individual connection has a new Seq Dis: End system will be switched off  3. identify PDUs individually Ad: Seq never gets reset Dis:higher usage of bandwidth and memory,CORRECT,1.0,"[0.6003825068473816, 0.7211697697639465, 0.6543336510658264, 0.5377961993217468, 0.7937746644020081, 0.628502368927002, 0.5737496614456177, 0.6450483798980713, 0.7042999863624573, 0.6178966760635376, 0.5939624309539795, 0.6873155236244202, 0.625737726688385, 0.6321647763252258, 0.7714521884918213, 0.5806772708892822]","[(1, 22), (23, 49), (50, 75)]","[['TSAPs Ad: TSAPs only for one connection Dis: process server addressing method not possible', 'identify connections individually Ad:each individual connection has a new Seq Dis: End system will be switched off', 'identify PDUs individually Ad: Seq never gets reset Dis:higher usage of bandwidth and memory']]",1.0
5.12,"1. to use temporarily valid TSAPs Method: TSAP only valid for one conntection, generates always a new TSAP Advantage: complete unique connection Disadvantage: too many connections will be generated in worst case, in general not always applicable   2. to identify connections individually Method: each individual connection is assigned a new SeqNo Advantage: each connection relies on SeqNo and will be remembered from endsystems because of the assigned SeqNo Disadvantage: endsystem must be capable of storing this information   3. to identify PDUs individually Method: individual sequential numbers for each PDU, SeqNo basically never gets reset Advantage: packets have a ""lifetime"" within the network Disadvantage: higher usage of bandwith and memory",CORRECT,1.0,"[0.7728880047798157, 0.7260453104972839, 0.678645133972168, 0.7484370470046997, 0.5958012342453003, 0.6583778262138367, 0.6248065233230591, 0.6120530962944031, 0.67259281873703, 0.6733381152153015, 0.667816162109375, 0.6146315932273865, 0.6878448724746704, 0.7068161368370056, 0.8658648133277893, 0.6086189150810242]","[(1, 20), (25, 26), (27, 34), (35, 39), (54, 56), (57, 59), (60, 147), (149, 155), (156, 159), (160, 162), (163, 168), (170, 171), (172, 186)]","[['to use temporarily valid TSAPs Method: TSAP only valid for one conntection', 'always', 'a new TSAP Advantage:', 'unique connection Disadvantage', 'general not', 'always applicable', 'to identify connections individually Method: each individual connection is assigned a new SeqNo Advantage: each connection relies on SeqNo and will be remembered from endsystems because of the assigned SeqNo Disadvantage: endsystem must be capable of storing this information 3. to identify PDUs individually Method: individual sequential numbers for each PDU', 'SeqNo basically never get', 'reset Advantage', 'packet', 'have a ""life', '', 'the network Disadvantage: higher usage of bandwith and memory']]",1.0
5.12,"1)Temporarily valid TSAPs Advantage: Easy to implement Disadvantage: Doesn't work for Connections that use a static and known TSAP.(server addressing)   2)Identifying the connections individually with SeqNo Advantage: Each connection gets its own SeqNo making it unique and easily idnetifiable. Disadvantage: The End Systems has to remember already assigned SeqNo.    3)Identifying the packets individually with SeqNo Advantage: Makes it easy to identify duplicates, as each packet has its own SeqNo. Disadvantage: Requires a lot of bandwidth and memory.",CORRECT,1.0,"[0.5714783072471619, 0.5668172836303711, 0.6269465088844299, 0.5788319110870361, 0.5652986168861389, 0.6452623605728149, 0.5927935242652893, 0.6421216130256653, 0.7426674365997314, 0.8573732376098633, 0.5811253786087036, 0.6598771810531616, 0.6481078863143921, 0.60439133644104, 0.6143561601638794, 0.5871989727020264]","[(0, 37), (43, 82), (86, 90), (94, 100), (102, 127), (150, 151), (152, 153)]","[[""1)Temporarily valid TSAPs Advantage: Easy to implement Disadvantage: Doesn't work for Connections that use a static and known TSAP"", '2)Identifying the connections individually with SeqNo Advantage: Each connection gets its own SeqNo making it unique and easily idnetifiable', 'The End Systems has', 'already assigned SeqNo', 'Identifying the packets individually with SeqNo Advantage: Makes it easy to identify duplicates', 'band', 'and']]",1.0
5.12,"1. To identify each connection, i.e., Each connection is assigned  an unique number and endsystems remember already those number.  Pro: + not complicate Con: - endsystems need largememory capacity to save this information.  2. To identify PDUs individually: Assign individual seq number for each PDU. Pro: + higher usage of bandwidth and memory. Con: - hard to choose a suitable sequential number range because of different packet rate and the limited lifetime of a packet within the network.  3. To use temporarily valid TSAPs Pro: + high availiablity Con: - not always applicable , sometimes no possible to address method",CORRECT,1.0,"[0.680555522441864, 0.5615212321281433, 0.6357172131538391, 0.6188848614692688, 0.5442249178886414, 0.6677764654159546, 0.5987779498100281, 0.6370352506637573, 0.7142003178596497, 0.7436215877532959, 0.6371476054191589, 0.7354512810707092, 0.7320538759231567, 0.5899143815040588, 0.7566186785697937, 0.6996124982833862]","[(15, 16), (17, 32), (57, 77), (78, 79), (80, 86), (87, 90), (95, 99), (100, 109), (110, 115), (116, 117), (118, 127), (129, 130), (132, 157)]","[['Each', 'is assigned an unique number and endsystems remember already those', 'To identify PDUs individually: Assign individual seq number for each PDU', 'Pro', '+ higher usage of', 'width and memory', 'hard to choose', 'a suitable sequential number range ', 'of different packet rate', 'the', 'limited lifetime of a packet ', 'network', 'To use temporarily valid TSAPs Pro: + high availiablity Con: - not always applicable ']]",1.0
10.2_TC,"Phase 1: Slow start  Phase 2: Congestion avoidance   In the beginning of Phase 1 the cwnd is increasing exponentially starting at cwnd=1 by doubling cwnd after every transmission until a threshhold ss_thresh is reached. From this point onwards, cwnd is increased linearly until congestion occurs. This initiates Phase 2, in which ss_thresh is set to the half of the value of cwnd at the moment when the congestion occured (ss_thresh_new = cwnd/2). Afterwards cwnd is reset to 1 and Phase 1 starts again with the new value of ss_thresh.",PARTIAL_CORRECT,0.625,"[0.6142473220825195, 0.6667768359184265, 0.6450576782226562, 0.5400970578193665, 0.6172581315040588, 0.6228453516960144, 0.6473573446273804]","[(0, 62), (95, 96), (108, 110), (121, 122), (124, 125), (126, 128), (131, 132)]","[['Phase 1: Slow start Phase 2: Congestion avoidance In the beginning of Phase 1 the cwnd is increasing exponentially starting at cwnd=1 by doubling cwnd after every transmission until a threshhold ss_thresh is reached', '_', 'wnd', 's', 'th', '_new', 'wn']]",0.875
10.2_TC,"Phase 1: Slow Start               In this phase, every time the segment is acknowledged, cnwd plus one until it reaches ss_thresh or packet loses, but when cnwd is not smaller than ss_thresh, cnwd will increase much slower.  Phase 2: Congestion Avoidance              In this phase, the new ss_thresh is half of the cnwd, and cnwd will be reset to one, then slow start starts.",PARTIAL_CORRECT,0.5,"[0.5368056893348694, 0.5505878925323486, 0.5733988881111145, 0.7317624092102051, 0.4826725721359253, 0.5216906666755676, 0.5307421684265137]","[(74, 85)]",[['Phase 2: Congestion Avoidance In this phase']],0.625
10.2_TC,"The two phases of congestion control are called slow start and congestion avoidance. In the first phase grows the cwnd exponentially until it reaches ss_thresh. From this moment, the second phase begins and the cwnd grows only linear. If a timeout happens, cwnd is reset to one and ss_thresh is set to the half of the (former) cwnd. Then the two phases start again.",PARTIAL_CORRECT,0.75,"[0.5716652870178223, 0.5912122130393982, 0.5986200571060181, 0.5526261925697327, 0.48903700709342957, 0.5526267290115356, 0.5404834747314453]","[(0, 20), (44, 45)]","[['The two phases of congestion control are called slow start and congestion avoidance', '_']]",0.625
10.2_TC,"The two phases are: 1. slow start 2. congestion avoidance  After initialization (cwnd = 1, ss_thresh = advertised window size), during the slow start, cwnd is incremented by one each time a segment is acknowledged, so that cwnd grows quickly (cwnd = 1, 2, 4, 8; so in effect, it is doubled every round-trip time). In case of packet loss (congestion) ss_thresh is reset to the half of cwnd, cwnd is then reset to 1 and the slow start phase is started from the beginning, otherwise cwnd is incremented as long as the condition cwnd less than ss_thresh holds. When ss_thresh is reached, the second phase (congestion avoidance) is entered and cwnd is now increased more slowly (linear versus exponential increase in the first phase: cwnd = 9, 10, 11...; it is increased by one every round-trip time) until a timeout (congestion) occurs. In case of timeout (congestion), ss_thresh is reset to the half of cwnd, cwnd is then reset to 1 and the slow start phase is started again.",CORRECT,1.0,"[0.7569902539253235, 0.6882464289665222, 0.6485171318054199, 0.7244266867637634, 0.7879986763000488, 0.6592325568199158, 0.6066679954528809]","[(11, 20), (21, 23), (24, 25), (45, 53), (54, 64), (99, 100), (103, 104), (106, 108), (109, 113), (114, 118), (119, 122), (123, 124), (181, 182), (187, 232), (233, 234), (237, 239), (242, 244), (245, 247), (252, 253)]","[['congestion avoidance After initialization (', 'wnd', '=', 'cwnd is incremented by one', 'each time a segment is acknowledged', 'In', 'packet', 'congestion', 'ss_', 'resh is reset to', 'half of c', 'd', 'resh', 'the second phase (congestion avoidance) is entered and cwnd is now increased more slowly (linear versus exponential increase in the first phase: cwnd = 9,', '11', 'is in', 'every round', 'trip time', '']]",0.875
10.2_TC,"Phase 1 is called Slow Start. In this phase, the congestion window (cwnd) grows exponentially until the slow start threshold (ss_thresh) is reached, and then it grows linearly. Then, everytime congestion occurs, Phase 2 or congestion control starts. In this phase, ss_thresh is set to 50% of the current cwnd value. cwnd is then set to 1 and slow start starts again.",PARTIAL_CORRECT,0.375,"[0.40753766894340515, 0.41145095229148865, 0.43178051710128784, 0.38703176379203796, 0.46073317527770996, 0.3539992570877075, 0.4441351890563965]","[(29, 30), (37, 38), (43, 44)]","[['the', 's', '']]",0.25
10.2_TC,"In the first phase, the slow start, cwnd grows exponentially with base 2.  When cwnd equals ss_thresh, the second phase, the congestion avoidance, starts, where cwnd now only grows linearly.  When congestion occurs, ss_thresh is set to cwnd / 2 and cwnd is reset to 1 and the system is back in phase 1.",PARTIAL_CORRECT,0.75,"[0.5909996032714844, 0.6756348609924316, 0.7262864112854004, 0.751196026802063, 0.5876982808113098, 0.5548871159553528, 0.7532409429550171]","[(41, 47), (71, 88), (89, 92)]","[['the congestion avoidance', 'ss_thresh is set to cwnd / 2 and cwn', 'is reset to']]",0.625
10.2_TC,"The two phases of congestion control are a slow start and congestion avoidance. Lets assume the slow start threshold is X. After initialization, the ""slow start"" begins with checking if one segment arrives at the sender (receiving ACK) and increases the number of segments until the procedure throws an error. The new ss_thresh is half of the last segments that arrived successfully (cwnd/2). Then in phase two, the congestion window is reset to 1, and the process starts with a new ss_thresh (cwnd/2).",PARTIAL_CORRECT,0.25,"[0.5738769173622131, 0.5948533415794373, 0.6023434996604919, 0.560570240020752, 0.4913071393966675, 0.5604202151298523, 0.5400392413139343]","[(0, 20)]",[['The two phases of congestion control are a slow start and congestion avoidance']],0.625
10.2_TC,"Two phases of congestion control: slow start and congestion avoidance   Congestion Window (cwnd) and the Slow Start threshold (ss_thresh) changes in:  - Slow start: cwnd starts with 1 and then after every successful ACK, 2 packets are sent instead of just one, so that cwnd increases exponentially with the power of two, as doubles after every round-trip time (RTT). When cwnd >= ss_thresh, congestion avoidance phase begins. Otherwise when a timeout (congestion) occurs during the slow start phase, cwnd is reset to 1 again (cwnd = 1) and the ss_thresh is set to half of the cwnd (ss_thresh = cwnd / 2). Then slow start repeats with the new ss_thresh value.  - Congestion avoidance: cwnd is not doubled after every RTT anymore, but only incrementally increases until a timeout (congestion) taking place again. Congestion avoidance is terminated and it gets back to slow start phase with the ss_thresh = cwnd / 2 and cwnd is now reset to 1 again.",CORRECT,1.0,"[0.6577820181846619, 0.6361644268035889, 0.690413773059845, 0.6426798105239868, 0.6487774848937988, 0.6187640428543091, 0.6765342950820923]","[(0, 47), (48, 50), (51, 52), (54, 55), (56, 57), (61, 63), (107, 108), (109, 111), (112, 114), (116, 119), (120, 129), (135, 138), (139, 141), (142, 144), (147, 148), (187, 190), (191, 194), (218, 238)]","[['Two phases of congestion control: slow start and congestion avoidance Congestion Window (cwnd) and the Slow Start threshold (ss_thresh) changes in: - Slow start', 'cwn', 'start', '1', 'then', 'ACK', 'When', 'wnd', '>= ', '_thresh', 'congestion avoidance phase begins', 'a timeout', 'congestion', 'occurs', 'slow', '_thresh', '= cwn', '- Congestion avoidance: cwnd is not doubled after every RTT anymore']]",0.875
10.2_TC,"First, in the ""slow start"" phase, the sender sends one segment, then two, four, eight segments, etc. (always doubling the cwnd), until the ss_thresh is reached. Then, in ""congestion avoidance"" phase, the sender only increments the cwnd linearly (+1). If a congestion occurs, the ss_thresh is set to 50% of the current size of the cwnd, the cwnd is set to 1, and the sender starts again with slow start.",PARTIAL_CORRECT,0.75,"[0.5592494010925293, 0.6026638150215149, 0.6149529814720154, 0.6473709344863892, 0.4699256718158722, 0.5617657899856567, 0.56873619556427]","[(56, 66)]","[['in ""congestion avoidance"" phase']]",0.625
10.2_TC,"1. Slow start: After the initializtion, cwnd is increased by 1 each time when a segment is acknowledged. This continues until cwnd == ss_thresh or a packet gets lost. When cwnd >= ss_trhesh, TCP slows down the increase of cwnd. Especially, slow start increases the rate exponentially if each ACK generates 2 packets. 2. Congestion avoidance: Each time congestion occurs, ss_thresh is set to ss_tresh = cwnd / 2 and cwnd is reset to one s.t. cwnd = 1. After that, slow-start is entered.",PARTIAL_CORRECT,0.75,"[0.7094950675964355, 0.6569669246673584, 0.7352551221847534, 0.6283589005470276, 0.7266472578048706, 0.6586785316467285, 0.7715407013893127]","[(11, 17), (18, 30), (38, 39), (41, 44), (45, 47), (49, 50), (54, 55), (110, 123), (125, 147), (148, 150), (152, 154), (161, 163)]","[['wnd is increased by', 'each time when a segment is acknowledg', 'wn', 'ss', 'thresh', 'a', 'lost', 'Congestion avoidance: Each time congestion occurs', 'ss_thresh is set to ss_tresh = cwnd / 2', 'cwn', 'reset to', 'wnd']]",0.625
10.2_TC,"The two phases are Slow Start and Congestion Avoidance. At the slow start, the cwnd is initialised with 1 and then ex the slow start treshold (ss-thresh) is set on the advertised window size. While in the slow phase, the cwnd is counted up exponentially, but smaller than the ss_thresh. The congestion avoidance phase is reached, when the cwnd is as big as the ss_thresh. After that, the cwnd is increased linearily. Whenever there is a timeout, then the ss_thresh will be set on half the amount of the cwnd, and cwnd will be reset at 1 again and phase 1 starts again.",PARTIAL_CORRECT,0.75,"[0.5908527374267578, 0.6496779918670654, 0.6129601001739502, 0.7115232348442078, 0.5219230651855469, 0.598224401473999, 0.5422886610031128]","[(0, 14), (85, 97)]","[['The two phases are Slow Start and Congestion Avoidance', 'The congestion avoidance phase is reached']]",0.625
12.2_PE,"λ = 9pkts/s µ = 10pkts/s ρ = 9/10 = 0,9 = 90% Utilization E[n] = (0,9/0,1) – ((11*0,9^11) / (1-0,9^11)) = 3,969 = 4 Expected number of customers in the system.",INCORRECT,0.0,"[0.4905657172203064, 0.49490559101104736, 0.5473474860191345, 0.47514569759368896, 0.46194908022880554]","[(10, 11), (46, 51), (52, 56), (57, 59), (60, 63)]","[['', '((11*0,', '^11) /', '1-0,', '^11))']]",0.875
12.2_PE,We need to calculate the probability that the system has 9 or less packets. To do that we calculate 1 – p_10.  p_10  is the blocking probability P_B which can be calculated using the formula on page 31 from the performance evaluation slides.  With a utilization of 9/10 we have a probability of around 1 – 0.05 = 0.95. Which means we expect the system to spend around 0.95 * 60s = 57s seconds in a state with less than 10 packets.,CORRECT,1.0,"[0.7441895008087158, 0.6562490463256836, 0.6399634480476379, 0.5990555882453918, 0.5855299830436707]","[(0, 14), (15, 18), (31, 51), (52, 53), (54, 55), (57, 58), (60, 61), (80, 81), (83, 84), (99, 100)]","[['We need to calculate the probability that the system has 9 or', 'packets', '_10 is the blocking probability P_B which can be calculated using the', 'on', '31', 'performance', '', '–', '=', '0.95']]",0.0
12.2_PE,"λ = 9     less than equal to packets arriving per second µ = 10   less than equal to packets served per second N = 10   less than equal to buffer size  => ρ = 9/10  The probability that there less than 10 packets in the system is E(n less than 10).  E(n less than 10) = 1- E(10) = 1 - Blocking probability = 1 - 0.457324 = 0.954276  So in 60 seconds, there are less than 10 packets in the queue for E(n less than 10) * 60 = 57.2561 seconds.",PARTIAL_CORRECT,0.5,"[0.561531662940979, 0.5951327085494995, 0.6329817175865173, 0.5667816996574402, 0.5842494368553162]","[(14, 15), (30, 31), (36, 38), (39, 41), (44, 45), (50, 51), (53, 61), (62, 64), (66, 73), (91, 92), (94, 97), (100, 101), (104, 105), (108, 109), (127, 128)]","[['ing', '', '= 10', 'than ', 'size', '=', 'The probability that there less than 10', 'packets', 'system is E(n less than', 'Block', 'ity =', '0.4', '=', 'So', 'E']]",0.875
12.2_PE,"We expect the system to be in a state where there are less than 10 packets in the queue roughly 57 seconds of the 1 minute we observe. First we need to calculate the mean load of the system (ro) as 9/10 as we can serve 10 packets while 9 arrive per sec. Then we can use the formulas from the lecture to compute with what percentage the system is in the state where 10 packets are waiting in the queue.  This is roughly 5% of the time, which means there are 10 packets waiting roughly 3 seconds of our observed minute. Which means there are less than 10 packets waiting ~57 seconds of our minute.",CORRECT,1.0,"[0.5684846639633179, 0.6148884892463684, 0.5675756931304932, 0.4791609048843384, 0.5384914875030518]","[(0, 4), (5, 7), (8, 19), (20, 36)]","[['We expect the system', 'be in', 'a state where there are less than 10 packet', 'in the queue roughly 57 seconds of the 1 minute we observe']]",1.0
12.2_PE,"The system reaches equilibrium when the arriving packet rate is the same as the serving packet rate. The system will never reach equilibrium because the arriving packet rate is less than the serving packet rate, thus the packets in the queue will always be less than 10 packets.",INCORRECT,0.0,"[0.6101754903793335, 0.6011682748794556, 0.6098763942718506, 0.364233136177063, 0.39212143421173096]","[(0, 13), (15, 26)]","[['The system reaches equilibrium when the arriving', 'rate is the same as the serving packet rate']]",0.0
12.2_PE,"With a buffer of size 10, the probability of less than 10 packets in the queue is the probability that there is any other number of packets in the system than 10. With the utilization being 9 / 10, the probability for this case after reaching equilibrium is 1 - p(10) = 0,9492 (rounded). When monitoring the system for one minute (60 s), I would therefore expect the system to be in a state with less than 10 waiting packets for 0,9492 * 60 s = 56,952 s",CORRECT,1.0,"[0.632391631603241, 0.6857236623764038, 0.5988516211509705, 0.42603766918182373, 0.4570789933204651]","[(7, 31), (32, 40), (50, 51), (53, 54), (65, 67), (70, 71), (106, 107)]","[['the probability of less than 10 packets in the queue is the probability that there is any other number', 'packets in the system than 10.', 'the', 'for', '-', '=', '10']]",1.0
12.2_PE,"Since the system reached an equilibrium the probabilities do not change anymore ( dp_n(t)/dt = 0 ). So it can be assumed that the queue is emptied by one package each second on average (10 served - 9 arrived).  Now assuming that the queue is full at obvservation start, it will be empty after 10 seconds, from which 9 seconds the queue has less packets then 10.",INCORRECT,0.0,"[0, 0, 0, 0, 0]",[],[[]],0.375
12.2_PE,"We expect the system to be in a state with less than 10 packets in the queue for 56.94s during the measured interval of one minute.  First we calculated the utilization: (9pkt/s)/(10pkt/s) = 0.9 Then, we calculated the probability for the system to be in state 10, i.e. the probability that the system is full. p_10=((1-0.9)*0.9^10)/(1-0.9^11) = 0.051 Next, we calculated the counter probability of p_10 as we actually want to know with which probability the system is not in state 10. 1-p_10 = 1-0.051 = 0.949 To get the number of seconds the system is not in state 10, we calculated 60s * 0.949 = 56.94s as we measure the system for 60 seconds.",CORRECT,1.0,"[0.6898570656776428, 0.6692237854003906, 0.6010904312133789, 0.503517746925354, 0.4895584285259247]","[(9, 10), (11, 12), (21, 22), (24, 26), (62, 76), (79, 80), (81, 86), (88, 89), (90, 108), (110, 116), (117, 122), (124, 133), (134, 136)]","[['state', 'less', 'for', 's ', 'we calculated the probability for the system to be in state 10,', 'e', 'the probability that the', 'full', 'p_10=((1-0.9)*0.9^10)/(1-0.9^11) = 0.051', 'we calculated the counter probabil', 'of p_10 as we', 'want to know with which probability the', 'is not']]",0.0
12.2_PE,First we need to calculate the utilization. In this scenario the utilization is quite high with 90%. However we want to know the time that the buffer has less than 10 entries. This means that not the case if the buffer is full. We can calculate probability for that using the above-mentioned utilization. The probability is about 5%. So it’s likely that the system will most likely have the full minute less than 10 packets.,PARTIAL_CORRECT,0.25,"[0.6315878033638, 0.6236916780471802, 0.5685537457466125, 0.40542131662368774, 0.4397253692150116]","[(0, 3), (6, 7), (55, 57), (59, 66), (70, 72)]","[['First we need', 'the', 'We can', 'probability for that using the', 'utilization']]",1.0
12.2_PE,p = 9/10 = 0.9 The expected Number of Customers in the System are p/1-p = 0.9/0.1 = 9. I expect that the queue always has less than 10 packets waiting in it.,INCORRECT,0.0,"[0, 0, 0, 0, 0]",[],[[]],0.375
